#+TODO: TODO IN-PROGRESS DONE
#+ORG-IMAGE-ACTUAL-WIDTH: 500px

* Journal de bord
** Backlog
*** IN-PROGRESS Automatiser la création d'un cluster de Raspberry virtualisé
- Plutôt que de travailler avec le cluster physique
- Serait intéressant d'apprendre à provisionner un cluster virtuel de Raspberry
- Permettrait de pouvoir créer un environnement pour dev et effectuer des tests
  - Notamment comment setup k8s ou équivalent sur un tel système
*** TODO Automatiser le setup de k3s sur un cluster de Raspberry
- Permettrait de graduate de minikube
  - Et d'apprendre ainsi tout ce qu'il gère pour moi automatiquement
- Et d'aller plus loin dans notre mise en place automatique d'environnements de dev et de test
- Ressources
  - Blogpost: https://medium.com/@stevenhoang/step-by-step-guide-installing-k3s-on-a-raspberry-pi-4-cluster-8c12243800b9
*** TODO Déployer WordPress sur un cluster de Raspberry
- Permettrait de valider le résultat obtenu dans les étapes précédentes
- Et de rencontrer les problèmes éventuels liés aux architectures processeurs
*** TODO SmartSense: Étudier la mise en place d'une interface WiFi
- Voir si un hardware donné est conseillé pour la Raspberry CM3
- Et comment ça s'utiliserait d'un POV logiciel
*** TODO SmartSense: Corriger le bug de récupération de la valeur `sector` dans une trame MQTT
- Un test unitaire a mis en lumière qu'en absence d'un champ `sector` dans une trame MQTT, c'est la valeur du champ `sub_sector` qui est utilisé instead
- Corriger cela
*** TODO SmartSense: Étudier la mise en place d'un schéma de fichier de config
- L'initialisation des noeuds reposent sur un fichier config.ini
- Pour le moment, je le retro-ingénérie pour identifier les différentes options possibles
  - Et leurs valeurs respectives
- Serait intéressant d'avoir un schéma précisant son format
  - Qui pourrait s'accompagner d'un outil de validation de fichier de config
  - Et p-e d'Enums utilisable dans le code Python
    - Plutôt que des chaînes de caractères error-prones
*** TODO SmartSense: Étudier la mise en place d'un protocole de messages
- Les différents composants de l'application s'échangent des messages pour communiquer des données et commandes
  - Noeud <-> Serveur
  - Mais aussi entre les différents modules d'un même composant
    - e.g. *InaManager* et *MainApp* du noeud
- A l'air d'utiliser pour le moment des chaînes de caractères codées en dur
- Error prone et peu lisible
- Voir si des outils permettent de décrire le schéma de communication
- Et de générer du code permettant guidant la création ou la lecture de messages
*** TODO SmartSense: Étudier la migration vers une nouvelle version d'InfluxDB
- Le projet utilise pour le moment la version 1.6.4 d'InfluxDB
- On en est actuellement à la version 2.7.5
- Voir si y a un intérêt à migrer à cette nouvelle version
  - Features, performances
- Voir surtout si ça peut tourner sur la rpi qui équipe le noeud SmartSense
  - Tourne sur un Compute Module 3 : https://www.raspberrypi.com/products/compute-module-3/
*** TODO SmartSense: Étudier la désactivation de la compaction des shards pour la base InfluxDB embarqué
- Le workaround implémenté pour éviter les crashs de la DB embarqué pointe du doigt le mécanisme de compression des shards d'InfluxDB
  - Trop coûteux à exécuter
- Une alternative possible au workaround possible est de tout simplement désactiver ce mécanisme
  - Cette PR semble confirmer que c'est possible : https://github.com/influxdata/influxdb/pull/19691
- Voir ce qu'est exactement ce mécanisme
  - Pourquoi il se déclenche ?
  - Quel est son rôle ?
  - Quel est l'impact sur InfluxDB si on le désactive ?
- Et voir si le désactiver met fin aux crashs
*** TODO SmartSense: Étudier l'intérêt de l'utilisation d'InfluxDB pour un noeud en mode autonome
- En mode autonome, un noeud SmartSense enregistre les données collectées dans sa BD InfluxDB embarquée
- Pourquoi ce SGBD ?
- On a besoin de stocker les données
- Mais a-t-on besoin d'une time series database ?
- Identifier l'utilisation que l'on va faire de la BD locale
- Et vérifier qu'une time series database est la plus appropriée pour répondre aux besoins correspondants
*** TODO SmartSense: Ajouter un test *provisioningViaMqtt* pour *MainApp*
- Mettre en place un test qui vérifie que si on démarre *MainApp* avec le flag /mqttEnabled/, on a bien
  - Envoi d'une requête de provisioning via *MqttInterface*
  - Que lorsqu'on répond via *MqttInterface*, ça conduise bien à un appel de *setProvisioning()* avec les bonnes valeurs
- Mocker *MqttInterface* ?
- Ou en faire un test d'intégration ?
*** TODO Lire *OZCAR: The French Network of Critical Zone Observatories*
- Ammar m'a recommandé cet article pour en apprendre plus sur les observatoires et leurs buts
- Le consulter
** Semaine du <2024-02-19 Mon> au <2024-02-23 Fri>
*** Planned
**** DONE SmartSense: Revert la version de l'application à avant le workaround pour InfluxDB
CLOSED: [2024-02-19 Mon 09:18]
- Je n'ai pas constaté le problème de crash de InfluxDB avec la version fournie
- Peut supposer qu'il est effectivement contourné par le workaround implémenté
- Mais ce workaround n'est pas satisfaisant
  - Données difficiles à importer par la suite vu qu'éclatées en de nombreux fichiers
- Serait intéressant de voir si une autre solution peut être mise en place
- Revert à la version pré-workaround de l'application pour observer et documenter le problème
**** DONE SmartSense: Identifier les paramètres de configuration d'InfluxDB pertinents pour la compaction
CLOSED: [2024-02-20 Tue 15:26]
- L'origine des crashs d'InfluxDB a bien l'air d'être le mécanisme de compaction de la base de données
- Il serait intéressant de jeter un oeil aux différents paramètres de configuration
  - https://docs.influxdata.com/influxdb/v1/administration/config/
- Et d'identifier lesquels peuvent être pertinents dans notre cas
- Sachant que nous voulons soit :
  - Désactiver le mécanisme de compression, puisque nous ne faisons aucune lecture sur le noeud
  - Augmenter la fréquence du mécanisme de compression, de façon à rendre ses exécutions moins gourmandes
**** IN-PROGRESS SmartSense: Intégrer la branche *refactor/mqtt-interface-remove-inheritance*
- Je voulais pas forcément intégrer cette modif
- Mais une bonne partie des commits de *refactor/main-app* modifient des lignes concernées par ces changements
- Je me retrouve avec des conflits fréquemment lorsque j'essaie de rebase en le retirant de l'historique
- Me parait plus safe, et préférable, d'intégrer ces changements
**** IN-PROGRESS SmartSense: Intégrer la branche *refactor/main-app*
- MàJ par rapport à *refactor/mqtt-interface-remove-inheritance*
- Faire la MR
**** IN-PROGRESS SmartSense: Ajouter *NodeManager*
- Idée est d'avoir un module qui se charge
  - Du provisioning
  - Des commandes ciblant le noeud entier
- Permet de démêler le code de *MainApp* du code du noeud
  - Et le routing des messages de leur traitement
**** IN-PROGRESS SmartSense: Intégrer la branche *refactor/naming-conventions*
- Préparer la MR, en attendant l'intégration de *refactor/main-app*
**** IN-PROGRESS SmartSense: Traiter les problèmes relevés lors de l'uniformisation du code
- J'ai noté plusieurs points problématiques au cours de mon passage sur l'ensemble des modules
  - Le module *sensor_board* est inutilisé
    - Code obsolète à supprimer ?
  - La librairie *telnetlib* est dépréciée
    - Passer à https://pypi.org/project/telnetlib3/ ?
  - Une conditionnelle étrange est effectuée dans le module *tlc59108_manager*
    - https://gitlab.inria.fr/smartsense/3douest/node-app/smartsense-node-app/-/blob/3feb5c56dc5e74dcea9eb2f2ba98bec40029acdf/TLC59108Manager.py#L370
    - Revient à `if data[0]`
    - `and` est-il l'opérateur désiré ?
    - Simplifier/corriger
  - Les appels à *OpenOCDManager.update()* dans *test_ocd* manquent d'un paramètre
    - J'ai l'impression que c'est le paramètre *board*
    - Ajouter les valeurs correctes ?
  - *USBBoardManager.read_data()* et *parse_to_mqtt()* sont particulièrement sujets aux retours de Pylint
    - Trop d'instructions
    - Trop de branchements
    - Trop de blocs imbriqués
    - Refactorer pour améliorer la lisibilité du code ?
    - Voir si on peut aussi factoriser du code à l'aide de fonctions
  - Corriger ces problèmes
    - Ou si pas de solution claire et rapide, créer une issue correspondante
**** IN-PROGRESS SmartSense: Monitorer l'instance locale d'InfluxDB
- Maintenant que j'ai revert le workaround
- Le problème rencontré autrefois devrait se reproduire
- Monitorer l'exécution de l'application pour détecter et identifier le problème rencontré
*** Done
- SmartSense: Revert la version de l'application à avant le workaround pour InfluxDB
  - Création d'un backup de l'application dans /home/pi/backupApp
  - Stop de l'application
    - systemctl stop mainApp
  - Suppression des DBs
    - DROP DATABASE SensorData
  - Petit doute sur le comportement de l'application à propos de collectd
  - Qu'est-ce qui se passe si la BD n'existe pas au lancement de l'application
  - Dans le doute
    - DROP DATABASE collectd
  - À la réflexion, rien à voir avec l'application dans cette version
  - J'ai en effet pu constater que les writes échouaient
  - Recréation de la DB
    - CREATE DATABASE collectd
  - Récupération du code source à l'état désiré et transfert
    - git checkout 29a50461
    - scp DataToLocalInfluxDB.py  pi@192.168.1.2:/home/pi
    - sudo mv DataToLocalInfluxDB.py /home/root/App (sur rpi)
  - Redémarrage de l'application
    - systemctl start mainApp
  - Plus qu'à attendre l'erreur
- SmartSense: État du noeud au <2024-02-19 Mon>
  - Avec mes jours de télétravail, je me retrouve avec le noeud qui a tourné durant ~1 semaine
  - Semblerait qu'aucun bug particulier ne se soit produit pendant ce temps
    - [[file:img/2024-02-19-smartsense-node-uptime-1-week.png]]
  - A bien quelques erreurs loggées, mais concernent le parsing de trame MQTT
    - [[file:img/2024-02-19-smartsense-node-errors-parsing-data.png]]
  - Le workaround a l'air d'être efficace
- SmartSense: Intégrer la branche *refactor/naming-conventions
  - MR préparée
- SmartSense: Traiter les problèmes relevés lors de l'uniformisation du code
  - Module `sensor_board` inutilisé
    - J'ai posé la question à Mickaël, à voir s'il sait quelque chose à ce sujet
  - `USBBoardManager.read_data()` et `parse_to_mqtt()`
    - Décomposition de `read_data()` en plusieurs méthodes
      - `handle_incoming_msgs()`, qui correspond au traitement des messages en entrée du module
        - Commande stop/start/timestamp et message MQTT
        - Quelle différence de nature entre les deux types de message?
- SmartSense: Monitorer l'instance locale d'InfluxDB
  - Suis les logs des services de l'application et d'InfluxDB
    - journalctl -f -u mainApp/influxdb
  - Et les performances systèmes (htop)
  - A vu un pic de consommation mémoire
    - Passé de 300Mo de RAM à 850Mo
      - Sature presque les 923Mo du noeud
    - Swap quant à lui saturé (100Mo)
  - La consommation mémoire est retombée ensuite
    - 350Mo
  - Mais pas le swap
  - Pas de logs particuliers côté mainApp à ce moment
  - Par contre, niveau influxdb, on a :
    #+BEGIN_PLAIN
mai 13 21:24:54 raspberrypi influxd[435]: ts=2023-05-13T19:24:54.806599Z lvl=info msg="Cache snapshot (start)" log_id=0hdK~cBG000 engine=tsm1 trace_id=0hme0UaW000 op_name=tsm1_cache_snapshot op_event=start
mai 13 21:24:56 raspberrypi influxd[435]: ts=2023-05-13T19:24:56.780813Z lvl=info msg="Snapshot for path written" log_id=0hdK~cBG000 engine=tsm1 trace_id=0hme0UaW000 op_name=tsm1_cache_snapshot path=/data/influxdb/data/SensorData/autogen/706 duration=1974.300ms
mai 13 21:24:56 raspberrypi influxd[435]: ts=2023-05-13T19:24:56.781155Z lvl=info msg="Cache snapshot (end)" log_id=0hdK~cBG000 engine=tsm1 trace_id=0hme0UaW000 op_name=tsm1_cache_snapshot op_event=end op_elapsed=1974.582ms
mai 13 21:24:56 raspberrypi influxd[435]: ts=2023-05-13T19:24:56.807596Z lvl=info msg="TSM compaction (start)" log_id=0hdK~cBG000 engine=tsm1 tsm1_level=1 tsm1_strategy=level trace_id=0hme0bPl000 op_name=tsm1_compact_group op_event=start
mai 13 21:24:56 raspberrypi influxd[435]: ts=2023-05-13T19:24:56.807735Z lvl=info msg="Beginning compaction" log_id=0hdK~cBG000 engine=tsm1 tsm1_level=1 tsm1_strategy=level trace_id=0hme0bPl000 op_name=tsm1_compact_group tsm1_files_n=8
mai 13 21:24:56 raspberrypi influxd[435]: ts=2023-05-13T19:24:56.807794Z lvl=info msg="Compacting file" log_id=0hdK~cBG000 engine=tsm1 tsm1_level=1 tsm1_strategy=level trace_id=0hme0bPl000 op_name=tsm1_compact_group tsm1_index=0 tsm1_file=/data/influxdb/data/SensorData/autogen/706/000000009-000000001.tsm
mai 13 21:24:56 raspberrypi influxd[435]: ts=2023-05-13T19:24:56.807853Z lvl=info msg="Compacting file" log_id=0hdK~cBG000 engine=tsm1 tsm1_level=1 tsm1_strategy=level trace_id=0hme0bPl000 op_name=tsm1_compact_group tsm1_index=1 tsm1_file=/data/influxdb/data/SensorData/autogen/706/000000010-000000001.tsm
mai 13 21:24:56 raspberrypi influxd[435]: ts=2023-05-13T19:24:56.807914Z lvl=info msg="Compacting file" log_id=0hdK~cBG000 engine=tsm1 tsm1_level=1 tsm1_strategy=level trace_id=0hme0bPl000 op_name=tsm1_compact_group tsm1_index=2 tsm1_file=/data/influxdb/data/SensorData/autogen/706/000000011-000000001.tsm
mai 13 21:24:56 raspberrypi influxd[435]: ts=2023-05-13T19:24:56.807970Z lvl=info msg="Compacting file" log_id=0hdK~cBG000 engine=tsm1 tsm1_level=1 tsm1_strategy=level trace_id=0hme0bPl000 op_name=tsm1_compact_group tsm1_index=3 tsm1_file=/data/influxdb/data/SensorData/autogen/706/000000012-000000001.tsm
mai 13 21:24:56 raspberrypi influxd[435]: ts=2023-05-13T19:24:56.808027Z lvl=info msg="Compacting file" log_id=0hdK~cBG000 engine=tsm1 tsm1_level=1 tsm1_strategy=level trace_id=0hme0bPl000 op_name=tsm1_compact_group tsm1_index=4 tsm1_file=/data/influxdb/data/SensorData/autogen/706/000000013-000000001.tsm
mai 13 21:24:56 raspberrypi influxd[435]: ts=2023-05-13T19:24:56.808082Z lvl=info msg="Compacting file" log_id=0hdK~cBG000 engine=tsm1 tsm1_level=1 tsm1_strategy=level trace_id=0hme0bPl000 op_name=tsm1_compact_group tsm1_index=5 tsm1_file=/data/influxdb/data/SensorData/autogen/706/000000014-000000001.tsm
mai 13 21:24:56 raspberrypi influxd[435]: ts=2023-05-13T19:24:56.808140Z lvl=info msg="Compacting file" log_id=0hdK~cBG000 engine=tsm1 tsm1_level=1 tsm1_strategy=level trace_id=0hme0bPl000 op_name=tsm1_compact_group tsm1_index=6 tsm1_file=/data/influxdb/data/SensorData/autogen/706/000000015-000000001.tsm
mai 13 21:24:56 raspberrypi influxd[435]: ts=2023-05-13T19:24:56.808196Z lvl=info msg="Compacting file" log_id=0hdK~cBG000 engine=tsm1 tsm1_level=1 tsm1_strategy=level trace_id=0hme0bPl000 op_name=tsm1_compact_group tsm1_index=7 tsm1_file=/data/influxdb/data/SensorData/autogen/706/000000016-000000001.tsm
mai 13 21:24:58 raspberrypi influxd[435]: [httpd] ::1 - admin [13/May/2023:21:24:58 +0200] "POST /write?db=SensorData HTTP/1.1" 204 0 "-" "python-requests/2.21.0" d985282a-f1c3-11ed-8a7e-000000000000 33756
mai 13 21:25:05 raspberrypi influxd[435]: [httpd] ::1 - admin [13/May/2023:21:25:03 +0200] "POST /write?db=SensorData HTTP/1.1" 204 0 "-" "python-requests/2.21.0" dc24e767-f1c3-11ed-8a7f-000000000000 2189585
mai 13 21:25:07 raspberrypi influxd[435]: [httpd] ::1 - admin [13/May/2023:21:25:07 +0200] "POST /write?db=SensorData HTTP/1.1" 204 0 "-" "python-requests/2.21.0" de7238fe-f1c3-11ed-8a80-000000000000 58013
mai 13 21:25:11 raspberrypi influxd[435]: [httpd] ::1 - admin [13/May/2023:21:25:11 +0200] "POST /write?db=SensorData HTTP/1.1" 204 0 "-" "python-requests/2.21.0" e0eb72bc-f1c3-11ed-8a81-000000000000 417895
mai 13 21:25:16 raspberrypi influxd[435]: [httpd] ::1 - admin [13/May/2023:21:25:16 +0200] "POST /write?db=SensorData HTTP/1.1" 204 0 "-" "python-requests/2.21.0" e3fdf960-f1c3-11ed-8a82-000000000000 360349
mai 13 21:25:19 raspberrypi influxd[435]: [httpd] ::1 - admin [13/May/2023:21:25:19 +0200] "POST /write?db=SensorData HTTP/1.1" 204 0 "-" "python-requests/2.21.0" e5fceda3-f1c3-11ed-8a83-000000000000 138687
mai 13 21:25:24 raspberrypi influxd[435]: [httpd] ::1 - admin [13/May/2023:21:25:24 +0200] "POST /write?db=SensorData HTTP/1.1" 204 0 "-" "python-requests/2.21.0" e8815e7b-f1c3-11ed-8a84-000000000000 157898
mai 13 21:25:28 raspberrypi influxd[435]: ts=2023-05-13T19:25:28.295225Z lvl=info msg="Compacted file" log_id=0hdK~cBG000 engine=tsm1 tsm1_level=1 tsm1_strategy=level trace_id=0hme0bPl000 op_name=tsm1_compact_group tsm1_index=0 tsm1_file=/data/influxdb/data/SensorData/autogen/706/000000016-000000002.tsm.tmp
mai 13 21:25:28 raspberrypi influxd[435]: ts=2023-05-13T19:25:28.320221Z lvl=info msg="Finished compacting files" log_id=0hdK~cBG000 engine=tsm1 tsm1_level=1 tsm1_strategy=level trace_id=0hme0bPl000 op_name=tsm1_compact_group tsm1_files_n=1
mai 13 21:25:28 raspberrypi influxd[435]: ts=2023-05-13T19:25:28.320331Z lvl=info msg="TSM compaction (end)" log_id=0hdK~cBG000 engine=tsm1 tsm1_level=1 tsm1_strategy=level trace_id=0hme0bPl000 op_name=tsm1_compact_group op_event=end op_elapsed=31512.756ms
    #+END_PLAIN
  - A bien l'air de correspondre au mécanisme de compression d'InfluxDB
    - Voir s'il est désactivable
    - Voir s'il est nécessaire
  - Augmentation de la RAM de ~70Mo
    - Dûe à un mécanisme de cache d'InfluxDB
      #+BEGIN_PLAIN
mai 13 21:44:49 raspberrypi influxd[435]: ts=2023-05-13T19:44:49.815468Z lvl=info msg="Cache snapshot (start)" log_id=0hdK~cBG000 engine=tsm1 trace_id=0hmf9Qal000 op_name=tsm1_cache_snapshot op_event=start
mai 13 21:44:51 raspberrypi influxd[435]: ts=2023-05-13T19:44:51.828599Z lvl=info msg="Snapshot for path written" log_id=0hdK~cBG000 engine=tsm1 trace_id=0hmf9Qal000 op_name=tsm1_cache_snapshot path=/data/influxdb/data/SensorData/autogen/706 duration=2014.542ms
mai 13 21:44:51 raspberrypi influxd[435]: ts=2023-05-13T19:44:51.841164Z lvl=info msg="Cache snapshot (end)" log_id=0hdK~cBG000 engine=tsm1 trace_id=0hmf9Qal000 op_name=tsm1_cache_snapshot op_event=end op_elapsed=2025.725ms
      #+END_PLAIN
  - RAM revient à sa valeur d'origine au bout d'un moment
  - Ça a enfin explosé à 16h50
  - La base de données crash au cours de sa compaction
    #+BEGIN_PLAIN
mai 14 00:02:08 raspberrypi influxd[435]: [httpd] ::1 - admin [14/May/2023:00:02:08 +0200] "POST /write?db=SensorData HTTP/1.1" 204 0 "-" "python-requests/2.21.0" ce13ecf6-f1d9-11ed-9349-000000000000 47503
mai 14 00:02:12 raspberrypi influxd[435]: [httpd] ::1 - admin [14/May/2023:00:02:12 +0200] "POST /write?db=SensorData HTTP/1.1" 204 0 "-" "python-requests/2.21.0" d0877f75-f1d9-11ed-934a-000000000000 42272
mai 14 00:02:16 raspberrypi influxd[435]: [httpd] ::1 - admin [14/May/2023:00:02:16 +0200] "POST /write?db=SensorData HTTP/1.1" 204 0 "-" "python-requests/2.21.0" d30c972d-f1d9-11ed-934b-000000000000 29123
mai 14 00:02:21 raspberrypi influxd[435]: [httpd] ::1 - admin [14/May/2023:00:02:21 +0200] "POST /write?db=SensorData HTTP/1.1" 204 0 "-" "python-requests/2.21.0" d5ae5268-f1d9-11ed-934c-000000000000 53104
mai 14 00:02:21 raspberrypi influxd[435]: ts=2023-05-13T22:02:21.806703Z lvl=info msg="Cache snapshot (start)" log_id=0hdK~cBG000 engine=tsm1 trace_id=0hmn14wW000 op_name=tsm1_cache_snapshot op_event=start
mai 14 00:02:23 raspberrypi influxd[435]: ts=2023-05-13T22:02:23.767757Z lvl=info msg="Snapshot for path written" log_id=0hdK~cBG000 engine=tsm1 trace_id=0hmn14wW000 op_name=tsm1_cache_snapshot path=/data/influxdb/data/SensorData/autogen/706 duration=1961.160ms
mai 14 00:02:23 raspberrypi influxd[435]: ts=2023-05-13T22:02:23.768046Z lvl=info msg="Cache snapshot (end)" log_id=0hdK~cBG000 engine=tsm1 trace_id=0hmn14wW000 op_name=tsm1_cache_snapshot op_event=end op_elapsed=1961.412ms
mai 14 00:02:23 raspberrypi influxd[435]: ts=2023-05-13T22:02:23.807542Z lvl=info msg="TSM compaction (start)" log_id=0hdK~cBG000 engine=tsm1 tsm1_level=1 tsm1_strategy=level trace_id=0hmn1Ckl000 op_name=tsm1_compact_group op_event=start
mai 14 00:02:23 raspberrypi influxd[435]: ts=2023-05-13T22:02:23.807708Z lvl=info msg="Beginning compaction" log_id=0hdK~cBG000 engine=tsm1 tsm1_level=1 tsm1_strategy=level trace_id=0hmn1Ckl000 op_name=tsm1_compact_group tsm1_files_n=8
mai 14 00:02:23 raspberrypi influxd[435]: ts=2023-05-13T22:02:23.807755Z lvl=info msg="Compacting file" log_id=0hdK~cBG000 engine=tsm1 tsm1_level=1 tsm1_strategy=level trace_id=0hmn1Ckl000 op_name=tsm1_compact_group tsm1_index=0 tsm1_file=/data/influxdb/data/SensorData/autogen/706/000000017-000000001.tsm
mai 14 00:02:23 raspberrypi influxd[435]: ts=2023-05-13T22:02:23.807809Z lvl=info msg="Compacting file" log_id=0hdK~cBG000 engine=tsm1 tsm1_level=1 tsm1_strategy=level trace_id=0hmn1Ckl000 op_name=tsm1_compact_group tsm1_index=1 tsm1_file=/data/influxdb/data/SensorData/autogen/706/000000018-000000001.tsm
mai 14 00:02:23 raspberrypi influxd[435]: ts=2023-05-13T22:02:23.807861Z lvl=info msg="Compacting file" log_id=0hdK~cBG000 engine=tsm1 tsm1_level=1 tsm1_strategy=level trace_id=0hmn1Ckl000 op_name=tsm1_compact_group tsm1_index=2 tsm1_file=/data/influxdb/data/SensorData/autogen/706/000000019-000000001.tsm
mai 14 00:02:23 raspberrypi influxd[435]: ts=2023-05-13T22:02:23.807911Z lvl=info msg="Compacting file" log_id=0hdK~cBG000 engine=tsm1 tsm1_level=1 tsm1_strategy=level trace_id=0hmn1Ckl000 op_name=tsm1_compact_group tsm1_index=3 tsm1_file=/data/influxdb/data/SensorData/autogen/706/000000020-000000001.tsm
mai 14 00:02:23 raspberrypi influxd[435]: ts=2023-05-13T22:02:23.807960Z lvl=info msg="Compacting file" log_id=0hdK~cBG000 engine=tsm1 tsm1_level=1 tsm1_strategy=level trace_id=0hmn1Ckl000 op_name=tsm1_compact_group tsm1_index=4 tsm1_file=/data/influxdb/data/SensorData/autogen/706/000000021-000000001.tsm
mai 14 00:02:23 raspberrypi influxd[435]: ts=2023-05-13T22:02:23.808011Z lvl=info msg="Compacting file" log_id=0hdK~cBG000 engine=tsm1 tsm1_level=1 tsm1_strategy=level trace_id=0hmn1Ckl000 op_name=tsm1_compact_group tsm1_index=5 tsm1_file=/data/influxdb/data/SensorData/autogen/706/000000022-000000001.tsm
mai 14 00:02:23 raspberrypi influxd[435]: ts=2023-05-13T22:02:23.808061Z lvl=info msg="Compacting file" log_id=0hdK~cBG000 engine=tsm1 tsm1_level=1 tsm1_strategy=level trace_id=0hmn1Ckl000 op_name=tsm1_compact_group tsm1_index=6 tsm1_file=/data/influxdb/data/SensorData/autogen/706/000000023-000000001.tsm
mai 14 00:02:23 raspberrypi influxd[435]: ts=2023-05-13T22:02:23.808110Z lvl=info msg="Compacting file" log_id=0hdK~cBG000 engine=tsm1 tsm1_level=1 tsm1_strategy=level trace_id=0hmn1Ckl000 op_name=tsm1_compact_group tsm1_index=7 tsm1_file=/data/influxdb/data/SensorData/autogen/706/000000024-000000001.tsm
mai 14 00:02:25 raspberrypi influxd[435]: [httpd] ::1 - admin [14/May/2023:00:02:25 +0200] "POST /write?db=SensorData HTTP/1.1" 204 0 "-" "python-requests/2.21.0" d805ca3e-f1d9-11ed-934d-000000000000 33651
mai 14 00:02:34 raspberrypi systemd[1]: influxdb.service: Main process exited, code=killed, status=9/KILL
mai 14 00:02:34 raspberrypi systemd[1]: influxdb.service: Failed with result 'signal'.
    #+END_PLAIN
  - Pendant ce temps, mainApp essaie d'enregistrer ses données et rencontre une erreur
    #+BEGIN_PLAIN
mai 14 00:02:25 raspberrypi mainApp.py[2526]: [DataToLocalInfluxDB] : write_points 100
mai 14 00:02:38 raspberrypi mainApp.py[2526]: [DataToLocalInfluxDB] : data not saved, timeout ! HTTPConnectionPool(host='localhost', port=8086): Max retries exceeded with url: /write?db=SensorData (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x74bc8350>: Failed to establish a new connection: [Errno 111] Connection refused'))
mai 14 00:02:38 raspberrypi mainApp.py[2526]: [DataToLocalInfluxDB] : data not saved, timeout ! HTTPConnectionPool(host='localhost', port=8086): Max retries exceeded with url: /write?db=SensorData (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x74bc88f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
mai 14 00:02:38 raspberrypi mainApp.py[2526]: [DataToLocalInfluxDB] : data not saved, timeout ! HTTPConnectionPool(host='localhost', port=8086): Max retries exceeded with url: /write?db=SensorData (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x74be50b0>: Failed to establish a new connection: [Errno 111] Connection refused'))
mai 14 00:02:38 raspberrypi mainApp.py[2526]: [DataToLocalInfluxDB] : data not saved, timeout ! HTTPConnectionPool(host='localhost', port=8086): Max retries exceeded with url: /write?db=SensorData (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x74bc8d10>: Failed to establish a new connection: [Errno 111] Connection refused'))
mai 14 00:02:38 raspberrypi mainApp.py[2526]: [DataToLocalInfluxDB] : data not saved, timeout ! HTTPConnectionPool(host='localhost', port=8086): Max retries exceeded with url: /write?db=SensorData (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x74bc84f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
mai 14 00:02:38 raspberrypi mainApp.py[2526]: [DataToLocalInfluxDB] : data not saved, timeout ! HTTPConnectionPool(host='localhost', port=8086): Max retries exceeded with url: /write?db=SensorData (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x74bc83b0>: Failed to establish a new connection: [Errno 111] Connection refused'))
mai 14 00:02:38 raspberrypi mainApp.py[2526]: [DataToLocalInfluxDB] : data not saved, timeout ! HTTPConnectionPool(host='localhost', port=8086): Max retries exceeded with url: /write?db=SensorData (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x74be5510>: Failed to establish a new connection: [Errno 111] Connection refused'))
mai 14 00:02:38 raspberrypi mainApp.py[2526]: [DataToLocalInfluxDB] : data not saved, timeout ! HTTPConnectionPool(host='localhost', port=8086): Max retries exceeded with url: /write?db=SensorData (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x74be5b10>: Failed to establish a new connection: [Errno 111] Connection refused'))
mai 14 00:02:38 raspberrypi mainApp.py[2526]: [DataToLocalInfluxDB] : data not saved, timeout ! HTTPConnectionPool(host='localhost', port=8086): Max retries exceeded with url: /write?db=SensorData (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x74bc81f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
mai 14 00:02:38 raspberrypi mainApp.py[2526]: [DataToLocalInfluxDB] : data not saved, timeout ! HTTPConnectionPool(host='localhost', port=8086): Max retries exceeded with url: /write?db=SensorData (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x74bc88b0>: Failed to establish a new connection: [Errno 111] Connection refused'))
mai 14 00:02:38 raspberrypi mainApp.py[2526]: [DataToLocalInfluxDB] : data not saved, timeout ! HTTPConnectionPool(host='localhost', port=8086): Max retries exceeded with url: /write?db=SensorData (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x74be5ab0>: Failed to establish a new connection: [Errno 111] Connection refused'))
mai 14 00:02:38 raspberrypi mainApp.py[2526]: [DataToLocalInfluxDB] : data not saved, timeout ! HTTPConnectionPool(host='localhost', port=8086): Max retries exceeded with url: /write?db=SensorData (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x74be5690>: Failed to establish a new connection: [Errno 111] Connection refused'))
mai 14 00:02:38 raspberrypi mainApp.py[2526]: [DataToLocalInfluxDB] : data not saved, timeout ! HTTPConnectionPool(host='localhost', port=8086): Max retries exceeded with url: /write?db=SensorData (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x74be53f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
mai 14 00:02:38 raspberrypi mainApp.py[2526]: [DataToLocalInfluxDB] : data not saved, timeout ! HTTPConnectionPool(host='localhost', port=8086): Max retries exceeded with url: /write?db=SensorData (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x74bc8f50>: Failed to establish a new connection: [Errno 111] Connection refused'))
mai 14 00:02:38 raspberrypi mainApp.py[2526]: [DataToLocalInfluxDB] : data not saved, timeout ! HTTPConnectionPool(host='localhost', port=8086): Max retries exceeded with url: /write?db=SensorData (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x74bc8730>: Failed to establish a new connection: [Errno 111] Connection refused'))
    #+END_PLAIN
  - Au bout d'un moment, la BDD redémarre automatiquement et réaccepte les requêtes
    - Voir [[file:logs/2024-02-19-crash-influxdb.log]], lignes 24-112
  - MainApp arrive alors à enregistrer ses données
    - [[file:logs/2024-02-19-crash-main-app.log]], lignes 445-449
  - J'ai récup les graphiques de Grafana au moment du crash
    - Sensor Data
      - [[file:img/2024-02-19-crash-grafana-sensor-data-part-1.png]]
      - [[file:img/2024-02-19-crash-grafana-sensor-data-part-2.png]]
    - Hardware Monitoring
      - [[file:img/2024-02-19-crash-grafana-hardware-monitoring-part-1.png]]
      - [[file:img/2024-02-19-crash-grafana-hardware-monitoring-part-2.png]]
  - Observe tout de même une perte de données à cette période
    - Pour quelle(s) raison(s) ?
  - À la réflexion, les courbes concernant les métriques systèmes sont étranges
    - Le pic de consommation est montré à 00:03:00, i.e. après le redémarrage d'influxdb et le lancement d'une nouvelle compaction
    - Rien de particulier n'apparaît à 00:02:20, lors de la compaction initiale, et à 00:02:30, lors du kill d'influxdb
  - P-e que le fait que grafana se base sur les données stockées par influxdb a un lien
    - Si influxdb était en train de planter à ce moment là
    - N'a pas pu enregistrer les données collectées par collectd
      - Pas sûr que le support de collectd par influxdb intègre un mécanisme de bufferisation des écritures
    - Les courbes montrées se basent-elles donc sur des données ou font-elles de l'interpolation ?
      - L'interpolation expliquerait l'absence de pic
  - Mickaël me faisait part de sa surprise que l'application redémarre normalement
  - Mais à la réflexion, j'ai p-e eu de la chance sur ce coup-ci
  - Influxdb redémarre et retente d'effectuer une compaction
    - Ici c'est passé
  - Mais possible que cette nouvelle compaction fasse de nouveau planter influxdb
  - Tomberait alors dans une boucle de crashs
  - Voir pour poursuivre/reproduire l'expérience si on peut observer cette boucle de crashs
- SmartSense: Identifier les paramètres de configuration d'InfluxDB pertinents pour la compaction
  - max-concurrent-compactions
    - https://docs.influxdata.com/influxdb/v1/administration/config/#max-concurrent-compactions--0
    - Par défaut, utilise jusqu'à 50% du CPU lors d'une compaction
    - Limiter à 1 ?
  - compact-throughput
    - https://docs.influxdata.com/influxdb/v1/administration/config/#compact-throughput--48m
    - Quantité de données écrites sur le disk par seconde lors d'une compaction
    - Par défaut, 48m = 48Mo/s
    - Me paraît raisonnable
  - compact-throughput-burst
    - https://docs.influxdata.com/influxdb/v1/administration/config/#compact-throughput-burst--48m
    - Pas sûr de comprendre la diff avec l'option précédente
    - Par défaut, 48m = 48Mo/s
  - max-index-log-file-size
    - https://docs.influxdata.com/influxdb/v1/administration/config/#max-index-log-file-size--1m
    - A l'air de correspondre à la taille limite du WAL afin qu'il soit clos, compacté et intégré à l'index
    - Indique que diminuer cette taille limite entrainera des compactions moins coûteuses mais plus fréquentes, et impactant le débit en écriture
    - Mais par défaut, 1m = 1Mo
    - Me paraît pas bien grand
    - Je suppose que c'est pas cette partie là du mécanisme de compression qui impacte et fait crasher influxdb
  - Aparté
    - Alors pas pertinent par rapport au problème actuel
    - Mais serait intéressant de vérifier les paramètres vis-à-vis de la rétention de données
    - retention.enabled
      - https://docs.influxdata.com/influxdb/v1/administration/config/#enabled--true
      - Par défaut activé
    - meta.retention_autocreate
      - https://docs.influxdata.com/influxdb/v1/administration/config/#retention-autocreate--true
      - Par défaut activé
      - Créé une *retention policy* autogen qui
        - Conserve indéfiniment les données
        - Replication factor de 1
        - Et une *shard group duration* de 7j
      - avec *shard*
        - Fichier TSM qui contient les données d'un ensemble donné de *serie* sur un interval de temps donné
        - avec *serie*, ensemble de *points* avec le même *measurement*, les mêmes *tags*, et les mêmes *field keys*
      - *shard group*
        - Ensemble de *shards* sur un interval de temps donné
      - et donc *shard group duration*
        - Interval de temps représenté/géré par un *shard group*
        - Tous les points de cette période seront donc stockés au sein de ce *shard group*
  - Donc finalement, la *retention policy* est p-e un paramètre sur lequel on peut jouer
    - En diminuant la *shard group duration*, par défaut 1 semaine, à une granularité plus fine, e.g. 4h
      - Sachant que la valeur minimale est 1h
    - Forcerait la création de nouveaux *shards* régulièrement
    - Donc *shards* plus petits
    - Et permettrait p-e de lisser les compactions
    - Notamment en combinaison de data.compact-full-write-cold-duration
      - https://docs.influxdata.com/influxdb/v1/administration/config/#compact-full-write-cold-duration--4h
      - Qui déclenche une compaction sur un shard non-modifié depuis 4h
      - On pourrait donc "forcer" la création et la compaction régulière de nouveaux shards
    - Reste à voir l'impact de la multiplication des shards
    - Tombe sur ces recommandations : https://docs.influxdata.com/influxdb/v1/concepts/schema_and_data_layout/#shard-group-duration-recommendations
      - 100k points par shard group
      - 1000 points par série
    - Dans notre cas, on a une 30aine de séries régulières
    - Nous suffit donc "que" de 3k points par série pour atteindre ces quotas
    - Voir la fréquence d'échantillonage, mais je suppose qu'on fait plusieurs mesures par seconde
  - Suis tombé sinon sur https://docs.influxdata.com/influxdb/v1/concepts/tsi-details/#important-compaction-configuration-settings
    - Ne met rien de nouveau en lumière
    - Le commentaire suivant n'est pas rassurant
      #+BEGIN_QUOTE
These configuration settings are especially beneficial for systems with irregular loads,
limiting compactions during periods of high usage, and letting compactions catch up during periods of lower load.
In systems with stable loads, if compactions interfere with other operations, typically,
the system is undersized for its load, and configuration changes won’t help much.
      #+END_QUOTE
  - Conclusion
    - Set max-concurrent-compactions à 1 pour déterminer si cela suffit
    - Sinon
      - Modifier la retention policy autogen
        - ALTER RETENTION POLICY "autogen" ON "Sensor Data" SHARD DURATION 4h
        - ALTER RETENTION POLICY "autogen" ON "collectd" SHARD DURATION 4h
      - Et set compact-full-write-cold-duration à 4h
** Semaine du <2024-02-12 Mon> au <2024-02-16 Fri>
*** Planned
**** DONE SmartSense: Self provision *InaManager* et *TlcManager*
CLOSED: [2024-02-13 Tue 17:00]
- À l'heure actuelle, on a un comportement étrange
- Le noeud sait, qu'en fonction de la configuration, il doit se self provision ou non
- Mais pas *InaManager* et *TlcManager*
- C'est lorsque leurs messages remontent à son niveau que le noeud les interceptent et y répond à la place du serveur
- Me paraît plus clair et simple d'avoir les différents modules qui se chargent eux-mêmes de leur self provisioning
**** DONE SmartSense: Mettre en place des *Factory* pour les *Manager*
CLOSED: [2024-02-14 Wed 16:59]
- Les objets *Manager* sont des objets un minimum complexe
- Potentiellement avec plusieurs configurations, en fonction du comportement voulu
  - Je pense à toi *MqttInterface*
- L'utilisation de *Factory* permettrait de préparer le terrain pour de l'injection de dépendances
- D'expliciter les paramètres requis pour chaque *Manager*
  - Au lieu de les avoir éparpillés dans le constructeur et dans la méthode executée lors du lancement du process
- Et permettrait aussi de déléguer l'instanciation des *Queue*
**** DONE SmartSense: Ajouter des tests pour *MainApp.handleProvisioningMsg()*
CLOSED: [2024-02-14 Wed 16:59]
- Vérifier le bon fonctionnement de cette méthode
- Me paraît un bon point d'entrée pour mettre en place des tests pour *MainApp*
**** DONE SmartSense: Rework *MainApp* pour permettre la mise en place de tests
CLOSED: [2024-02-15 Thu 14:08]
- En essayant de mettre en place des tests, j'ai rencontré le problème suivant
- *MainApp* instancie tous les composants de l'application, notamment ceux qui interagissent avec le hardware
- Empêche donc l'exécution de tests, même si c'est pour une méthode n'interagissant pas avec cette partie de l'application
  - Au hasard, *MainApp.handleProvisioningMsg()*
- Plusieurs pistes pour corriger ce problème
  - Mise en place d'injections de dépendances
    - Un framework à utiliser ?
  - Décomposition de *MainApp* en modules
    - Mais comment ?
  - Combinaison des deux
**** DONE SmartSense: Intégrer la branche *refactor/split-mqtt-interface*
CLOSED: [2024-02-15 Thu 14:08]
- Maintenant que la branche *feat/autonomous-node-and-add-tools* a été intégrée
- Peut commencer à intégrer les modifications dans mon backlog
- MàJ la branche *refactor/split-mqtt-interface* par rapport à *main*
- Faire la MR
**** DONE SmartSense: Mettre en place les conventions de nommage
CLOSED: [2024-02-16 Fri 16:44]
- Le projet n'a pas adopté initialement les conventions de nommage de Python
- Les avertissements de Pylint sur les morceaux de code complexes et conseils sur comment les retravailler se retrouvent donc noyés
- Afin d'éviter cela, j'ai adopté les conventions Python pour les nouveaux modules que j'ai défini
- On se retrouve donc avec un micmac de conventions dans le projet
- Modifier la base existante pour adopter les conventions Python
**** IN-PROGRESS SmartSense: Intégrer la branche *refactor/mqtt-interface-remove-inheritance*
- Je voulais pas forcément intégrer cette modif
- Mais une bonne partie des commits de *refactor/main-app* modifient des lignes concernées par ces changements
- Je me retrouve avec des conflits fréquemment lorsque j'essaie de rebase en le retirant de l'historique
- Me parait plus safe, et préférable, d'intégrer ces changements
**** IN-PROGRESS SmartSense: Intégrer la branche *refactor/main-app*
- MàJ par rapport à *refactor/mqtt-interface-remove-inheritance*
- Faire la MR
**** IN-PROGRESS SmartSense: Ajouter *NodeManager*
- Idée est d'avoir un module qui se charge
  - Du provisioning
  - Des commandes ciblant le noeud entier
- Permet de démêler le code de *MainApp* du code du noeud
  - Et le routing des messages de leur traitement
*** Done
- SmartSense: Rework *MainApp* pour permettre la mise en place de tests
  - Plusieurs tentatives de décomposition de *MainApp* en modules
  - *MessageManager*
    - À partir des queues de message des différents process
      - In et Out
    - Route les messages
      - Récupère de *MainApp* les méthodes suivantes
        - *route_incoming_message()*
        - *read_msg()*, l'équivalent du main
        - *publish_msg()*
    - Difficultés
      - Quid de *handle_cmd_msg()* ?
        - Pour certaines commandes, on délègue au module correspondant, i.e. on forward le message au bon module
        - Mais pour d'autres, on effectue directement des actions, e.g. la commande "restart"
        - Cela nécessite d'interagir (appels de fonctions) directement avec le module concerné
        - Comment gérer cela ?
      - Quid du provisioning ?
        - Est-ce qu'on déplace la logique du provisioning dans ce module ?
        - D'un côté, me paraît pas trop déconnant vu qu'on utilise le locationPath pour router les messages notamment sortant
        - Mais de l'autre, que ça soit le ce module qui soit à l'initiative du message de provisioning et qui intègre une logique d'attente me paraît étrange
  - *ProcessManager*
  - Idées
    - Ajout d'un module *NodeManager*
      - Pour le moment, le comportement du noeud et de *Main* sont confondus
      - D'où le fait que le *MessageManager* doive effectuer des actions lorsqu'il s'aperçoit qu'un message, e.g. une commande, lui est destiné
      - Et qu'il communique à la fois par le biais de messages et d'appels de fonction avec ces objets
      - Ajouter un module dédié permettrait de découpler cette logique
      - *NodeManager* pourrait être en charge de
        - Se provisionner
        - Exécuter les commandes concernant le noeud, ou une board mais nécessitant un niveau d'indirection supplémentaire
        - La synchronisation des modules
      - Permettrait de découpler instanciation des différents modules et fonctionnement du noeud itself
    - Self-provisioning de chacun des modules
      - Pourquoi seul le noeud sait qu'il doit se self-provision ?
      - Et qu'on se retrouve à devoir gérer le provisioning des modules Ina et Tlc au niveau du routing des messages ?
      - Pourquoi ne pas indiquer aux modules concernés qu'ils doivent se self-provision ?
      - Directement passer cette information
- SmartSense: Ajouter *NodeManager*
  - J'ai commencé à faire cela
  - Mais je viens de me rendre compte d'un potentiel problème
  - À l'heure actuelle, les commandes sont exécutées par le process principal
  - L'ajout de *NodeManager* déplacerait leur exécution dans un nouveau process
  - Donc pendant que la commande s'exécute, d'autres commandes peuvent être récupérées par le process principal, envoyées à un module et traitées
  - Est-ce qu'on ne risque pas de rencontrer des problèmes de concurrence du coup ?
    - Genre un /updateFirmwareCmd/ en concurrence d'un /set meta/
  - Après, est-ce qu'on a pas déjà ces problèmes ?
  - À vérifier
- SmartSense: Ajouter des tests pour *MainApp.handleProvisioningMsg()*
  - Maintenant que j'ai mis en place des *Factory*, peut voir pour mock leur comportement dans les tests
  - Peut les mocker dans le cadre d'un test à l'aide de *unittest.mock.patch()*
  - *patch()* peut aussi mocker une classe carrément
  - En mockant *MqttInterface* et *INA219Manager*, arrive à instancier *MainApp*
  - Pas besoin des *Factory* du coup
  - Quoique, rencontre l'erreur habituelle quand essaie d'intégrer les tests sur l'état pré-factory
    - *patch()* n'a pas l'air d'avoir d'effet
    - Le constructeur de *INA219Manager* est bel et bien appelé
  - Peut reproduire le bug sur la branche avec factory en repassant sur un appel au constructeur plutôt qu'à la factory
  - Why?
  - Tout simplement parce que j'utilise mal *patch()*
    - https://docs.python.org/3/library/unittest.mock.html#where-to-patch
  - Doit pas patcher d'où vient l'objet, mais où est son utilisation
    - Donc patcher *MainApp.INA219Manager* et non pas *INA219Manager.INA219Manager*
    - Cela fonctionnait avec la factory car *INA219Manager.INA219Manager* correspondait bien au module où l'objet était utilisé
  - Correction des patchs
  - Ajout de tests en guise d'exemple
    - Directement dans la branche *refactor/main-app*
- SmartSense: Intégrer la branche *refactor/split-mqtt-interface*
  - Ajout des modifs demandées par Mickaël
  - Intégration de la branche
- SmartSense: Intégrer la branche *refactor/mqtt-interface-remove-inheritance*
  - Rebase sur la branche *main*
  - Intégration du commit qui ajoute *QualityOfService*
  - Création de la MR : https://gitlab.inria.fr/smartsense/3douest/node-app/smartsense-node-app/-/merge_requests/4
- SmartSense: Intégrer la branche *refactor/main-app*
  - Rebase sur la branche *refactor/mqtt-interface-remove-inheritance*
  - Modification au passage du type annoté pour *sector* et *sub_sector*
  - Préparation du draft de la MR
    - En attendant que *refactor/mqtt-interface-remove-inheritance* soit validée et intégrée
  - MR : https://gitlab.inria.fr/smartsense/3douest/node-app/smartsense-node-app/-/merge_requests/5
** Semaine du <2024-02-05 Mon> au <2024-02-09 Fri>
*** Planned
**** DONE SmartSense: Ajouter des tests pour *DataToLocalInfluxDB.parseMqtt()*
CLOSED: [2024-02-05 Mon 13:58]
- J'ai atteint la limite du refactoring que je peux faire dans le projet en ayant à peu près confiance
- Et n'ayant pas de précisions sur les évolutions à apporter
- Serait préférable de consolider les tests pour le moment
- Pour le moment, vérifie le bon fonctionnement de *parseMqtt()* avec un payload correct
- Vérifier pour d'autres payloads corrects
- Vérifier pour payload invalide
**** DONE SmartSense: Ajouter des tests pour l'instanciation de *DataToLocalInfluxDB*
CLOSED: [2024-02-05 Mon 14:35]
- Comment se comporte l'objet si la base de données est inaccessible ?
**** DONE SmartSense: Ajouter des tests pour l'instanciation de *MqttInterface*
CLOSED: [2024-02-05 Mon 15:13]
- Comment se comporte l'objet si le message broker est inaccessible ?
**** DONE SmartSense: Prendre en main le noeud SmartSense
CLOSED: [2024-02-07 Wed 08:21]
- J'ai récupéré via Guillermo le noeud autonome que m'a setup Mickaël
- Le brancher et se connecter dessus pour mieux comprendre son fonctionnement
**** DONE SmartSense: Intégrer les modifications effectuées à la branche *main*
CLOSED: [2024-02-07 Wed 16:52]
- J'ai fini de mettre en place une première série de tests
- Avant d'aller plus loin et d'effectuer de nouvelles modifs
- Serait bien de me poser avec Mickaël pour reviewer mes branches et discuter de ce que j'ai fait
**** DONE SmartSense: Intégrer la branche *autonomous-node* à la branche *main*
CLOSED: [2024-02-07 Wed 16:53]
- Cette branche a l'air d'apporter des workarounds pour les problèmes constatés lors de l'utilisation du noeud SmartSense en mode autonome
- Notamment, exporte et reset la DB périodiquement pour éviter le mécanisme de compression des shards
  - Qui a l'air d'être trop couteux pour tourner sur le noeud
- Améliore aussi la lisibilité du code
**** DONE SmartSense: Préparer la branche *refactor/main-app* pour intégration
CLOSED: [2024-02-08 Thu 11:03]
- MàJ la branche par rapport à *refactor/split-mqtt-interface*
- Review les différents commits
  - Notamment l'instanciation de l'instance *MqttInterface* pour publier les données me semble incorrecte à la réflexion
    - Effectuée avant de set *mainApp.sectorBrokerPort*
**** DONE SmartSense: Explorer les données collectées par le noeud
CLOSED: [2024-02-08 Thu 15:15]
- Maintenant que j'ai un noeud avec l'application en route dessus
- Peut voir concrètement des samples de données collectées
- Peut m'aider à créer mon jeu d'essai pour les tests unitaires
**** IN-PROGRESS SmartSense: Ajouter des tests pour *MainApp.handleProvisioningMsg()*
- Vérifier le bon fonctionnement de cette méthode
- Me paraît un bon point d'entrée pour mettre en place des tests pour *MainApp*
**** IN-PROGRESS SmartSense: Intégrer la branche *refactor/split-mqtt-interface*
- Maintenant que la branche *feat/autonomous-node-and-add-tools* a été intégrée
- Peut commencer à intégrer les modifications dans mon backlog
- MàJ la branche *refactor/split-mqtt-interface* par rapport à *main*
- Faire la MR
*** Done
- SmartSense: Ajouter des tests pour l'instanciation de *DataToLocalInfluxDB*
  - Déclenche l'exception *requests.exceptions.ConnectionError* lorsque le SGBD est non-disponible
  - Voir comment le process se comporte lorsque l'erreur est levée
    - Est-ce qu'il s'arrête ?
    - Ou tombe dans un état zombie ?
  - Si le SGBD ne répond pas, doit-on stopper *MainApp* ?
- SmartSense: Ajouter des tests pour l'instanciation de *MqttInterface*
  - Même constat que pour *DataToLocalInfluxDB*
  - Juste un problème pour déterminer l'exception levée
    - Obtient un message *ConnectionRefusedError*
    - Mais n'arrive pas à importer de type correspondant
    - Le plus proche que je trouve est *MqttException*
      - https://github.com/eclipse/paho.mqtt.python/blob/47ab9b94d9d1408abd8717e6c2d052ca329d549b/src/paho/mqtt/__init__.py#L4
    - Mais l'utiliser en catch pas l'exception
- SmartSense: Ajouter des tests pour *MainApp.handleProvisioningMsg()*
  - Nécessite plusieurs modifications en amont
  - *handleProvisioningMsg* instancie et démarre le process publiant les données sur le broker une fois le message de provisioning reçu
    - Serait p-e préférable de découpler cette action de la réception du message
    - Et de démarrer ce process en même temps que les autres, i.e. dans *main()* après avoir été provisionné
  - Le constructeur de *MainApp* repose sur une config
    - Celle-ci doit se trouver à un emplacement spécifique
    - Peut facilement modifier le code pour qu'on passe le path de la config en paramètre
    - Mais rencontre la même erreur pour les autres modules
    - Ce qui mène au problème suivant
  - *MainApp* instancie beaucoup d'objets
    - Certains reposent sur la même config
      - Doit donc transmettre le path de la config
      - Mais pourquoi réinstancier la config à chaque fois ?
      - Et non pas partager l'objet de *MainApp* ?
    - Certains dépendent de services potentiellement pas en ligne
      - e.g. *NPTManager*, *OpenOCDManager* qui utilise Telnet
    - Quelle est la bonne approche pour tester *MainApp* ?
      - Rendre optionnel ces différents composants ?
        - En fonction de la config, instancier ou non les composants
      - Mocker ces différents composants ?
      - Décomposer *MainApp* en différents modules, chacun séparément facilement testable ?
    - Config
      - Ne constate pas de raison particulière à ces multiples instances
      - Modification du code pour en utiliser qu'une
    - Instanciation de *MainApp*
      - [ ] Sortir du constructeur l'instanciation des modules problématiques, i.e. les *Manager*
        - Et les mettre dans une méthode appelée immédiatement dans *main()*
        - Permet d'instancier *MainApp* dans les tests en s'en passant
        - Cette approche me semble par contre error prone
          - Faut savoir que *MainApp* n'est pas fonctionnelle à proprement parler tant que cette seconde méthode n'a pas été appelée
        - Après on retrouve déjà un peu ça avec *MainApp.go()*
        - Ou même que c'est *main()* qui sait faire fonctionner le module
      - [ ] Mise en place d'un *MessageRouter*
        - En soit, *MainApp* n'interagit pas directement avec les *Managers*
        - Se contente de lire des messages qu'ils émettent et de les transmettre/d'y répondre
        - Pourrait séparer la logique instanciation/utilisation
          - *MainApp* instancie les objets
          - Ainsi qu'un module en charge des messages
          - Configure ce dernier
          - Et le laisse ensuite gérer les messages
        - Reste à voir comment fournir les *Managers* et *Queues* respectives à ce composant sans trop le coder en dur
          - Après, c'est un trade-off qualité vs. complexité
      - [ ] Suppression du routing par *MainApp*
        - Une approche /Reactive Programming/ me paraitrait plus adaptée en fait
          - Chaque module s'abonne au flux de messages et traite ceux qui le concerne
        - Plus vraiment de routing à ce niveau là
        - Permet de découpler les différents modules de *MainApp*
          - Chorégraphie plutôt qu'orchestration
        - Un peu curieux par contre sur les perfs d'un flux unique
          - Et de la compatibilité avec une appli multi-process
        - Et comment faire évoluer l'appli, i.e. ajouter des couches de traitement
          - E.g. on parle de traiter les données collectées par un capteur
          - Et de ne transmettre/stocker que le résultat de ce traitement
            - Et non pas la donnée d'origine
          - Comment achieve cela ?
            - La couche publication qui filtre la donnée brute ?
            - Le capteur qui marque non-publiable la donnée brute ?
          - Dans tous les cas, me retrouve avec un couplage implicite
            - Un des deux modules sait qu'il existe un module de traitement
            - Même si on peut considérer que le couplage est faible
            - Puisque ne pas avoir le module de traitement fait juste que la donnée brute est ignorée/inexploitée
      - [ ] Mise en place de *Factories*
        - Puisque c'est l'instanciation qui pose problème
        - Serait p-e intéressant de voir si on peut mettre en place des *Factories*
        - Et les injecter à *MainApp*
        - De façon à pouvoir les mocker dans les tests
- SmartSense: Prendre en main le noeud SmartSense
  - Plusieurs services s'occupent de faire fonctionner l'application
    #+BEGIN_PLAIN
UNIT                         LOAD   ACTIVE SUB     DESCRIPTION
alsa-state.service           loaded active running Manage Sound Card State (restore and store)
avahi-daemon.service         loaded active running Avahi mDNS/DNS-SD Stack
collectd.service             loaded active running Statistics collection and monitoring daemon
cron.service                 loaded active running Regular background program processing daemon
dbus.service                 loaded active running D-Bus System Message Bus
dnsmasq.service              loaded active running dnsmasq - A lightweight DHCP and caching DNS server
getty@tty1.service           loaded active running Getty on tty1
grafana-server.service       loaded active running Grafana instance
influxdb.service             loaded active running InfluxDB is an open-source, distributed, time series database
mainApp.service              loaded active running Smartsense Python App
rng-tools.service            loaded active running rng-tools.service
rsyslog.service              loaded active running System Logging Service
serial-getty@ttyAMA0.service loaded active running Serial Getty on ttyAMA0
ssh.service                  loaded active running OpenBSD Secure Shell server
systemd-journald.service     loaded active running Journal Service
systemd-logind.service       loaded active running Login Service
systemd-udevd.service        loaded active running udev Kernel Device Manager
triggerhappy.service         loaded active running triggerhappy global hotkey daemon
user@1000.service            loaded active running User Manager for UID 1000
wpa_supplicant.service       loaded active running WPA supplicant
    #+END_PLAIN
  - mainApp.service
    - Décrit dans /etc/systemd/system/mainApp.service
    - Concrètement, execute la commande suivante : cd /home/root/App; python3 mainApp.py
  - collectd.service
    - Pas de description du service
    - Retrouve sa configuration dans le fichier /etc/collectd/collectd.conf
      #+BEGIN_PLAIN
FQDNLookup true
LoadPlugin syslog
<Plugin syslog>
	LogLevel info
</Plugin>
LoadPlugin battery
LoadPlugin cpu
LoadPlugin df
LoadPlugin disk
LoadPlugin entropy
LoadPlugin interface
LoadPlugin irq
LoadPlugin load
LoadPlugin memory
LoadPlugin network
LoadPlugin processes
LoadPlugin swap
LoadPlugin users
<Plugin df>
	FSType rootfs
	FSType sysfs
	FSType proc
	FSType devtmpfs
	FSType devpts
	FSType tmpfs
	FSType fusectl
	FSType cgroup
	IgnoreSelected true
</Plugin>
<Plugin network>
	Server "127.0.0.1"
</Plugin>
<Include "/etc/collectd/collectd.conf.d">
	Filter "*.conf"
</Include>
      #+END_PLAIN
    - Collecte des métriques sur l'état du système
  - influxd.service
    - Décrit dans /etc/systemd/system/influxd.service
    - Lance influxd avec comme fichier de config /etc/influxdb/influxdb.conf
      #+BEGIN_PLAIN
reporting-enabled = false
[meta]
  dir = "/data/influxdb/meta"
[data]
  dir = "/data/influxdb/data"
  wal-dir = "/data/influxdb/wal"
  index-version = "tsi1"
[coordinator]
[retention]
[shard-precreation]
[monitor]
[http]
  auth-enabled = true
[ifql]
[logging]
[subscriber]
[[graphite]]
[[collectd]]
  enabled = true
  bind-address = ":25826"
  database = "collectd"
  typesdb = "/usr/share/collectd"
[[opentsdb]]
[[udp]]
[continuous_queries]
[tls]
      #+END_PLAIN
    - Important : c'est la config d'influxdb qui active l'enregistrement des données collectées par collectd dans influxdb
      - Cf. https://docs.influxdata.com/influxdb/v1/supported_protocols/collectd/
    - Ça vaudra p-e le coup néanmoins de se pencher sur cette config
      - Peut-on désactiver le mécanisme de shard compression incriminé pour les crashs ?
      - La partie concernant collectd insiste sur le fait de mettre en place une bufferisation, y en a-t-il une par défaut ?
  - grafana-server.service
    - Instance disponible à : http://192.168.1.2:3000
    - Config disponible dans /etc/grafana/grafana.ini
    - Configuration par défaut
    - Mais disposait déjà de deux dashboards
      - Hardware Monitoring
        - Présente les métriques systèmes récupérées par collectd
      - Sensor Data
        - Présente les données récupérées par l'application
  - dnsmasq.service
    - D'après sa description, sert de DHCP
    - Suppose que c'est ce service qui permet au noeud de mettre en place le réseau local
  - Pose la question de comment est setup le noeud
    - De la façon dont Mickaël m'a présenté les choses, j'ai l'impression que c'est un setup manuel
    - Ne vois pas de repo avec un script Ansible ou bash pour installer et configurer le noeud
    - Serait intéressant de documenter la procédure de mise en place et de l'automatiser
    - Pose aussi la question d'installer les différentes applications à même le noeud
    - Ou de conteneuriser l'application
- SmartSense: Explorer les données collectées par le noeud
  - SensorData
    - Measurements
      #+BEGIN_PLAIN
> SHOW MEASUREMENTS
name: measurements
name
----
event_accelerometer
event_airInfo
event_asx340
event_audio
event_bf707
event_cc2650
event_consumption
event_esensor
event_gyroscope
event_magnetometer
event_rfGiga
event_rgbwLuminosity
event_sensor
event_stream
event_telemeter
event_thermal
event_thermalImgHd
event_thermalImgLd
event_uvLuminosity
event_uwb
meta_accelerometer
meta_airInfo
meta_airQuality
meta_asx340
meta_audio
meta_bf707
meta_cc1310
meta_cc2650
meta_consumption
meta_esensor
meta_gyroscope
meta_leds
meta_magnetometer
meta_rfGiga
meta_rgbwLuminosity
meta_sensor
meta_stream
meta_telemeter
meta_thermal
meta_thermalImgHd
meta_thermalImgLd
meta_uvLuminosity
meta_uwb
meta_uwbCfg
meta_uwbData
      #+END_PLAIN
    - event
      - accelerometer
        #+BEGIN_PLAIN
    > SELECT * FROM event_accelerometer LIMIT 10
    name: event_accelerometer
    time                admin board          location mcu     mode       node              sector subsector x   y   z
    ----                ----- -----          -------- ---     ----       ----              ------ --------- -   -   -
    1683307383833892224 p     sensorBoard    External sensor  production b8:27:eb:8c:67:48 1      1         -5  -34 977
    1683307384111892224 p     externalBoard2 External esensor production b8:27:eb:8c:67:48 1      1         -12 480 872
    1683307384814892224 p     sensorBoard    External sensor  production b8:27:eb:8c:67:48 1      1         -2  -37 976
    1683307385102892224 p     externalBoard2 External esensor production b8:27:eb:8c:67:48 1      1         -12 479 874
    1683307385798892224 p     sensorBoard    External sensor  production b8:27:eb:8c:67:48 1      1         -4  -32 977
    1683307386094892224 p     externalBoard2 External esensor production b8:27:eb:8c:67:48 1      1         -11 477 874
    1683307386777892224 p     sensorBoard    External sensor  production b8:27:eb:8c:67:48 1      1         -4  -36 977
    1683307387086892224 p     externalBoard2 External esensor production b8:27:eb:8c:67:48 1      1         -10 479 874
    1683307387758892224 p     sensorBoard    External sensor  production b8:27:eb:8c:67:48 1      1         -2  -35 975
    1683307388082892224 p     externalBoard2 External esensor production b8:27:eb:8c:67:48 1      1         -12 478 872
        #+END_PLAIN
      - airInfo
        #+BEGIN_PLAIN
    > SELECT * FROM event_airInfo LIMIT 10
    name: event_airInfo
    time                admin board          humidity location mcu     mode       node              pressure  sector subsector temperature
    ----                ----- -----          -------- -------- ---     ----       ----              --------  ------ --------- -----------
    1683307383266892224 p     sensorBoard    34.86    External sensor  production b8:27:eb:8c:67:48 101613.41 1      1         33.71
    1683307383716892224 p     externalBoard2 34.24    External esensor production b8:27:eb:8c:67:48 101450.65 1      1         26.01
    1683307384259892224 p     sensorBoard    34.86    External sensor  production b8:27:eb:8c:67:48 101610.69 1      1         33.71
    1683307384708892224 p     externalBoard2 34.24    External esensor production b8:27:eb:8c:67:48 101451.36 1      1         26.03
    1683307385240892224 p     sensorBoard    34.86    External sensor  production b8:27:eb:8c:67:48 101612.33 1      1         33.72
    1683307385703892224 p     externalBoard2 34.25    External esensor production b8:27:eb:8c:67:48 101453.19 1      1         26.03
    1683307386221892224 p     sensorBoard    34.87    External sensor  production b8:27:eb:8c:67:48 101612.33 1      1         33.72
    1683307386694892224 p     externalBoard2 34.23    External esensor production b8:27:eb:8c:67:48 101456    1      1         26.01
    1683307387201892224 p     sensorBoard    34.86    External sensor  production b8:27:eb:8c:67:48 101605.24 1      1         33.71
    1683307387686892224 p     externalBoard2 34.23    External esensor production b8:27:eb:8c:67:48 101457.83 1      1         26.01
        #+END_PLAIN
      - airQuality
        #+BEGIN_PLAIN
    > SELECT * FROM event_airQuality LIMIT 10
    name: event_airQuality
    time                admin board          co2  location mcu     mode       node              resistance sector subsector tvoc
    ----                ----- -----          ---  -------- ---     ----       ----              ---------- ------ --------- ----
    1683307383428892224 p     externalBoard2 450  External esensor production b8:27:eb:8c:67:48 197033     1      1         125
    1683307383970892224 p     sensorBoard    3699 External sensor  production b8:27:eb:8c:67:48 89100      1      1         1020
    1683307384419892224 p     externalBoard2 450  External esensor production b8:27:eb:8c:67:48 196837     1      1         125
    1683307384951892224 p     sensorBoard    3699 External sensor  production b8:27:eb:8c:67:48 89100      1      1         1020
    1683307385411892224 p     externalBoard2 450  External esensor production b8:27:eb:8c:67:48 196837     1      1         125
    1683307385931892224 p     sensorBoard    3699 External sensor  production b8:27:eb:8c:67:48 89100      1      1         1020
    1683307386403892224 p     externalBoard2 450  External esensor production b8:27:eb:8c:67:48 196837     1      1         125
    1683307386913892224 p     sensorBoard    3699 External sensor  production b8:27:eb:8c:67:48 89100      1      1         1020
    1683307387395892224 p     externalBoard2 450  External esensor production b8:27:eb:8c:67:48 197033     1      1         125
    1683307387894892224 p     sensorBoard    3699 External sensor  production b8:27:eb:8c:67:48 89100      1      1         1020
        #+END_PLAIN
      - asx340
        #+BEGIN_PLAIN
> SELECT * FROM event_asx340 LIMIT 10
name: event_asx340
time                admin board       energy estimation estimation_max estimation_min image_sub                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         location mcu   mean   mode       node              occupation sector subsector variance
----                ----- -----       ------ ---------- -------------- -------------- ---------                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         -------- ---   ----   ----       ----              ---------- ------ --------- --------
1683318911060120064 p     sensorBoard 6133   0          0              0              @AAAABIgABEQACEAAAAQAAAAABAAABEQABAAABEAABAAAAAABRAAAAAAABIAABEQAAAQABEAAAAAABAAABAQAAAAAAEAEAEQAAAAAAAABAAAABEAAAAQAAEQAAEQABAAABEQAAEQAAEQABMAAAEAAAAAAAgQAEIAABAAAAEAAAIQABAQABEAABAQABAQAB8QAAAAABAQABEQAAAAAAcAAAAQACAAAAEQAAEAAAAAAAAAAAAAABAAAAEAABEAAAAAABAAAAAAAAAQABMAAAEQABEQABAAABEAAAAQABAAAAAAAAEQAAAAACIQABEwAGEAABEAAAEQABAQABAAAAAQABAQAAAAABAQAAAAABEAACEAARkCBBAQABEQAAEQABAAAAEQAAAQAAAQABEAABAAAAAQABAAABAQAXIhHAIgDCEAAAEQABEQAAAQAAEQAAAAABEAABAQAAEQABEAAAEQAK8QAAEQAAEAACEgABAAAAAQAAAQAAAAABEAAAEQAAAQABEAAAEQAAEAAAAQAAEAABEAABEQAAEQAAQQABAAAAEAABEAAAAAAAAAAAEAAAAQAAEQAAEAABAQABEQACEAABAQAAEQABEQABAQABEAAAEAABEAAAEQABEQABEAABAQAAAQABEQABAAAAAAAAAAAAAAAAEAABEAAAAQABAAABAQAAEAABAQABEAABAQAAAQABAQABEAAAEAABEAAAEAABAQAAAAAAAAAAEAABAAABAAAAEQAAAQAEAQABAQABEAAAAAABAQAAAQAAAAABEAAAAQABAQAAEQABEQABAQABAQABEQCAAQAAEQABAQABAAADEQAAEAABEAAAEAABAAABEAABEAABEQABAQABAAAAAQAAEAAAAQAAAAAAEAABEAAAEAAAEAABEAABIQABEQAAEQAAEQAAAQAAEAAAEQAAEAAAAAABEAABEwAAcgABAAABEQAAEQAAEQABEQABEAAAEAAAEQAAAAAAAAABEAAAAQAAAAAAAQABEAAAEQAAEQAAAQAAAAAAAAAAAQAAAQAAAAAAEAAAAAABEAACAAAAggABEQABEAAAQgABEAAAAAAAAQABAAAAAQAAMAAAAAAAAAAAAQAAEAAAIAAAAAABAAAAEQAAEQAAEQAAAAAAAAAAAAAAAAABAAAAAAAAEQABEgAAEAAAAAABAAAAAQAAAAAAEAAAAAAAEAAAAAAAAAAAAAAAEQABAAABEQAAEAABAQAAAQABEAAAAAABEAAAAQAAAAAAAAAAAAAAAAAAEAAAEQABAQABEAABAQABAAAAAAAAAAAAAAAAAAAAAAABAAABAAAAAAABEAABEAAAAQABEAAAEAAAAAABAAAAAQAAEAAAEAABQAAAEAABAAABEAABEQAAEgABEAABEQABEQAAEQAAAAAAEAAAAAAAEAABAAAAEAAAAQABAAABEQAAEQABAAABAAAAEQAAAAABAQAAAAAAEAABAAAAAAABAAABAgABAgABAQABAAABAQABEQAAAAAAAQABEQAAAAABEQABEAAAEAABAAAAAAABEQABAQAAAQABAAABEAAAAAAAAQABAQAAAAAAAQAAEAAAAAA External bf707 0.7099 production b8:27:eb:8c:67:48 1          1      1         4.5959
1683319143060120064 p     sensorBoard 25922  0          0              0              @AAAABAAAAEAABAAABAAAAAAAAAQAAAQAAAQAAAAABEAABAAAAEQAAAAABAAAAAQAFAAAAAAAAAAABAQABAAAAAAAAAQAAAQAAAAAAAAAAAAEBAAABAAAAEAAAEAAAEAAAEAABAAABEAAAEQAAAAAAAAAAAQABEQAAAAABAQAAAQAAAAAAAAAAAAABAAAAEAABEAAAAAAAAAABAAAAAAQAAQAAAQAAAAAAEAABAAABEAAAAQAAAAAAEQABAQAAAAAAEQAAAQAAAwDAAQAAEAAAEAAAAAAAAAAAAAAAAQABAAAAAQAAAAABAQAAEwAAAQAAAAAAAQAAEAAAAQAAAAABAAABEAAAAQAAAQAAAAACEAAQkCBAAQAAEABBEAAAAAAAAAAAAAABAAAAEAAAAAAAEQAAAQABEQAWAhHAEADBAAABEAAAEAABAAAAAQAAAAAAEAAAAAAAEAABEQABEAAJ4QAAAQAAAAABEAAAAAAAEAABAAAAEAAAAAABAAAAAQAAAAAAAAAAAQAAAAAAAQAAEQABAQABEAABEQAAAAAAAQAAEAAAAAABAAAAEAAAAAAAAAAAAAAAAAAAAQAAEQAAAAAAEAAAAAAAEAABAAAAAQAAAAAAAAAAAAAAAQAAAAAAAAAAEQAAAAAAAAABEAAAAAAAAQABAQAAEAAAAAAAEAAAAAAAAAABAAAAAQAAEAAAAAAAAAABAAAAAAABAAAAEAAAIAAAIAAAEQAAAAABAAABEAABEAABEQAAEAABAAABEAAAEAAAAAAAAQABAQAAEAAAAAAAAAABEAAAEAAAAAAAEQAAAQAAAQAAEAAAAAAAAQAQAQAAAQBBAQAAAQAAEAAAAAAAAAABEAAAEQAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAQAAAQABAAAAAAAAEAAAEAAAAAAAAQABAAAAAQABAAABEQAAAAAAgwABAQAAEAAAEQABAAAAAQAAEAAAAAAAAAAAAAAAAQAAAQAAAABAAQAB8nAAAAAAAQAAEQAAAQAAAAAAAAABAAAAAAAAAAAAAAABAAAAAAACAAAAgQAAAAAAEAAAEAAAAAAAAAAAAQAAEQAAAAAAEAAEAAAAAQABAAAKAAAAEQAAAgAAAAAAAQAAAQABEQAAEQBAAQABAAAAEAAAAAAAAAAAEAABEAAAEQAAAQABAQAAAAAAAAABAAABAAACAAAAEAAAAAAAAAAAEAABAQAAEAAAAAAAAQAAAAAAEAAAAAAAAAAAAAAAAAAAEAABAAAAAABAAQACAAABEAAAAAAAAAAAEQAAAAAAAAABEAAAEQAAAgAAAABAQAAAAAAAAQAAAQAAAQABAAABEQAAEQAAAQAAAAABAAAAAAABQQAAAAABAQAAAAAAAAABAAAAAAAAAQAAAAAAEAAAAAAAAAAAgQADEAABAAAAEAABAAABAQAAAAAAAQAAAAAAAAAAAAABEQAAAAAAAAAAAAAAEACAAAAAAAABEQABEAAAAAAAAAAAAQAAAAAAEQAEAAACAAAAAAAAAgAAAQAAAAABAQABEAAAAAAAEAAAAAAAEQAAAQAAAQAAEAABAAAAEAABAAAAAAAAAAA External bf707 0.69   production b8:27:eb:8c:67:48 1          1      1         21.1238
        #+END_PLAIN
      - audio
         #+BEGIN_PLAIN
> SELECT * FROM event_audio LIMIT 10
name: event_audio
time                admin board       location mode       node              sector subsector synchronize
----                ----- -----       -------- ----       ----              ------ --------- -----------
1683318692060120064 p     sensorBoard External production b8:27:eb:8c:67:48 1      1         OK
        #+END_PLAIN
      - bf707
        #+BEGIN_PLAIN
> SELECT * FROM event_bf707 LIMIT 10
name: event_bf707
time                admin board       location mode       node              sector subsector synchronize
----                ----- -----       -------- ----       ----              ------ --------- -----------
1683318691060120064 p     sensorBoard External production b8:27:eb:8c:67:48 1      1         OK
        #+END_PLAIN
      - cc2650
        #+BEGIN_PLAIN
> SELECT * FROM event_cc2650 LIMIT 10
name: event_cc2650
time                admin board       location mode       node              sector subsector synchronize
----                ----- -----       -------- ----       ----              ------ --------- -----------
1683318691060120064 p     sensorBoard External production b8:27:eb:8c:67:48 1      1         OK
        #+END_PLAIN
      - consumption
        #+BEGIN_PLAIN
    > SELECT * FROM event_consumption LIMIT 10
    name: event_consumption
    time                A       V      W        admin board    location mcu       mode       node              sector subsector
    ----                -       -      -        ----- -----    -------- ---       ----       ----              ------ ---------
    1683307383096313088 8.5     5      43.126   p     rpiBoard External inaExt1   production b8:27:eb:8c:67:48 1      1
    1683307383197403904 106.003 5      530.641  p     rpiBoard External inaExt2   production b8:27:eb:8c:67:48 1      1
    1683307383399406848 669.989 3.288  2168.816 p     rpiBoard External inaRpi    production b8:27:eb:8c:67:48 1      1
    1683307383601250048 722.491 11.712 8212.751 p     rpiBoard External inaPoe    production b8:27:eb:8c:67:48 1      1
    1683307384004352000 755.492 4.988  3738.864 p     rpiBoard External inaSensor production b8:27:eb:8c:67:48 1      1
    1683307384105933824 8       5.004  43.126   p     rpiBoard External inaExt1   production b8:27:eb:8c:67:48 1      1
    1683307384207138048 102.003 5.004  525.641  p     rpiBoard External inaExt2   production b8:27:eb:8c:67:48 1      1
    1683307384409869056 588.987 3.292  1831.931 p     rpiBoard External inaRpi    production b8:27:eb:8c:67:48 1      1
    1683307384611720192 661.489 11.748 7800.238 p     rpiBoard External inaPoe    production b8:27:eb:8c:67:48 1      1
    1683307385014542080 752.492 4.992  3766.365 p     rpiBoard External inaSensor production b8:27:eb:8c:67:48 1      1
        #+END_PLAIN
      - esensor
        #+BEGIN_PLAIN
> SELECT * FROM event_esensor LIMIT 10
name: event_esensor
time                admin board          location mode       node              sector subsector synchronize
----                ----- -----          -------- ----       ----              ------ --------- -----------
1683318691060120064 p     externalBoard2 External production b8:27:eb:8c:67:48 1      1         OK
        #+END_PLAIN
      - gyroscope
        #+BEGIN_PLAIN
    > SELECT * FROM event_gyroscope LIMIT 10
    name: event_gyroscope
    time                admin board          location mcu     mode       node              sector subsector x  y  z
    ----                ----- -----          -------- ---     ----       ----              ------ --------- -  -  -
    1683309474180892224 p     sensorBoard    External sensor  production b8:27:eb:8c:67:48 1      1         0  -1 -1
    1683309474502892224 p     externalBoard2 External esensor production b8:27:eb:8c:67:48 1      1         0  0  0
    1683309475161892224 p     sensorBoard    External sensor  production b8:27:eb:8c:67:48 1      1         0  -1 -1
    1683309475493892224 p     externalBoard2 External esensor production b8:27:eb:8c:67:48 1      1         -1 0  0
    1683309476143892224 p     sensorBoard    External sensor  production b8:27:eb:8c:67:48 1      1         0  0  0
    1683309476484892224 p     externalBoard2 External esensor production b8:27:eb:8c:67:48 1      1         -1 0  0
    1683309477125892224 p     sensorBoard    External sensor  production b8:27:eb:8c:67:48 1      1         -1 0  0
    1683309477476892224 p     externalBoard2 External esensor production b8:27:eb:8c:67:48 1      1         0  0  0
    1683309478106892224 p     sensorBoard    External sensor  production b8:27:eb:8c:67:48 1      1         0  -1 -1
    1683309478468892224 p     externalBoard2 External esensor production b8:27:eb:8c:67:48 1      1         0  -1 0
        #+END_PLAIN
      - magnetometer
        #+BEGIN_PLAIN
    > SELECT * FROM event_magnetometer LIMIT 10
    name: event_magnetometer
    time                admin board          location mcu     mode       node              sector subsector x   y  z
    ----                ----- -----          -------- ---     ----       ----              ------ --------- -   -  -
    1683309474181892224 p     sensorBoard    External sensor  production b8:27:eb:8c:67:48 1      1         8   48 26
    1683309474335892224 p     externalBoard2 External esensor production b8:27:eb:8c:67:48 1      1         -25 -3 -72
    1683309475161892224 p     sensorBoard    External sensor  production b8:27:eb:8c:67:48 1      1         10  48 26
    1683309475327892224 p     externalBoard2 External esensor production b8:27:eb:8c:67:48 1      1         -24 -3 -73
    1683309476143892224 p     sensorBoard    External sensor  production b8:27:eb:8c:67:48 1      1         10  48 26
    1683309476318892224 p     externalBoard2 External esensor production b8:27:eb:8c:67:48 1      1         -25 -3 -73
    1683309477125892224 p     sensorBoard    External sensor  production b8:27:eb:8c:67:48 1      1         8   47 26
    1683309477310892224 p     externalBoard2 External esensor production b8:27:eb:8c:67:48 1      1         -24 -3 -73
    1683309478106892224 p     sensorBoard    External sensor  production b8:27:eb:8c:67:48 1      1         9   47 26
    1683309478301892224 p     externalBoard2 External esensor production b8:27:eb:8c:67:48 1      1         -25 -3 -73
        #+END_PLAIN
      - rfGiga
        #+BEGIN_PLAIN
    > SELECT * FROM event_rfGiga LIMIT 5
    name: event_rfGiga
    time                admin board       location mcu    mode       node              rssi1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             sector subsector
    ----                ----- -----       -------- ---    ----       ----              -----                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ------ ---------
    1683309474101892224 p     sensorBoard External cc2650 production b8:27:eb:8c:67:48 @nmqpb25nbuJnYWJmWWJmYOJoYWJmYOplVWZlVWpmTK5lmiplVOJkVK5lXiZlTKJmSWJmWWZlSWplTm5jTWZlWOpkYa5kVaZlkO5lWeZlVaplVOJkTOpkTiplWW5kVWpkVOplViZlYWZlXO5krWZltKpkVOplSC5jVCpkTWpkSWZlWOZlTyokWiZlXOZlTOJkWepkT+YlWW5kTialWa5kTaZlVm5kVO5jT25kTC5kVK5kVeZlXCpoQaZlSO5kVW5jQW5kPKZlSO5kcKplTy4lVWpmVKZlWCZlTW5kSOZlSOpkWC5kSKZlVOplYOpkWOZlTWJkSWZlPOpkTWZlVWpkPK5kWa5kZWJmVeZlXi5nSO5kSWZlPC5kQKZlVWZlfuZlWOZlWWplVKZnVW5kTWZlT+olTa5kTWpkSWpkVCJkQWpkVWZlYKpkQWplTO5kVepmTWpkVC5kVO5lTKZlSW5kW+YlTaZlVWpkSCpkVOplVOpkTOplVWZlVWpkSOJmTK5kVWJmTCpkSOZlVWZlZa5kVOpkTWZlT+YlX+IkSOJkV+olSO5kQO5kWWZlWaJmVW5lTWZlVWpkSa5kVaZlVKJmVO5kVWZlWaplSaZlnOplTOpkSWJmTO5kZWZlYO5kQW5lWyqlVa5jWiplWWZlSO5jPOZlSW5kT+YlVeZmYeJmXKpkWuZlYKJmQaZlVy4kViZpWepmWi5naiKrVuZlQO5kV2ZnamZnYi5kWmpmZiJmWqJmYqJnVqJmYyZlYWJmZi5lSO5mWWZlVWZlYOpkTaZlPOpkVWZlYC5kTWZmSiZlSOZlVOZlTW5kTWZlVqJmVKZlZW5mWaJmWaZlWa5muWplXOZlQaZlbe5jW25lXiJmZ2ZmYWZlVqpmWO5kVipmYWpl 1      1
    1683309475955892224 p     sensorBoard External cc2650 production b8:27:eb:8c:67:48 @lm6pZuJoai5mba5mVaJmYiJmYu5lbWZmaqZnaiJmcuJmdyJmbiZmVipmauJnZqJmYiZnZqJnYq5mai5mcyJnZqpmYmZlXepmVm5nbaZnWuZmZqplZiJmVW5lWKZlSa5kZOZlnO5kYiZlYiZlVmJmYK5kVq5kYWZlWyZlYCZlVeZlWWplVqpkWq5nWi5mZiJmTiJmYq5lbq5mZiqkWeZmTWZlXuJkTOZlSK5lWapkVyYlaiJmRK5lQO5jWWZlOWZlV+YmVWZlTOZlca5kYeZlTWJmVKZlSe5kQqJkQO5kTKplRK5kTW5kZGalVWZlViZlTupkVK5kVOJkSW5kYqZlWK5mTO5kWaJmVi5mXKplbWZlVa5kVeZlVaZlVy5jQaplVOZlYmJoQa5lVeJmdOZlT6pmWaZlYW5kYW5lVaJmVmZlWO5lTi5kVWpkWq6jWOZlWeZlgWJmSWZmVaJmVCplSiplPW5jTKZlTOplSmplYapkaa5kTaJmWW5jViplWaZmTKZlYmJmTWJnbu5lQW5kYaplWi5lTq5kYaZlVOplT+4kZW5kWa5jViJmXOZlbu5mQaZlZqJmbqJmSKplVOplPW5mW25lYaplYW5kmWZlai5kaa5lSW5kSmJmWWpmW25oWi5lSaZlWaJkWaZlSm5kVK5kSKZlWi5kXapkYmZlTKJmXiJmWOplTiJmdK5kQWpkVWplYWZlVW5lVWZlYmplZW5lV+YlTmplTWpkZaZlTWZlVuJmVWZmSaZlTaZlWWZlVaZmVOplVWZlYOZlXiZlVapmYO5kaiZlXWZlVO5kTWZlSWZlVa5kYW5kYipmVaZlWeplVmZlVOJmVa5kSeplUq5kXW5jYipkVuJmTeZlVeJmWqZmVi5lXa5kSiJmXaZm 1      1
    1683309477809892224 p     sensorBoard External cc2650 production b8:27:eb:8c:67:48 @mi6pd+ZocuZmYiZnYa5kYW5mXaZnTmJmZiJmXWZlWW5kVWJmTOpkZeZlWaJmVm5lWi5mayJmWi5lWiplVWplXqplgipkWWplVi5lYaZlYaplTeJmWiJmPi5lVeJmWiZlYqplYipmVKZlZaJmVWJmWm5kTOplWeplSOZlZipkYq5mVWJmaqJnbqJmceZmYWZmaWZlbWJmXOZmVealViplbqZlYypmdiJmSW5kY2ZlZW5kVm5lSaJmZipkYOplVKJmWWZmSWJmVOZleiZlYmZlXi5mXm5mYWpmVi5mYCpkViJmWOZlVa5lVW5lSmZmViZmViplYe5maqJmZiplZqJnZaZlZiJmbuJmYe5mZi5lbWJmWeplYipmXq5lauZmYmpmauZma2ZmciJmZWJmYipmYaJmaqJmXmJmZipmhuplcaZmYiJnXi5mai5mbaZmYWJmTiJmZOJmbepmXuZmZaJnYipmhiZmZiJmamJmYupmbqZmaupmZapoYq5maqJmauZmau5mZm5mcqpmdmZnbm5lY2plbqpmZqpmYyZmTqJmbqplYmrmYiJmXeJnaeJmdm5maC6mYuZmZqpmYiZmXm5maqpmau5mXKZmWuplnyJmZa5mZuJmauJmWe5mauZnYu5lampmcmpmYuZmaipkZe5maapmbiZlYq5lYipmZupmZmKmYapmYeJmZiZmYeZmWmJmViZmaWZmam5mSaZmYmJmWeplcqZmTqZlaiJmbiJmaiJnXiJmZiJmYaZmZiJmYaplYmZnZqplZaplamJmZiZmYmJmZi5lbWZmZu5lbmJmYiJmYWJmYiJmcmJmZiJnaqqmVWZmbepmWiZmTipmYWpmXaZmYWJmeiplXuJndipmaqJmdi5mVi5mam5mai5lXu5m 1      1
    1683309479663892224 p     sensorBoard External cc2650 production b8:27:eb:8c:67:48 @mqKpeK6ofq5meuJnbqJmduJncuJmb2JnaqJnZqJme2JnbypmYiZmdypmZyJncqZmYyZnXuZldqpmbiZlbqplcupma25lbqJmaiplduJmbepmcqZmaeZmYiZmYipmYupmdypmamZnai5mYy5mZqpmbupmamJmbiJncmJmaiZnYiJmjyZmXu5mV25mZmZmWaZmciZlWiZlauZmZeqmaqpmbiJmcqZmbyZmZepmZqJmamJmYq5maupmWmJmae5lXupmWeZnYu5maWZleapmai5mZi5mYipmZKplTq5mcuJnbq5mbyplWq5mdipmbmJnauJncaJnbmJmdi5lZWpmYqJmYi5mbeZnZyJtam5mcu5mYiplYiJmXq5kbqJnbuZmXiZlVm5lWqpmamJmYq5mWiJmbaJnZqpmZmpmW2plWm5mYiZmna5mYq5laOpmTeZmYWJmYWpmSe5lWqplZiZlZWJmYqJmXaZmamZlhWJmYmJmbi5lWWppYuZmaiJmWy5layZmYuZmYmplViJmYaJmYqpmXqJncupmce5lZe5maqJmbiJmZmJmciZlbeJmZyZnZuJmau5mZmJmaaplYiJmbq5mWeZmcm5lZipmYiJnmuJmZi5maaplXK6mWuplYmJmZe5mau5mY2JmZW5lYiZmWm5lampmYuJmaaJmZaplYq5mXm5lbmJmZuZmYmpmaepkYeZmYe5mYWpmYeZnampmZWZma+pmYi5lYmZmYqJmZaplYqZlam5laqplWm5lYWplViJmamJmVaJmViJmaa5lZWZmaipmamZlamJmaqplaepmVm5lVaJnWipmZaJmZqZmbi5mVWZmYqplYKqmbiJmWeZmaaJmXuZlYqpmcuJmaOJmZmZmaipmZupmauJmZmplYuZl 1      1
    1683309481517892224 p     sensorBoard External cc2650 production b8:27:eb:8c:67:48 @nmapbC6ocWJnau5mdqJmaupmbapmYmZrZ2pmY2JmauJmeuJnYmZmWCamam5mYqpmYipmaiJnbmpmfqJmcqJnZmJma2Zmbm5lcipmZyZnY2ZmduJnVupmZq5mjipmba5mbuJnVqpmdq5mbuZnbmplYqJmYiZnYiJnb25mXyJmViKmYa5paqplbe5mau5ka2JnQqpmfqpmbipmceqmaWpldqJmaqJmZmpmaqJmYuJmcqZmZmJnZupmdupmZe5mamJmVyZnbuJmdmpmfi5mZWZnbiplaeJmai5mceZmaq5mYqJmZqpmXuZnYyZmauZnYqJmXypmYm5oXWpmZqZlYWZmVqJmWipmXi5mWqpmTuplauZmYipmYm5lamJmaeZmYa5mYuJmem5mYqZmYiZmWiplam5mZupldqZmamplYyJmZiZmbi5oZm5mZiZmbipmYOJmZm5mXWJmaqplaaZmbe5mWWpkXipmYiJmYmZmYq5lYmZmYiplbqpmZm5lY2JmVeplVa5mWKKmai5kYiJmWWpmZiJnYe5mZqZlYmZmZuJmQqZmSiJmWiJmZuZmZm5mcWJmYq5maipmWuplYqJmZiZmaeJnVy5laiJnbmpklq5mbqpmZi5mbupmYuJmZiJmZiJmduplXmJmZypmYuZmYu5laiplZeZmpqZmYiJmbqJmceZmWWJmYq5mYiplYiZmZiJmZiZlay5mWuZmZipkYOplYWJmWq5maiplYm5mYapmXiplaa5mXiplZiJmYaZlZiplYipmZi5lZmplYipmbmJmYipmXaJmeaZmXi5laiZmXqplZiJmZWZmYuJmYypmaiJmaqpmbq5mZm5mZepmYqJmYiJmYqJmYqpmcyZnZqpmXmZlWqZnau5lYiZmbq5lYqZn 1      1
        #+END_PLAIN
      - rgbwLuminosity
        #+BEGIN_PLAIN
    > SELECT * FROM event_rgbwLuminosity LIMIT 10
    name: event_rgbwLuminosity
    time                B    G    R    W    admin board          location mcu     mode       node              sector subsector
    ----                -    -    -    -    ----- -----          -------- ---     ----       ----              ------ ---------
    1683309473963892224 1783 3493 3645 6421 p     externalBoard2 External esensor production b8:27:eb:8c:67:48 1      1
    1683309474514892224 1636 3749 3541 5868 p     sensorBoard    External sensor  production b8:27:eb:8c:67:48 1      1
    1683309474955892224 1783 3488 3642 6418 p     externalBoard2 External esensor production b8:27:eb:8c:67:48 1      1
    1683309475495892224 1637 3754 3545 5875 p     sensorBoard    External sensor  production b8:27:eb:8c:67:48 1      1
    1683309475947892224 1785 3496 3645 6426 p     externalBoard2 External esensor production b8:27:eb:8c:67:48 1      1
    1683309476476892224 1637 3751 3543 5872 p     sensorBoard    External sensor  production b8:27:eb:8c:67:48 1      1
    1683309476938892224 1785 3498 3646 6427 p     externalBoard2 External esensor production b8:27:eb:8c:67:48 1      1
    1683309477458892224 1639 3753 3544 5876 p     sensorBoard    External sensor  production b8:27:eb:8c:67:48 1      1
    1683309477930892224 1786 3499 3647 6428 p     externalBoard2 External esensor production b8:27:eb:8c:67:48 1      1
    1683309478440892224 1635 3747 3544 5874 p     sensorBoard    External sensor  production b8:27:eb:8c:67:48 1      1
        #+END_PLAIN
      - sensor
        #+BEGIN_PLAIN
> SELECT * FROM event_sensor LIMIT 10
name: event_sensor
time                admin board       location mode       node              sector subsector synchronize
----                ----- -----       -------- ----       ----              ------ --------- -----------
1683318692060120064 p     sensorBoard External production b8:27:eb:8c:67:48 1      1         OK
        #+END_PLAIN
      - stream
        - Trop lourd
      - telemeter
        #+BEGIN_PLAIN
    > SELECT * FROM event_telemeter LIMIT 10
    name: event_telemeter
    time                admin board          data location mcu     mode       node              sector subsector
    ----                ----- -----          ---- -------- ---     ----       ----              ------ ---------
    1683309473840892224 p     sensorBoard    3    External sensor  production b8:27:eb:8c:67:48 1      1
    1683309473902892224 p     externalBoard2 1867 External esensor production b8:27:eb:8c:67:48 1      1
    1683309474829892224 p     sensorBoard    3    External sensor  production b8:27:eb:8c:67:48 1      1
    1683309474893892224 p     externalBoard2 1861 External esensor production b8:27:eb:8c:67:48 1      1
    1683309475810892224 p     sensorBoard    4    External sensor  production b8:27:eb:8c:67:48 1      1
    1683309475885892224 p     externalBoard2 1863 External esensor production b8:27:eb:8c:67:48 1      1
    1683309476791892224 p     sensorBoard    4    External sensor  production b8:27:eb:8c:67:48 1      1
    1683309476877892224 p     externalBoard2 1864 External esensor production b8:27:eb:8c:67:48 1      1
    1683309477773892224 p     sensorBoard    3    External sensor  production b8:27:eb:8c:67:48 1      1
    1683309477868892224 p     externalBoard2 1867 External esensor production b8:27:eb:8c:67:48 1      1
        #+END_PLAIN
      - thermalImgHd
        - Trop lourd
      - thermalImgLd
        #+BEGIN_PLAIN
    > SELECT * FROM event_thermalImgLd LIMIT 1
    name: event_thermalImgLd
    time                admin board       image                                                                                                                                                                         location mcu     mode       node              sector subsector thermistor
    ----                ----- -----       -----                                                                                                                                                                         -------- ---     ----       ----              ------ --------- ----------
    1683309474354892224 p     sensorBoard @PBATAsEASBgTAEFASBQVA4EAQBAUA8EAWBwUAsFANBgVA8EAQBQUAMFAYBQVAgFAPBQUA4EATBwTAMFAXBgVA8EAOBgTA8EATBwUAcFAQBwVA4EAQBwTAIFAUBQUAQFAPBwTAwEATBwTAQFAWBwUAQFAPBQUAAFAQBgVAIFAAAQV External thermal production b8:27:eb:8c:67:48 1      1         743
        #+END_PLAIN
      - uvLuminosity
        #+BEGIN_PLAIN
    > SELECT * FROM event_uvLuminosity LIMIT 10
    name: event_uvLuminosity
    time                UVA UVB UVCOMP1 UVCOMP2 admin board          location mcu     mode       node              sector subsector
    ----                --- --- ------- ------- ----- -----          -------- ---     ----       ----              ------ ---------
    1683309473552892224 32  39  9       0       p     externalBoard2 External esensor production b8:27:eb:8c:67:48 1      1
    1683309473771892224 21  25  5       0       p     sensorBoard    External sensor  production b8:27:eb:8c:67:48 1      1
    1683309474543892224 32  39  9       0       p     externalBoard2 External esensor production b8:27:eb:8c:67:48 1      1
    1683309474752892224 20  25  5       0       p     sensorBoard    External sensor  production b8:27:eb:8c:67:48 1      1
    1683309475535892224 32  39  9       0       p     externalBoard2 External esensor production b8:27:eb:8c:67:48 1      1
    1683309475733892224 21  25  5       0       p     sensorBoard    External sensor  production b8:27:eb:8c:67:48 1      1
    1683309476527892224 32  39  10      0       p     externalBoard2 External esensor production b8:27:eb:8c:67:48 1      1
    1683309476715892224 21  25  5       0       p     sensorBoard    External sensor  production b8:27:eb:8c:67:48 1      1
    1683309477518892224 32  39  10      0       p     externalBoard2 External esensor production b8:27:eb:8c:67:48 1      1
    1683309477697892224 20  25  4       0       p     sensorBoard    External sensor  production b8:27:eb:8c:67:48 1      1
        #+END_PLAIN
      - uwb
        #+BEGIN_PLAIN
> SELECT * FROM event_uwb LIMIT 10
name: event_uwb
time                admin board       location mode       node              sector subsector synchronize
----                ----- -----       -------- ----       ----              ------ --------- -----------
1683318692060120064 p     sensorBoard External production b8:27:eb:8c:67:48 1      1         OK
        #+END_PLAIN
    - meta
      - acceleremoter
        #+BEGIN_PLAIN
> SELECT * FROM meta_accelerometer LIMIT 5
name: meta_accelerometer
time                admin board          location mcu     mode       name          node              period revision sector status subsector
----                ----- -----          -------- ---     ----       ----          ----              ------ -------- ------ ------ ---------
1683318691204120064 p     externalBoard2 External esensor production accelerometer b8:27:eb:8c:67:48 1000   2.03.01  1      NOK    1
1683318692193120064 p     sensorBoard    External sensor  production accelerometer b8:27:eb:8c:67:48 1000   2.03.01  1      NOK    1
1683318692810120064 p     externalBoard2 External esensor production               b8:27:eb:8c:67:48                 1      OK     1
1683318693670120064 p     sensorBoard    External sensor  production               b8:27:eb:8c:67:48                 1      OK     1
        #+END_PLAIN
      - airInfo
        #+BEGIN_PLAIN
> SELECT * FROM meta_airInfo LIMIT 5
name: meta_airInfo
time                admin board          location mcu     mode       name    node              period revision sector status subsector
----                ----- -----          -------- ---     ----       ----    ----              ------ -------- ------ ------ ---------
1683318691199120064 p     externalBoard2 External esensor production airInfo b8:27:eb:8c:67:48 1000   2.03.00  1      NOK    1
1683318691952120064 p     externalBoard2 External esensor production         b8:27:eb:8c:67:48                 1      OK     1
1683318692186120064 p     sensorBoard    External sensor  production airInfo b8:27:eb:8c:67:48 1000   2.03.00  1      NOK    1
1683318692840120064 p     sensorBoard    External sensor  production         b8:27:eb:8c:67:48                 1      OK     1
        #+END_PLAIN
      - airQuality
        #+BEGIN_PLAIN
> SELECT * FROM meta_airQuality LIMIT 10
name: meta_airQuality
time                admin board          location mcu     mode       name       node              period revision sector status subsector
----                ----- -----          -------- ---     ----       ----       ----              ------ -------- ------ ------ ---------
1683318691200120064 p     externalBoard2 External esensor production airQuality b8:27:eb:8c:67:48 1000   2.04.00  1      NOK    1
1683318692188120064 p     sensorBoard    External sensor  production airQuality b8:27:eb:8c:67:48 1000   2.03.00  1      INIT   1
1683318692926120064 p     externalBoard2 External esensor production            b8:27:eb:8c:67:48                 1      INIT   1
1683318704842120064 p     sensorBoard    External sensor  production            b8:27:eb:8c:67:48                 1      INIT   1
1683318980604120064 p     sensorBoard    External sensor  production            b8:27:eb:8c:67:48                 1      OK     1
1683319006473120064 p     externalBoard2 External esensor production            b8:27:eb:8c:67:48                 1      OK     1
        #+END_PLAIN
      - asx340
        #+BEGIN_PLAIN
> SELECT * FROM meta_asx340 LIMIT 10
name: meta_asx340
time                admin board       capture_rate coasting_time columns decimation_factor detection_rate enable_decimation height_person location mcu   mode       name   node              occupancy_estimation period  revision rows sector status subsector width_person
----                ----- -----       ------------ ------------- ------- ----------------- -------------- ----------------- ------------- -------- ---   ----       ----   ----              -------------------- ------  -------- ---- ------ ------ --------- ------------
1683318691060120064 p     sensorBoard 30           30            40      4                 30             1                 80            External bf707 production asx340 b8:27:eb:8c:67:48 0                    1000000 1.02.02  30   1      OK     1         40
        #+END_PLAIN
      - audio
        #+BEGIN_PLAIN
> SELECT * FROM meta_audio LIMIT 10
name: meta_audio
time                admin board       child  enable location mode       name  node              revision sector subsector
----                ----- -----       -----  ------ -------- ----       ----  ----              -------- ------ ---------
1683318692166120064 p     sensorBoard stream 1      External production audio b8:27:eb:8c:67:48 3.00.00  1      1
        #+END_PLAIN
      - bf707
        #+BEGIN_PLAIN
> SELECT * FROM meta_bf707 LIMIT 10
name: meta_bf707
time                admin board       child  enable location mode       name  node              revision sector subsector
----                ----- -----       -----  ------ -------- ----       ----  ----              -------- ------ ---------
1683318691060120064 p     sensorBoard asx340 1      External production bf707 b8:27:eb:8c:67:48 1.02.02  1      1
        #+END_PLAIN
      - cc1310
        #+BEGIN_PLAIN
> SELECT * FROM meta_cc1310 LIMIT 10
name: meta_cc1310
time                admin board       enable location mode       name   node              revision sector subsector
----                ----- -----       ------ -------- ----       ----   ----              -------- ------ ---------
1683318691060120064 p     sensorBoard 1      External production cc1310 b8:27:eb:8c:67:48 1.01.00  1      1
        #+END_PLAIN
      - cc2650
        #+BEGIN_PLAIN
> SELECT * FROM meta_cc2650 LIMIT 10
name: meta_cc2650
time                admin board       child  enable location mode       name   node              revision sector subsector
----                ----- -----       -----  ------ -------- ----       ----   ----              -------- ------ ---------
1683318691167120064 p     sensorBoard rfGiga 1      External production cc2650 b8:27:eb:8c:67:48 1.01.00  1      1
        #+END_PLAIN
      - consumption
        #+BEGIN_PLAIN
> SELECT * FROM meta_consumption LIMIT 10
name: meta_consumption
time                admin board    location mcu       mode       node              period revision sector status subsector
----                ----- -----    -------- ---       ----       ----              ------ -------- ------ ------ ---------
1683318690630868992 p     rpiBoard External inaExt1   production b8:27:eb:8c:67:48 1000   1.0.0    1      OK     1
1683318690631166976 p     rpiBoard External inaPoe    production b8:27:eb:8c:67:48 10000  1.0.0    1      OK     1
1683318690631275008 p     rpiBoard External inaRpi    production b8:27:eb:8c:67:48 10000  1.0.0    1      OK     1
1683318690631360000 p     rpiBoard External inaSensor production b8:27:eb:8c:67:48 10000  1.0.0    1      OK     1
1683318690631442944 p     rpiBoard External inaExt2   production b8:27:eb:8c:67:48 10000  1.0.0    1      OK     1
1683318690633387008 p     rpiBoard External inaExt1   production b8:27:eb:8c:67:48 1000   1.0.0    1      OK     1
1683318690633591040 p     rpiBoard External inaPoe    production b8:27:eb:8c:67:48 1000   1.0.0    1      OK     1
1683318690633684992 p     rpiBoard External inaRpi    production b8:27:eb:8c:67:48 10000  1.0.0    1      OK     1
1683318690633766912 p     rpiBoard External inaSensor production b8:27:eb:8c:67:48 10000  1.0.0    1      OK     1
1683318690633862912 p     rpiBoard External inaExt2   production b8:27:eb:8c:67:48 10000  1.0.0    1      OK     1
        #+END_PLAIN
      - esensor
        #+BEGIN_PLAIN
> SELECT * FROM meta_esensor LIMIT 10
name: meta_esensor
time                admin board          child                                                                                         enable location mode       name    node              revision sector subsector
----                ----- -----          -----                                                                                         ------ -------- ----       ----    ----              -------- ------ ---------
1683318691167120064 p     externalBoard2 airInfo;airQuality;rgbwLuminosity;uvLuminosity;telemeter;accelerometer;gyroscope;magnetometer 1      External production esensor b8:27:eb:8c:67:48 3.00.00  1      1
        #+END_PLAIN
      - gyroscope
        #+BEGIN_PLAIN
> SELECT * FROM meta_gyroscope LIMIT 10
name: meta_gyroscope
time                admin board          location mcu     mode       name      node              period revision sector status subsector
----                ----- -----          -------- ---     ----       ----      ----              ------ -------- ------ ------ ---------
1683318691206120064 p     externalBoard2 External esensor production gyroscope b8:27:eb:8c:67:48 1000   2.03.01  1      NOK    1
1683318692195120064 p     sensorBoard    External sensor  production gyroscope b8:27:eb:8c:67:48 1000   2.03.01  1      NOK    1
1683318692810120064 p     externalBoard2 External esensor production           b8:27:eb:8c:67:48                 1      OK     1
1683318693670120064 p     sensorBoard    External sensor  production           b8:27:eb:8c:67:48                 1      OK     1
        #+END_PLAIN
      - leds
        #+BEGIN_PLAIN
> SELECT * FROM meta_leds LIMIT 10
name: meta_leds
time                B G R Y admin board    duty location mcu      mode       node              period               revision sector status subsector
----                - - - - ----- -----    ---- -------- ---      ----       ----              ------               -------- ------ ------ ---------
1683318690618007040 0 0 0 0 a     rpiBoard 0    External TLC59108 production b8:27:eb:8c:67:48 0.041666666666666664 1.0.0    1      OK     1
        #+END_PLAIN
      - sensor
        #+BEGIN_PLAIN
> SELECT * FROM meta_sensor LIMIT 10
name: meta_sensor
time                admin board       child                                                                                         enable location mode       name   node              revision sector subsector
----                ----- -----       -----                                                                                         ------ -------- ----       ----   ----              -------- ------ ---------
1683350298380319936 p     sensorBoard airInfo;airQuality;rgbwLuminosity;uvLuminosity;telemeter;accelerometer;gyroscope;magnetometer 1      External production sensor b8:27:eb:8c:67:48 3.00.00  1      1
        #+END_PLAIN
      - stream
        #+BEGIN_PLAIN
> SELECT * FROM meta_stream LIMIT 10
name: meta_stream
time                admin board       divider fs    location mcu   microphone mode       name   node              revision sector status subsector
----                ----- -----       ------- --    -------- ---   ---------- ----       ----   ----              -------- ------ ------ ---------
1683350298389319936 p     sensorBoard 2       48000 External audio 0          production stream b8:27:eb:8c:67:48 2.03.00  1      NOK    1
1683350301129319936 p     sensorBoard               External audio            production        b8:27:eb:8c:67:48          1      OK     1
        #+END_PLAIN
      - uwb
        #+BEGIN_PLAIN
> SELECT * FROM meta_uwb LIMIT 10
name: meta_uwb
time                admin board       child          enable location mode       name node              revision sector subsector
----                ----- -----       -----          ------ -------- ----       ---- ----              -------- ------ ---------
1683318692166120064 p     sensorBoard uwbCfg;uwbData 1      External production uwb  b8:27:eb:8c:67:48 3.00.00  1      1
        #+END_PLAIN
      - uwbCfg
        #+BEGIN_PLAIN
> SELECT * FROM meta_uwbCfg LIMIT 10
name: meta_uwbCfg
time                address admin antdelayrx antdelaytx board       channel datarate location mcu mode   mode_1     name   node              nssfd pac panid power prf prflength revision sector status subsector trim
----                ------- ----- ---------- ---------- -----       ------- -------- -------- --- ----   ------     ----   ----              ----- --- ----- ----- --- --------- -------- ------ ------ --------- ----
1683318692181120064 2       p     0          0          sensorBoard 5       6800     External uwb normal production uwbCfg b8:27:eb:8c:67:48 0     8   1     255   64  128       2.04.00  1      INIT   1         15
1683318692324120064         p                           sensorBoard                  External uwb        production        b8:27:eb:8c:67:48                                              1      OK     1
        #+END_PLAIN
      - uwbData
        #+BEGIN_PLAIN
> SELECT * FROM meta_uwbData LIMIT 10
name: meta_uwbData
time                admin board       location mcu mode       name    node              revision sector status subsector
----                ----- -----       -------- --- ----       ----    ----              -------- ------ ------ ---------
1683318692183120064 p     sensorBoard External uwb production uwbData b8:27:eb:8c:67:48 2.03.00  1      NOK    1
1683318692324120064 p     sensorBoard External uwb production         b8:27:eb:8c:67:48          1      OK     1
        #+END_PLAIN
      - thermalImgHd
        #+BEGIN_PLAIN
  > SELECT * FROM meta_thermalImgHd LIMIT 10
  name: meta_thermalImgHd
  time                admin board       leptonVersion location mcu     mode       node              sector status subsector
  ----                ----- -----       ------------- -------- ---     ----       ----              ------ ------ ---------
  1683309571571892224 p     sensorBoard 2             External thermal production b8:27:eb:8c:67:48 1      OK     1
        #+END_PLAIN
  - collectd
    - Measurements
      #+BEGIN_PLAIN
> SHOW MEASUREMENTS
name: measurements
name
----
cpu_value
df_value
disk_io_time
disk_read
disk_value
disk_weighted_io_time
disk_write
entropy_value
interface_rx
interface_tx
irq_value
load_longterm
load_midterm
load_shortterm
memory_value
processes_value
swap_value
users_value
      #+END_PLAIN
  - En consultant le dashboard, observe qu'on a l'air de produire 1Mo de données par minute
    - Donc 1Go toutes les 16h40
    - Dispose de ~100Go d'espace de stockage
    - Peut donc tourner ~70 jours avant de run out of space
    - Donc pas le facteur le plus limitant du système
  - Plusieurs measurements ne sont que peu utilisés en mode autonome
    - Les measurements correspondants aux events des mcu ayant des children (audio, bf707, cc2650, esensor, sensor, uwb)
      - Dans ce cas, n'a qu'un event pour indiquer que le mcu s'est sync
    - event_asx340 a l'air à déclenchement unique
      - Deux events enregistrés au même timestamp (au lancement?), depuis rien
      - J'ai rien dit, les timestamps sont différents
      - Vu sa période d'après les infos stockées dans meta, i.e. 1000000, ça a du sens
        - Donc toutes les 16min40 si je me trompe pas
    - Les measurements meta_
      - Indiquent seulement la mise en route et la configuration initiale des capteurs
  - Ces measurements disparaissent donc après la 1ère réinitialisation de la BD
  - Les différentes entrées permettent de retrouver de quel mcu dépend chaque capteur
    - audio gère stream
    - bf707 gère asx340
    - cc2650 gère rfGiga
    - esensor gère airInfo;airQuality;rgbwLuminosity;uvLuminosity;telemeter;accelerometer;gyroscope;magnetometer
    - sensor gère airInfo;airQuality;rgbwLuminosity;uvLuminosity;telemeter;accelerometer;gyroscope;magnetometer
    - thermal gère thermalImgHd;thermalImgLd;
    - uwb gère uwbCfg;uwbData
      - Qui n'ont pas d'avoir leurs propres events
  - Plusieurs questions
    - Qu'est-ce asx340 ?
      - Quel est son rôle ?
    - Qu'est-ce que cc1310 ?
      - Un mcu sans enfant, qui ne se sync pas
      - Ne voit cependant pas d'entrées correspondantes
      - Quel est son rôle ?
    - Qu'est-ce que uwb ?
      - Un mcu avec des enfants ? uwbCfg et uwbData me semblent pas être des capteurs
      - Pas réussi à observer le moindre event de ce côté
    - Pourquoi doubler une partie des capteurs ?
      - Les mcu esensor et sensor ont l'air de proposer le même ensemble de capteurs
      - Sauf que sensor est sous une vitre de plexiglas, donc quid de la pertinence des données sur l'air, la luminosité ?
      - Mickaël m'a répondu que désactiver ces capteurs lors du fonctionnement en mode autonome fait partie des choses à faire
  - asx340
    - S'agit d'un capteur d'image
  - cc1310
    - Est censé avoir un enfant rfSubGiga
    - Donc un module radio émettant sur des fréquences < 1GHz ?
    - Un module similaire à cc2650/rfGiga je suppose
  - uwb
    - Semble être un module de communication
    - Certains champs de ses messages meta font mention d'antennes d'après la doc
    - Ultra-Wideband (UWB)
  - On retrouve donc plusieurs modules liés aux communications
    - rfGiga
    - rfSubGiga
    - uwb
    - Aucun n'a jamais été utilisé ?
- SmartSense: Intégrer les modifications effectuées à la branche *main*
  - Mickaël a validé la MR, mais a fait plusieurs retours
  - Faudrait soit
    - Y répondre
    - Créer des issues qui correspondent
      - Histoire d'en conserver une trace
      - Et de lister les tâches restantes
  - [X] Problème de crash d'InfluxDB
    - Création d'une issue
  - [X] Ajout de tests pour la réception et le traitement de commandes
    - Création d'une issue
  - [X] Ajout de tests pour la BD "collectd"
    - Pas trop sûr de quoi ajouter comme tests
    - À part check l'existence de la BD
  - [X] Correction du secteur, sous-secteur et nodeId pour les topics de test
- SmartSense: Intégrer la branche *refactor/split-mqtt-interface*
  - [X] Rebase sur *main*
  - [X] Ouvrir la MR
- SmartSense: Préparer la branche *refactor/main-app* pour intégration
  - Rebase sur *refactor/split-mqtt-interface*
  - En a profité pour
    - Drop les commits équivalents
    - Rework le commit rendant optionnelles les instances de *MqttInterface* au passage
      - Préfère continuer à les instancier dans *mainApp.startProcess()*
** Semaine du <2024-01-29 Mon> au <2024-02-02 Fri>
*** Planned
**** DONE SmartSense: Rechercher outil pour refactorer le code du projet vis-à-vis des conventions Python
CLOSED: [2024-01-29 Mon 17:00]
- Pas mal de retours de Pylint sur le code correspondent à un non-respect des conventions Python
  - Noms de modules, de fonctions et de méthodes
- Voir si un outil permet d'automatiser ce type de correctifs
**** DONE SmartSense: Refactor *MqttInterface*
CLOSED: [2024-01-31 Wed 10:26]
- Ne plus hériter de *mqtt.Client*
  - Actuellement composant dans un état bizarre
  - Hérite des méthodes mais pas des attributs car n'appelle jamais le constructeur de *Mqtt.Client*
  - Déclenche des warnings et même erreurs si on manipule un peu trop le composant
    - e.g. ne peut pas surcharger /on_subscribe()/
- Mettre en place un Enum pour gérer le niveau de QoS des messages
  - Passe directement les valeurs 0, 1 et 2 pour le moment
  - MQTT n'offre pas du tout les mêmes garanties en fonction du niveau choisi
  - 0: At most once
  - 1: At least once
  - 2: Exactly once
  - Serait plus parlant d'utiliser un type qui précise cela
- Refactor /processDataForInfluxDBEmbedded()/
  - Décomposer en fonctions
  - Ne fait rien si /not self.subscriber/
    - Vérifier que c'est un comportement souhaité
    - Me parait error-prone perso
- Séparer l'interface avec le broker MQTT avec l'interface avec la BDD InfluxDB
  - IMO *MqttInterface* devrait servir à interagir avec le broker MQTT
  - L'interaction avec la BDD InfluxDB devrait être géré par un autre composant spécialisé
    - Qui plus est, l'interaction avec la BDD est plus limitée, i.e. write-only
  - Permettrait ainsi de rendre plus clair le code
  - E.g. composant n'interagit pas avec la BDD si le flag /mqttEnabled/ est activé
    - Même dans le cas où le flag /influxDbEmbedded/ est lui aussi activé
**** DONE SmartSense: Nettoyer *mainApp*
CLOSED: [2024-02-01 Thu 14:39]
- Déplacer le code du scope global du module dans une fonction /main()/
- Factoriser le code de /startProcess()/
- Décomposer en fonctions /routeIncomingMqttMessages()/
**** IN-PROGRESS SmartSense: Ajouter des tests pour *DataToLocalInfluxDB.parseMqtt()*
- J'ai atteint la limite du refactoring que je peux faire dans le projet en ayant à peu près confiance
- Et n'ayant pas de précisions sur les évolutions à apporter
- Serait préférable de consolider les tests pour le moment
- Pour le moment, vérifie le bon fonctionnement de *parseMqtt()* avec un payload correct
- Vérifier pour d'autres payloads corrects
- Vérifier pour payload invalide
**** IN-PROGRESS SmartSense: Intégrer les modifications effectuées à la branche *main*
- J'ai fini de mettre en place une première série de tests
- Avant d'aller plus loin et d'effectuer de nouvelles modifs
- Serait bien de me poser avec Mickaël pour reviewer mes branches et discuter de ce que j'ai fait
**** IN-PROGRESS SmartSense: Intégrer la branche *autonomous-node* à la branche *main*
- Cette branche a l'air d'apporter des workarounds pour les problèmes constatés lors de l'utilisation du noeud SmartSense en mode autonome
- Notamment, exporte et reset la DB périodiquement pour éviter le mécanisme de compression des shards
  - Qui a l'air d'être trop couteux pour tourner sur le noeud
- Améliore aussi la lisibilité du code
*** Done
- SmartSense: Intégrer les modifications effectuées à la branche *main*
  - J'ai notifié Mickaël que j'ai push mes modifications
  - Et lui ai précisé que j'aimerais une validation
- SmartSense: Intégrer la branche *autonomous-node* à la branche *main*
  - J'ai rebase ma branche *add-tests* sur la branche *autonomous-node*
  - Notamment en modifiant les commits impactés par les modifications de cette branche, i.e.
    - feat(formatter): add ruff
    - test(dataToLocalInfluxDB): edit test to verify buffering mechanism
  - Pushé cette branche sur le repo
  - Ouvert une MR décrivant les modifs globales de la branche
  - Ai demandé à Mickaël de valider cette MR
- SmartSense: Rechercher outil pour refactorer le code du projet vis-à-vis des conventions Python
  - Pas trouvé d'outils qui fait cela
  - Le plus proche que j'ai vu est : https://github.com/hhatto/autopep8
  - Mais ne fait que des transformations autour des whitespaces
    - A un mode aggressif
    - Mais ne propose d'autofix que les règles E711 et E712
    - Moi c'est la C0103 qui m'intéresse
  - Je pense que je suis bon pour faire ça "à la main"
- SmartSense: Refactor *MqttInterface*
  - [X] Séparer l'interface avec le broker MQTT avec l'interface avec la BDD InfluxDB
    - [X] Déplacement de /processDataForInfluxDBEmbedded()/ dans son propre module
      - Permet de simplifier les deux composants
        - Pas de mode "subscriber" pour *influxdb_interface*
        - Plus de mode "mqttEnabled" et "influxDbEmbedded" pour *MqttInterface*
      - Pose plusieurs questions cependant
        - Où déplacer/comment retravailler le code simulant une réponse du service de provisioning ?
          - Permettrait de se débarrasser de la *Queue* dans le sens *influxdb_interface* -> *mainApp*
          - Nécessite de comprendre le but de ce morceau de code
        - Où instancier et dans quelles conditions instancier *influxdb_interface* ?
          - Liée à cette question de provisioning
        - Nécessite aussi de savoir s'il est possible de cumuler un broker MQTT et une base de données locale InfluxDB
        - I.e. doit-on découpler le provisioning (setup?) du noeud du broker MQTT ?
    - Concernant le provisioning
      - Plusieurs messages concernent le provisioning
      - Le message sur le topic "provisioning/{self.currentSite}/node/{self.id}"
        - Permet de set les valeurs requises pour générer les topics
          - mode, location, secteur, sous-secteur
        - Et de préciser le port du broker MQTT lié au secteur
          - Y a plusieurs brokers ?
        - Dans le cas du mode autonome, utilise une valeur dummy (0) comme port pour le broker MQTT
      - Les messages sur les topics "provisioning/p/{MyApp.locationPath}/{MyApp.id}/rpiBoard/{ina}/consumption"
        - Plusieurs devices INA
          - Poe
          - Rpi
          - Sensor
          - Ext1
          - Ext2
        - Chacun va être à l'origine d'un message de provisioning sur son topic dédié
        - Permet d'obtenir la fréquence d'échantillonnage à utiliser si je pige bien
      - Les messages sur les topics "provisioning/a/{MyApp.locationPath}/{MyApp.id}/{tcl}"
        - Semble être conçu pour supporter plusieurs devices
        - En pratique, y en a qu'un seul pour le moment
          - Et donc qu'un seul suffixe pour le topic : "rpiBoard/TLC59108/leds"
        - De même, semble concerner la fréquence d'échantillonnage
    - [X] Découplage du self provisioning et de *MQTT/InfluxDBInterface*
      - Ajout d'un flag isProvisioningViaMQTT
      - Spécifie si le noeud doit se provisionner via MQTT
        - Dans ce cas envoie le 1er message
          - Sur le topic "provisioning/{self.currentSite}/node/{self.id}"
        - Et attend la réponse avant de passer à la suite
      - Sinon utilise d'emblée les valeurs dummy pour la génération de topics et le broker du secteur
      - Et intercepte les messages des modules *InaManager* et *TclManager* concernant le provisioning
        - Simule lui-même les réponses au lieu de déléguer au module *MQTT/InfluxDBInterface*
  - [X] Mettre en place un Enum pour gérer le niveau de QoS des messages
  - [X] Ne plus hériter de *mqtt.Client*
    - J'en ai profité pour refactorer le code et virer le code inutilisé
      - Par exemple /setCallbackOnMessage()/
    - Un cas particulier est celui du paramètre /protocol/ du constructeur
    - Dans la version d'origine de *MqttInterface*, s'agit à la fois
      - D'une propriété de la classe héritée de *mqtt.Client*, qui a pour valeurs possibles MQTTv31, MQTTv311 ou MQTTv5
        - Constantes fournies par *mqtt*
      - D'un flag pour déterminer la valeur d'une autre propriété, /transport/, qui a pour valeurs possibles "tcp" et "websocket"
    - Sauf que /protocol/ n'est jamais spécifié dans le moindre appel au constructeur de *MqttInterface*
      - Donc inutilisé et on repose donc sur la valeur par défaut de /transport/ : "tcp"
    - A donc supprimé le paramètre /protocol/
      - Voir si cela pose un problème
    - Rencontré quelques difficultés à faire fonctionner les tests
      - La connexion au broker se faisait correctement
      - L'envoi de messages aussi
      - Mais la réception, via *MqttInterface* ou *mqtt.Client* directement, ne se produisait pas
      - C'est tombé en marche, mais sans que je n'arrive à identifier le problème exactement
      - Trouvé, il s'agissait d'une erreur dans la callback /on_connect()/
      - Essayais d'accéder à /self.nodeId/, qui correspond à cet instant à /client.nodeId/ et non à /mqttInterface.nodeId/
        - Propriété non définie
      - Étrangement, fait planter silencieusement le client MQTT
      - De plus, utilisais dans tous mes tests une instance de *MqttInterface* en mode subscriber
        - Et donc exécutant les lignes de code problématiques
    - A pu en profiter pour rework le test "receive_msg_from_broker"
      - Surcharge callback /on_subscribe()/ pour déclencher l'envoi du message de test
      - Au lieu d'utiliser le workaround non-déterministe "j'attends un peu que l'instance *MqttInterface* se soit connectée au broker"
  - J'ai mes différentes modifs prêtes sous la forme de branches
  - Reste plus qu'à les faire valider
    - En profiter pour voir ce paramètre étrange /protocol/ et son impact sur /transport/
- SmartSense: Refactor *mainApp*
  - [X] Déplacer le code du scope global du module dans une fonction /main()/
  - [X] Utilisation de f-strings
  - [X] Rendre l'instanciation des *MqttInterface* dépendantes de la config
  - [X] Ajout d'une vérification de la config
    - Stop l'application si les sorties MQTT et InfluxDB sont toutes deux désactivées
    - Quel intérêt dans ce cas là ?
  - [X] Ajout d'un Enum pour représenter les différents noms de process
    - Permet l'utilisation de strings codées en dur
    - Et les erreurs que ça peut engendrait
  - [X] Utilisation de match/case au lieu de if/elif
  - [X] Factorisation du code de /startProcess()/
    - Mise en place d'une méthode /startAndRegisterProcess()/ qui se charge de créer, démarrer et enregistrer le process
    - Utilisation de cette méthode dans /startProcess()/
  - [X] Décomposition de /routeIncomingMqttMessages()/
    - Identifie 2 types de messages
      - provisioning
      - cmd
    - Provisioning
      - Pas bien conséquent, peut faire l'objet d'une fonction
    - Cmd
      - Là par contre, y a de multiples cas à gérer
      - À décomposer en sous-fonctions
    - Par contre, remarque un détail étrange
      - Certains messages peuvent déclencher plusieurs réactions
      - Par exemple, un même message peut déclencher les bouts de code suivants
        - https://gitlab.inria.fr/smartsense/3douest/node-app/smartsense-node-app/-/blob/main/mainApp.py?ref_type=heads#L144-147
        - https://gitlab.inria.fr/smartsense/3douest/node-app/smartsense-node-app/-/blob/main/mainApp.py?ref_type=heads#L194-205
      - Est-ce volontaire ?
    - Autre point étrange
      - Pour certains messages, le topic n'a aucun rôle
      - E.g. https://gitlab.inria.fr/smartsense/3douest/node-app/smartsense-node-app/-/blob/main/mainApp.py?ref_type=heads#L218-240
        - Le seul requirement au niveau du topic est sa taille, i.e. >=8
        - Mais le reste, osef
      - En fait, je pense que c'est bien ça : on s'en fout du topic
      - Le check de la taille du topic ne sert qu'à se protéger d'une erreur lors de la récupération de la target
    - Interrogation supplémentaire
      - Les commandes ne ciblent pas des noeuds spécifiques ?
      - À aucun moment on ne fait un filtre sur le topic par rapport à l'identifiant du noeud
      - Ah si, c'est implicite
      - Puisque le noeud s'abonne qu'aux topics avec son nodeId, ne reçoit que les messages le concernant
- SmartSense : Ajouter des tests pour *DataToLocalInfluxDB.parseMqtt()*
  - Pensais juste ajouter des topics à liste des valeurs possibles que peut retourner /getTopic()/
  - Mais vu que j'utilise cet helper à plusieurs reprises, doit faire gaffe aux valeurs proposées
  - Peut pas proposer des topics concernant
    - Le provisioning
    - Des cmd
    - Étant dans un autre mode que production
  - Donc reste des events
  - /getTopic()/ est utilisé conjointement avec /getPayload()/
    - Les fusionner ?
- SmartSense: Réflexions
  - Comment mettre en place et maintenir un protocole de communication ?
    - SmartSense utilise des messages pour communiquer à la fois entre les noeuds et le serveur
    - Mais aussi entre les différents modules du noeud
      - e.g. via les topics et payload
    - Pour le moment, ces messages sont construits et parsés à la main à différents endroits du code
      - Les modules tels que *InaManager* créent les messages
      - Les transmettent à *MainApp* qui les parse pour les router
      - Ou se self-provision
      - Idem pour les messages du serveur que *MainApp* reçoit via le client MQTT
    - Approche me parait error-prone
      - Quid de quand on décide de modifier le topic utilisé pour un type de message ?
        - E.g. pourquoi les messages provenant du module INA sont marqués comme niveau public ?
        - Et les messages du module TLC sont marqués comme niveau admin ?
        - Uniformiser ?
      - Comment vérifier que l'on a traité tous les cas ?
    - Et peu lisible
      - Détermine le message reçu en checkant des morceaux de ce dernier
      - Et déclenche des actions en réaction
      - Mais sans vraiment nommer/expliciter ce qui est fait
      - Au lecteur de recoller les morceaux
  - Est-ce vraiment InfluxDB qu'on veut utiliser dans le cas du mode autonome ?
    - À voir les traitements que l'on va effectuer
    - Et les données qu'ils requièrent
    - Mais plusieurs questions se posent
    - Est-ce que la dimension temporelle va être très importante ?
    - Est-ce qu'on ne peut pas reproduire cette dimension temporelle avec une fenêtre glissante des entrées ?
    - Grosso modo, va-t-on à un moment query la BDD locale ?
    - Pour quelles raisons le choix s'est porté sur InfluxDB pour le SGBD embarqué lors de la conception du mode autonome ?
      - Si c'est juste une question de compatibilité/d'export avec la BDD qui tourne sur le serveur, est-ce qu'un fichier ne suffit pas ?
- SmartSense: Compréhension du code
  - *TlcManager*
    - Gère les leds du noeud SmartSense
    - Reçoit des commandes pour paramétrer les leds
    - Envoie ses données meta au provisioning puis lors d'une commande ("cmd/.../nodeId", "action=get *")
  - *InaManager*
    - Monitore l'alimentation des différents ports de la raspberry
      - poe: Power Over Ethernet ?
      - rpi: Pourquoi il y a aussi la rpi elle-même dans la liste ?
    - Reçoit des commandes pour
      - get sa configuration
      - set sa période
    - À l'issue d'une période, envoie les données meta de la conso électrique de chaque port
  - *UsbBoardManager*
    - Gère les différentes sondes du capteur
    - Reçoit des commandes pour interagir avec les sondes
      - Démarrer ou stop les sondes
      - Lire les métas des sondes
      - Transmettre les commandes aux sondes
      - Aussi une commande "timestamp"
        - Permet de décaler les timestamps sur les mesures futures
        - Soit à partir d'un offset fourni
        - Soit à partir d'un timestamp calculé sur le coup
        - Comprends pas trop comment cela fonctionne
    - Envoie dès que possible les données collectées par les sondes
  - *RpiGpioManager*
    - Deux instances
      - Une de *MainApp*
      - Une de *UsbBoardManager*
      - Safe ?
    - Gère l'alimentation des différents ports de la raspberry
      - SensorBoard
      - Ext1 et Ext2
      - GlobalSync ?
  - *SensorBoardManager*
    - N'est plus utilisé actuellement
    - Ancêtre de *UsbBoardManager* ?
    - Lui ressemble beaucoup en tout cas
  - *Syncer*
    - Étant donné un timestamp, attends que celui-ci arrive
    - Utilisé par *MainApp.syncAll()*
    - Pige pas trop son fonctionnement
      - Instancie un *RpiGpioManager* avant de se mettre en attente
      - Utilise *RpiGpioManager.globalSync()* une fois le timestamp arrivé
      - Comment cet appel peut-il aider à synchro les différentes sondes ?
      - Sert p-e plutôt à synchroniser les différents noeuds
** Semaine du <2024-01-22 Mon> au <2024-01-26 Fri>
*** Planned
**** DONE S'approprier SmartSense/smartsense-node-app
CLOSED: [2024-01-29 Mon 10:33]
- On est en train de revoir les priorités avec l'arrêt maladie de Guillaume
- Serait préférable que je passe sur SmartSense en attendant son retour
- Les différentes tâches identifiées concernent principalement le capteur SmartSense
  - Ajout d'une couche réseau WiFi
  - Ajout de traitements en local des données collectées
    - i.e. sur le capteur
  - Correction des bugs rencontrés lors de l'utilisation de la BDD en local
    - Dans la version du capteur pour un fonctionnement autonome
    - Le capteur fait tourner une instance de la BD, InfluxDB, en local
    - Mais lors de leurs expériences, ont constaté des crashs de la BDD
      - Parfois au bout de plusieurs heures
- Il serait donc intéressant que je rentre rapidement dans ce projet
**** DONE Mettre en place des tests pour MQTTInterface
CLOSED: [2024-01-29 Mon 10:33]
- Pistes de tests possibles
  - Se connecte bien au broker
    - Variante not subscriber
  - Si je fournis un message valide à l'instance MQTTInterface, il est bien publié sur le broker
    - Variante avec message invalide
  - Si je fournis un message valide au broker, il est bien récupéré par l'instance MQTTInterface
    - Variante avec message invalide
*** Done
- S'approprier SmartSense/smartsense-node-app
  - Pistes de travail
    - Identifier les dépendances
    - Mettre en place un gestionnaire de dépendances
      - Poetry est un bon candidat
    - Mettre en place un linter
      - pylint : https://www.pylint.org/
      - Ruff : https://astral.sh/ruff
    - Setup un task runner
      - poethepoet : https://github.com/nat-n/poethepoet
    - Automatiser le déclenchement des outils
      - Hook pré-commit
      - Config VSCode
    - Mettre en place un autoformatter
      - Ruff : https://astral.sh/ruff
      - Black : https://github.com/psf/black
      - isort: https://github.com/PyCQA/isort
    - Mettre en place un outil d'analyse des types
      - mypy : https://www.mypy-lang.org/
      - pyright : https://github.com/microsoft/pyright
  - Getting started
    - pipx install poetry
    - pipx install poethepoet
    - poetry add --group dev pylint
    - poetry add --group dev ruff
    - poetry add --group dev isort
  - Dépendances identifiées
    - influxdb
      - https://pypi.org/project/influxdb/
    - intelhex
      - https://pypi.org/project/intelhex/
    - ntplib
      - https://pypi.org/project/ntplib/
    - paho-mqqt
      - https://pypi.org/project/paho-mqtt/
    - pi-ina219
      - https://pypi.org/project/pi-ina219/
    - pyftdi
      - https://pypi.org/project/pyftdi/
    - pyserial
      - https://pyserial.readthedocs.io/en/latest/pyserial.html
    - RPi.GPIO
      - https://pypi.org/project/RPi.GPIO/
    - smbus2
      - https://pypi.org/project/smbus2/
    - spiflash
      - https://pypi.org/project/pyspiflash/
      - A pour dépendance pyftdi et pyserial
  - Rencontre une erreur lors de l'installation de
    - pi-ina219
    - RPi.GPIO
  - Une brève recherche m'informe que c'est parce qu'il me manquait une dépendance système
    - sudo dnf install python3-devel
  - J'ai pu installer les dépendances restantes
  - Obtient les erreurs suivantes
    - Module RPi.GPIO has no setmode/BCM/setup/.../OUT member
    - No name 'SMBusWrapper' in module 'smbus2'
  - SMBusWrapper
    - Le changelog de la librairie indique la suppression de la classe SMBusWrapper au profit de SMBus
    - Voir https://github.com/kplindegaard/smbus2/blob/master/CHANGELOG.md#040---2020-12-05
    - Remplacer toutes les occurrences de SMBusWrapper par SMBus corrige l'erreur relevée par pylint
  - RPi.GPIO
    - A tenté de lancer l'interpréteur python pour jouer avec ce module et voir ce qui pouvait poser problème
      - poetry shell
      - python3
      - import RPi.GPIO as GPIO
    - Mais rencontre l'erreur suivante
      - RuntimeError: This module can only be run on a Raspberry Pi!
    - Ce qui peut p-e expliquer l'erreur rencontrée
      - Le linter rencontre p-e des difficultés à gérer le module, si ne peut pas importer ce dernier
  - Comment résoudre ça ?
    - Dev sur raspberry/VM ?
  - J'ai tenté d'émuler la raspberry et de déployer l'environnement de dev dessus, histoire de tenter le coup
    - Setup la raspberry et les deps de dev
      - sudo apt update; sudo apt full-upgrade
      - sudo apt install python3-pip
      - sudo apt install python3-venv
      - python3 -m pip install --user pipx
      - python3 -m pipx ensurepath
      - source ~/.bashrc
      - pipx install poetry
      - pipx install poethepoet
      - poetry install --no-root --with dev
    - Transférer le projet sur la raspberry emulée
      - scp -P 2222 -r . pi@localhost:/home/pi/smartsense-node
  - Mais lors de l'install de poetry, j'ai rencontré un problème de stockage
    - La raspberry émulée ne dispose que de 1.7Go de stockage, et il ne m'en restait que 20Mo à ce stade
  - Comment allouer plus d'espace à la machine ?
    - Création d'une image à partir de l'image raspbian
      - qemu-img dd -f raw -O qcow2 if=2023-12-05-raspios-bullseye-arm64-lite.img of=rpi-bullseye.qcow2
      - qemu-img resize rpi-bullseye.qcow2 8G
    - Resize de la partition / une fois le système démarré
      - Suivi le tuto : https://raspberrypi.stackexchange.com/questions/499/how-can-i-resize-my-root-partition
      - Commandes
        - sudo fdisk /dev/mmcblk0
        - Suppression de la partition / (d)
        - Création d'une nouvelle partition / (n)
          - Bien préciser comme start number le start number de la partition existant précédemment
        - sudo reboot
        - sudo resize2fs /dev/mmcblk0p2 (p2 correspondant à la partition /)
        - sudo reboot
        - df -h (pour vérifier le résultat)
  - J'ai pu exécuter le linter sur la raspberry emulée
  - Malheureusement, rencontre la même erreur que sur ma machine
    - En démarrant l'interpréteur python et en essayant d'importer le module RPi.GPIO, retrouve le même message d'erreur
    - i.e. "Module can only be run on a Raspberry Pi!"
  - Pose la question de la librairie utilisée/à utiliser
    - Projet utilise : https://sourceforge.net/projects/raspberry-gpio-python/
      - Mais qui n'a pas l'air fonctionnel sur un autre système que RPi
        - Et encore, n'a pas l'air de fonctionner dans mon env virtuel
      - Dernier commit date de février 2022
      - Mais projet a l'air encore d'actualité
        - Des issues sont encore crées et attribuées au maintainer
        - Notamment pour dev en dehors de l'env RPi
    - Existe RPIO : https://github.com/metachris/RPIO
      - Une alternative à RPi.GPIO
        - Peut être utilisée à sa place sans modifications
      - Mais plus maintenue depuis fin 2022
      - 'Fin, repo archivé depuis fin 2022
      - Le dernier commit date de 2013
      - Est-ce compatible avec les modèles de RPi utilisés ?
    - Des posts abordent la question des différentes librairies
      - e.g. https://raspberrypi.stackexchange.com/questions/58820/compare-and-contrast-python-gpio-apis
    - Voir si on peut s'en sortir avec RPi.GPIO, i.e. dev facilement sur un autre env que RPi
    - Ou s'il est préférable de remplacer la librairie utilisée pour une plus adaptée à un process de CI
  - Suis tombé sur la librairie Mock.GPIO : https://github.com/codenio/mock.gpio
    - Via ce post https://stackoverflow.com/questions/51879185/how-to-mock-rpi-gpio-in-python
  - Permet de résoudre le problème posé par RPi.GPIO
  - J'ai expliqué à Mickaël ce que j'ai fait et que j'aimerais poursuivre par l'ajout de tests
    - Semble d'accord
    - Souhaite juste limiter le temps passé à faire des tests
  - Pour le moment, j'ai fait une branche regroupant mes changements et ouvert une MR
  - Ok maintenant, que faire ?
  - Serait intéressant de retravailler mainApp et MQTTInterface
  - MQTTInterface
    - A trop de responsabilité IMO
      - Permet au noeud d'interagir avec le broker MQTT
        - Établir la connexion, publier les données collectées sur le broker, gérer les messages reçus via le broker et gérer les déconnexions
      - Permet au noeud d'interagir avec la base de données InfluxDB
        - Instancie le composant se connectant avec la DB et permettant d'y enregistrer les données collectées
      - Détermine à quel endpoint transmettre les données en fonction de sa config
        - Si mqttEnabled, envoie les données au broker
        - Sinon si influxDbEmbedded et subscriber, i.e. si influxDbEmbedded and subscriber and not mqttEnabled, envoie les données à influxDB
      - Gère aussi la config des capteurs dans le cas où le noeud est en mode autonome, i.e. il n'y a pas de communication via le broker pour indiquer les settings du noeud
    - IMO, devrait juste permettre l'interaction avec le broker MQTT
    - L'interaction avec la BDD devrait se faire via un autre composant
    - Et la config du noeud en mode autonome devrait être gérée par mainApp
  - mainApp
    - Pourquoi instancie deux MQTTInterface ?
      - Une subscriber, l'autre non
      - L'instance subscriber permet d'envoyer les messages ayant trait au provisioning
        - Donc utile qu'en mode connecté
        - Ah non, permet dans le cas du mode autonome de simuler une réponse du serveur
      - Les autres messages sont diffusés via l'instance not subscriber
        - Concerne le mode connecté et le mode autonome
    - Y a-t-il un intérêt à conserver ces deux instances ?
      - Permet d'avoir des threads séparés pour les types de message
      - Est-ce nécessaire ?
    - Pourquoi ce n'est pas lui qui instancie le composant pour interagir avec la BDD ?
    - Et qui détermine où sont propagées les données ?
  - Comment procéder ?
    - Avant de modifier le code et sa logique, je voudrais bien mettre en place des tests
  - Qu'est-ce que je veux tester ?
    - MQTTInterface
      - Se connecte bien au broker
        - Variante not subscriber
      - Si je fournis un message valide à l'instance MQTTInterface, il est bien publié sur le broker
        - Variante avec message invalide
      - Si je fournis un message valide au broker, il est bien récupéré par l'instance MQTTInterface
        - Variante avec message invalide
- Mettre en place des tests pour MQTTInterface
  - Peut faire les questions réponses dans un même test
    - i.e. demander à MQTTInterface d'envoyer un message sur un topic donné
    - M'être abonné au préalable à ce topic
    - Et ainsi vérifier que j'ai bien reçu le message
    - Et inversement
  - J'ai réussi à mettre en place un test simple
    - Créé un client MQTT
    - L'abonne à un topic
    - Publie un message sur ce topic via le helper de la librairie
    - Assert si mon client a bien reçu le message
  - Par contre, un test n'échoue pas par défaut si aucun assert n'est exécuté
    - Voir si on peut modifier ce comportement dans la config
  - [X] Ajout test publier sur le broker
    - But est de tester que si je fournis un message dans la Queue de l'instance MqttInterface, celui-ci est bien envoyé au broker
  - [X] Ajout test lire depuis le broker
    - But est de tester que si je poste un message sur le broker, MqttInterface transmet bien ce message à l'application via la Queue
    - Juste un problème pour publier le message sur le broker à temps
    - Si l'envoie dès que possible, MqttInterface loupe le message car n'a pas encore subscribe
    - Peut pas déclencher l'envoi du message en utilisant on_subscribe() de MqttInterface
      - Rencontre une erreur lorsque j'essaie de set on_subscribe()
      - Semble lié au fait que MqttInterface n'appelle jamais le constructeur de Client
      - Et ne dispose pas de tous les attributs qu'il est censé posséder
    - Workaround pour le moment en ajoutant une attente avant la publication du message
    - À corriger dans MqttInterface
  - [ ] Ajout test publier dans InfluxDB
    - But est de tester que si je fournis un message dans la Queue de l'instance MqqtInterface, celui-ci est bien envoyé à la BDD
    - Plusieurs détails à gérer
    - Tous les messages ne sont pas envoyés à la BDD
      - Un filtre est effectué pour ne stocker que les données intéressantes/pertinentes
      - Reste à comprendre les données attendues et les topics associés
    - L'écriture en BDD ne se fait pas à chaque donnée, mais une fois que le buffer dépasse un certain seuil
      - Doit donc procéder à l'envoi de suffisamment de données pour déclencher une écriture
      - Le seuil a l'air d'être 100 messages
      - P-e rendre paramètrisable cette donnée de façon à simplifier la validation des tests
    - Pour procéder par étapes, je vais déjà ajouter des tests sur DataToLocalInfluxDB
      - Composant chargé d'interagir avec InfluxDB, de formater la trame MQTT en une trame InfluxDB et de gérer l'écriture en BD des données
  - [X] Ajout test création de DB
    - But est de tester que DataToLocalInfluxDB créé bien une base de données à son instanciation
  - [X] Ajout test parseMqtt
    - But est de tester que DataToLocalInfluxDB transforme bien une trame MQTT en une trame InfluxDB
  - [X] Ajout test sendPointsToInfluxDB
    - But est de tester que DataToLocalInfluxDB écrit bien les données en BDD
      - Doit par contre atteindre la taille minimum pour déclencher une écriture
      - En attendant, données bufferisées
** Semaine du <2024-01-15 Mon> au <2024-01-19 Fri>
*** Planned
**** DONE Prendre en main le script de connexion aux brokers MQTT
CLOSED: [2024-01-16 Tue 13:38]
- Mickaël m'a partagé son script de test
- Voir pour l'essayer et le comprendre
**** DONE Résoudre problème d'accès aux fichiers sur WordPress
CLOSED: [2024-01-18 Thu 10:25]
- Lorsque je réplique mon serveur d'application WordPress, je constate que WordPress rencontre régulièrement un problème pour afficher les images
  - Les fichiers que j'ai uploadé moi-même pour créer la page
- Probablement dû au fait que le volume qui stocke ces images n'est pas partagé par l'ensemble des instances
- Étudier comment faire évoluer l'application pour corriger cela
**** DONE Résoudre problème d'authentification sur WordPress
CLOSED: [2024-01-18 Thu 10:25]
- Lorsque je réplique mon serveur d'application WordPress, je me retrouve à devoir me reconnecter à chaque changement de page
- Probablement dû au fait que mon cookie d'auth est valide pour une instance donnée, et est invalidé par les autres
- Étudier comment faire évoluer l'application pour corriger cela
**** DONE Se familiariser avec le concept d'Infrastructure as Code (IaC)
CLOSED: [2024-01-22 Mon 09:11]
- Plutôt que de setup manuellement Kubernetes sur ses machines
- Semblerait que la pratique soit d'automatiser son setup
- Process connu comme l'Infrastructure as Code
- Se renseigner et documenter à ce sujet
- Ressources rapides
  - https://learn.microsoft.com/en-us/devops/deliver/what-is-infrastructure-as-code
  - https://aws.amazon.com/what-is/iac/
- Guillaume mentionnait notamment l'outil Vagrant
  - https://www.vagrantup.com
**** IN-PROGRESS Automatiser la création d'un cluster de Raspberry virtualisé
- Plutôt que de travailler avec le cluster physique
- Serait intéressant d'apprendre à provisionner un cluster virtuel de Raspberry
- Permettrait de pouvoir créer un environnement pour dev et effectuer des tests
  - Notamment comment setup k8s ou équivalent sur un tel système
**** IN-PROGRESS S'approprier SmartSense/smartsense-node-app
- On est en train de revoir les priorités avec l'arrêt maladie de Guillaume
- Serait préférable que je passe sur SmartSense en attendant son retour
- Les différentes tâches identifiées concernent principalement le capteur SmartSense
  - Ajout d'une couche réseau WiFi
  - Ajout de traitements en local des données collectées
    - i.e. sur le capteur
  - Correction des bugs rencontrés lors de l'utilisation de la BDD en local
    - Dans la version du capteur pour un fonctionnement autonome
    - Le capteur fait tourner une instance de la BD, InfluxDB, en local
    - Mais lors de leurs expériences, ont constaté des crashs de la BDD
      - Parfois au bout de plusieurs heures
- Il serait donc intéressant que je rentre rapidement dans ce projet
*** Done
- Résoudre problème d'accès aux fichiers sur WordPress
  - Plusieurs pistes possibles
  - Modification de la config du volume dans la description de l'application
    - La configuration que j'ai utilisé précise que le volume persistant est en ReadWriteOnce
    - i.e. qu'un seul noeud peut l'utiliser en mode RW
    - Cohérent avec le problème constaté
    - L'option ReadWriteMany permet de spécifier qu'il sera utilisé par plusieurs noeuds
      - Permettrait ainsi de rendre accessible les fichiers à tous les noeuds en ayant besoin
      - Solution limitée cependant
        - En interne, fonctionne avec un NFS d'après ce que m'explique Guillaume
        - Les performances sont donc pas adaptées à une charge conséquente
    - A testé avec cette configuration, sans succès
      - L'image, de nouveau, n'est pas chargée régulièrement lors de l'affichage de la page
    - La raison m'échappe
    - Je commence à avoir un doute sur le fait que le volume soit correctement partagé par les noeuds
    - En explorant les containers, j'ai observé des différences
      - kubetcl exec -it <container> -- /bin/bash
      - Seul un container possède le fichier uploadé
      - Un fichier créé manuellement dans un container n'apparait pas dans l'arborescence des autres
    - En creusant, j'ai remarqué que la configuration pour la gestion des volumes pour un cluster avait été perdue
    - En réactivant cette config, cela fonctionne
      - Fichier uploadé bien disponible sur l'ensemble des instances
      - Modifications manuelles sont bien observables sur l'ensemble des instances
    - Effet de bord intéressant mais intriguant : corrige aussi le problème d'authentification
      - Comprend pas la logique derrière
  - Ajout d'un service de sync des volumes
    - Je suis surpris de ne pas trouver d'articles qui présentent cette solution et détaillent comment la mettre en place
    - Ni de trouver un outil/composant qui assumerait ce rôle
    - Les gens reposent sur des solutions customs à base de rsync ?
    - Tombé sur *VolSync*, un système de réplication async entre volumes dans ou entre clusters
      - Disponible ici : https://github.com/backube/volsync
      - Projet Red Hat
      - Pas sûr que l'outil soit adapté pour répliquer des fichiers en temps réel vu les cas d'usages présentés
        - Plutôt  l'impression que c'est pour propager des données à terme, pour résilience ou traitements à posteriori sur les données
        - cf. https://next.redhat.com/2021/08/23/introducing-volsync-your-data-anywhere/
    - Demander des précisions sur le service mentionné par Guillaume
  - Est-il sinon possible d'override le fonctionnement de WordPress pour héberger les fichiers ?
    - Plutôt que d'essayer de retomber sur nos pattes en ajoutant des rustines
      - Partager un même volume entre pods
      - Sync les volumes de nos pods
    - Serait-il pas mieux et possible de faire déléguer à WordPress la gestion des fichiers à un service tiers, dédié à cela ?
      - Je suppose que WordPress est assez flexible pour cela
    - Genre mettre en place son propre CDN
- Résoudre problème d'authentification sur WordPress
  - Comme évoqué précédemment, partager un même volume entre les instances WordPress a pour effet de bord de résoudre ce problème
    - D'une manière que je ne comprends pas
    - Quoique
    - Cela s'explique si le serveur ne conserve aucune donnée en mémoire entre 2 requêtes
    - Et recréé l'état, e.g. de la session, à partir des infos fournies par la requête, e.g. cookies, et de fichiers
    - Une rapide recherche confirme ce mode de fonctionnement
  - Donc c'est une approche pour résoudre le problème des sessions, mais p-e pas la plus adaptée/conseillée
  - Guillaume m'a conseillé de regarder du côté des sessions PHP partagées
- Formation SED - Bonnes Pratiques du Dev Logiciel
  - Dans toute équipe de recherche, y a correspondant SED pour entrer en contact
  - Existe un GitLab pour projets avec données confidentielles
    - https://gitlab-int.inria.fr
  - Tests et intégration continue
    - Tests métiers
      - Vérifier que son logiciel est compris et utilisé par les personnes devant l'utiliser
    - Analyse statique
      - Mettre en place linter/convention de codage
      - Utiliser des outils de vérification de la qualité du code
        - e.g. sonarqube
        - Voir si facilement pluggable/hookable au gitlab
    - Documentation
      - Existe gitlab-pages
      - Recommandations sur comment écrire la doc : https://smartbear.com/blog/13-things-people-hate-about-your-open-source-docs/
  - Licences conseillées
    - MIT
    - GPL/LGPL
    - BSD
- Prendre en main le script de connexion aux brokers MQTT
  - Dépendance
    - Ce script nécessite pour fonctionner l'installation d'une librairie pour instancier un client MQTT
      - pip install paho-mqtt
  - Ce script se connecte à ou plusieurs brokers MQTT de la plateforme SmartSense
    - Choix codé en dur
  - Il récupère les messages postés sur le topic, les décode et les affiche
  - S'interrompt au bout d'une minute
  - Fonctionne
  - Particulier au niveau de la connexion aux topics
    - Tous les topics n'ont pas l'air d'utiliser la même configuration
    - Notamment au niveau du port utilisé
      - Pourquoi ?
  - Semble associer un port différent à chaque zone
    - Plusieurs zones à Lannion, plusieurs à Rennes
  - Semble retrouver cette information directement dans l'URL d'un topic
    - e.g. "event/p/production/Rennes/0/E/..." indique un topic d'un capteur situé à Rennes, dans le secteur 0
    - Si j'ai bien pigé
    - Un peu confus sur la signification du champ suivant
      - Vaut 3 ou E en fonction des topics présentés
    - D'après la doc, indique le sous-secteur
      - Doc dispo ici, page 8 : https://gitlab.inria.fr/smartsense/3douest/documents/conception/-/blob/master/CDC-20190806-Design%20MQTT%20et%20InfluxDB-V1.4.pdf
- Se familiariser avec le concept d'Infrastructure as Code (IaC)
  - Un peu de mal à piger si Vagrant est adapté à notre use-case
    - Outil permettant de déployer des environnements
      - Instancie des VMs selon la configuration donnée
      - Exécute le/les scripts fournis
      - Copie une partie du FS dans la VM
    - On a probablement pas envie de déployer notre application à même les raspberry du serveur
    - Mais voulons-nous utiliser des VMs pour autant ?
    - Préférions-nous pas utiliser simplement des conteneurs ?
      - Installer k8s (ou plutôt k3s probablement) sur les raspberry
      - Configurer le cluster pour définir les noeuds et leurs rôles
      - Déployer l'application
  - A un intérêt donc, mais plutôt pour la partie dev/testing IMO
    - Pour provisionner/recréer le cluster de raspberry localement
  - Est-ce que son rôle s'arrête là ?
    - i.e. utiliser un autre outil pour setup le cluster k8s ?
      - Ansible ?
  - Serait intéressant de voir avec Khaled ce qu'il fait dans le cadre de ses expériences
    - Est-ce qu'il simule des raspberry ?
    - Quels outils il utilise ?
      - Pour provisionner les machines virtuelles
    - Est-ce qu'il a mis ses ressources, configurations et scripts à disposition ?
      - Genre dans son article
  - Il m'a donné accès à son repo avec tout les scripts pour son setup experimental
    - Dispo ici : https://gitlab.inria.fr/stream-processing-autoscaling/scalehub
  - De ce que j'ai compris
    - Réserve des noeuds sur g5k
    - En utilisant les IPs des machines attribuées, lance un script Ansible qui les préparent à la configuration
      - Setup SSH
    - Puis exécute un script Ansible qui installe k3s sur les noeuds
      - A rencontré des problèmes pour setup k3s, mais ne se souvient plus quoi
      - A commencé à creuser l'alternative mini-k0s
      - Mais a résolu son problème sur k3s
    - À partir de là, fait tout par le biais de k3s
      - Déploie des services supplémentaires en fonction de ses besoins
      - Prometheus, Grafana, Kafka, Flink
  - Par contre, ne fait aucune virtualisation des machines
    - Va falloir que je me débrouille pour cette partie là
  - Parcours le livre *Infrastructure as Code* de Kief Morris
- Automatiser la création d'un cluster de Raspberry virtualisé
  - Ressources :
    - Tuto suivant a l'air plutôt complet sur comment virtualiser une Raspberry : https://linuxconfig.org/how-to-run-the-raspberry-pi-os-in-a-virtual-machine-with-qemu-and-kvm
    - Celui-ci a l'air plus d'actualité : https://interrupt.memfault.com/blog/emulating-raspberry-pi-in-qemu
    - Ou celui-ci : https://brettops.io/blog/custom-raspberry-pi-image-no-hardware/
  - Pose la question de l'outil VM à utiliser
    - Souhaite émuler du ARM
    - Est-ce une bonne idée ?
  - Essayons, on jugera à l'essai
  - Pars donc sur l'émulation d'une Raspberry à l'aide de QEMU
  - Suivi du tuto https://interrupt.memfault.com/blog/emulating-raspberry-pi-in-qemu
  - Erreur rencontrée avec la dernière image de Raspberry OS
    - OS : https://downloads.raspberrypi.com/raspios_lite_arm64/images/raspios_lite_arm64-2023-12-11/2023-12-11-raspios-bookworm-arm64-lite.img.xz
    - usbnet: failed control transaction: request 0x8006 value 0x600 index 0x0 length 0xa
    - Aucun autre message ne s'affiche dans le terminal, qui ne répond plus
  - J'ai re-essayé en utilisant cette fois-ci la version précédente de l'OS
    - OS : https://downloads.raspberrypi.com/raspios_oldstable_lite_arm64/images/raspios_oldstable_lite_arm64-2023-12-06/2023-12-05-raspios-bullseye-arm64-lite.img.xz
    - Cette fois-ci, la Raspberry a l'air de se lancer
      - Retrouve l'erreur parmi les logs, mais n'a pas l'air bloquante
    - Pu in fine me logger au système
  - Ok, comment on instrumentalise ça avec Vagrant maintenant ?
  - Plutôt voir déjà comment on automatise le lancement de VMs avec Vagrant
  - Suivi le tuto : https://developer.hashicorp.com/vagrant/tutorials/getting-started
    - Étrangement, n'utilise pas virtualbox en provider par défaut
      - Je ne l'avais pas installé au moment où j'ai installé vagrant, probablement pour cela
      - Utilise donc libvirt à la place
      - Sauf que libvirt n'a pas l'air compatible avec toutes les boxes
        - Genre, celle du tuto
      - J'ai set la variable d'env
        - VAGRANT_DEFAULT_PROVIDER="virtualbox"
      - Mais n'a aucun impact à la création d'un env
    - Doit donc spécifier le provider au démarrage
      - vagrant up --provider="virtualbox"
    - A pu démarrer la VM, une Ubuntu 18.04.3, et s'y connecter en SSH
      - vagrant ssh
  - Maintenant, comment on lance plusieurs VMs avec Vagrant ?
  - Ça se fait bien, suffit d'en définir plusieurs dans le fichier de config
    - https://gitlab.inria.fr/mnicolas/vagrant-getting-started/-/blob/382bfe988d13dfbe450cb0b5e3ee459bfd70cdbd/Vagrantfile
  - Temps de s'intéresser à la partie réseau maintenant
  - Notamment comment SSH une VM depuis l'autre, et inversement
- S'approprier SmartSense/smartsense-node-app
  - Point d'entrée est mainApp
    - Instancie les différents composants logiciels du capteur
  - Pour le moment, identifie les composants suivants
    - ClientMQQT & PublisherMQQT
    - INAManager
    - USBManager
    - NTPManager
    - RpiGpioManager
    - FirmwareUpdateManager
    - TLCManager
    - Syncer
  - MQQT
    - Système de message brokers
    - Permet au noeud de communiquer avec le serveur
      - Remonter les données collectées
      - Mais aussi de recevoir des instructions
        - e.g. changement de configuration
  - NTPManager
    - Système de synchronisation d'horloges du noeud avec le serveur central
    - Du sens si on utilise une timeseries database
  - RpiGpioManager
    - Gère l'alimentation des ports GPIO de la Raspberry
    - À quoi correspondent ces ports ?
    - Dans le code, on retrouve la mention de
      - Sensor Board
      - Ext1 et Ext2
    - Peut supposer que la sensor board est la carte sur laquelle sont branchés les différents capteurs
    - Tandis que Ext1 et Ext2 correspondent aux ports disponibles pour brancher des extensions supplémentaires
      - cf. https://gitlab.inria.fr/smartsense/3douest/documents/conception/-/blob/master/SMARTSENSE-Module%20d'extension%20pour%20noeud.pdf
  - mainApp
    - Instancie l'ensemble des composants
    - Met en place les processus de contrôle périodique du bon fonctionnement du capteur
    - Sync son horloge
    - Alimente les différents capteurs du noeud
    - Démarre le process mqttManagerCmdProvisioning
      - Lit en boucle la Queue donnée en entrée en quête de messages
      - Dès qu'un message est détecté, le publie au MQTT Broker
    - Pas sûr de comprendre les lignes suivantes
      - https://gitlab.inria.fr/smartsense/3douest/node-app/smartsense-node-app/-/blob/main/mainApp.py?ref_type=heads#L378-381
      - Envoie par le biais du message broker un message au serveur
      - Mais dans quel but ? Que signifie provisioning dans ce contexte ?
  - Plusieurs réflexions sur le code et projet
    - Absence d'un gestionnaire de dépendances
    - Absence de tests
      - Pose la question de comment développer et tester
      - Est-ce que développe à même le capteur ?
      - Ou fait tourner le programme dans une VM pour tester ?
      - Est-ce que l'architecture différente ARM implique des étapes supplémentaires ?
      - Globalement, qu'est-ce qu'il faudrait faire pour mettre en place un process de CI ?
    - Absence de linter
    - Quelle méthodologie de travail ?
      - Si je veux faire des modifs
    - Absence de doc
  - Réflexions sur mainApp
    - startProcess()
      - Pourrait utiliser un enum plutôt que des chaines de caractères pour spécifier le process à démarrer
        - cf. https://docs.python.org/3/library/enum.html
      - À l'exception de usbBoardManager, la logique est la même pour chaque process
        - Seul l'instanciation du process change
        - Pourrait factoriser le code
  - Réflexions sur MqttInterface
    - run()
      - Pourquoi while True and self.stopLoop is False ?
        - Et non pas while not self.stopLoop ?
      - Pourquoi une attente active sur la Queue ?
        - Pas possible d'utiliser de l'event-based ?
        - Semblerait que non, d'après l'API
          - cf. https://docs.python.org/3/library/multiprocessing.html
      - Pourquoi le type Queue ?
        - Permet de passer des messages
        - Canal de diffusion avec plusieurs producers et subscribers possibles
          - cf. https://docs.python.org/3/library/multiprocessing.html#pipes-and-queues
        - Mais à messages à usage unique
          - i.e. lire un message le consomme
        - Ne supporte pas le pattern fan out du coup
        - Pas le plus pratique si on veut déclencher plusieurs traitements pour un même message
          - e.g. stocker en local et diffuser sur le réseau
        - L'utilisation que j'en vois pour le moment est d'un composant à un autre
          - De mainApp à mqqtInterface par exemple
        - Voir si c'est la structure de données la plus adaptée à notre use case finalement
      - Pourquoi prend en paramètre queueDataIn et queueDataOut ?
        - Puisque n'utilise pas queueDataOut de toute la méthode
        - Ne pourrait-on pas passer ces attributs au constructeur plutôt ?
** Semaine du <2024-01-08 Mon> au <2024-01-12 Fri>
*** Planned
**** DONE Régulariser situation du 02/01
CLOSED: [2024-01-09 Tue 14:36]
**** DONE Suivre cours de Guillaume sur les technologies cloud
CLOSED: [2024-01-10 Wed 11:47]
- Disponible ici : https://gitlab.inria.fr/pierre/sct-m1info
**** DONE Trouver des ressources sur Docker & Kubernetes
CLOSED: [2024-01-10 Wed 13:49]
- Au-delà du cours de Guillaume, existe des ressources pour rentrer plus en détails sur ces outils (talks, livres)
- Voir pour en trouver et les consulter
**** DONE Regarder *Kubernetes Design Principles: Understand the Why*
CLOSED: [2024-01-11 Thu 15:57]
- Talk en 2018 de Saad Ali, ingé Google de l'équipe sur k8s
  - Dispo ici : https://www.youtube.com/watch?v=ZuIQurh_kDk
**** DONE Adapter la configuration réseau pour clusters multi-nodes
CLOSED: [2024-01-11 Thu 16:42]
- Lors de l'ajout du 2nd Node à mon cluster minikube, j'ai eu le warning suivant
  - Cluster was created without any CNI, adding a node to it might cause broken networking.
- Voir ce que cela signifie et ce que je dois modifier
**** DONE Utiliser un driver pour Volume adapté aux clusters multi-nodes
CLOSED: [2024-01-11 Thu 17:01]
- La page tuto de k8s indiquant comment lancer un cluster multi-nodes mentionne un problème avec le driver pour Volume par défaut
  - https://minikube.sigs.k8s.io/docs/tutorials/multi_node/
- Renvoie à la page suivante :
  - https://minikube.sigs.k8s.io/docs/tutorials/volume_snapshots_and_csi/
- Voir si le problème est toujours d'actualité et si c'est bien la solution conseillée
**** DONE Prendre en main Kubernetes
CLOSED: [2024-01-12 Fri 13:15]
- J'ai atteint la partie du cours de Guillaume présentant Kubernetes
- Voir maintenant pour expérimenter avec histoire de creuser l'outil
- Ressources disponibles :
  - Le TP du cours de Guillaume : [[file:~/Documents/sct-m1info/support/pdf/tp08.orchestration.pdf]]
  - Le tuto de Digital Ocean sur faire fonctionner Kubernetes en local : https://www.digitalocean.com/community/tutorials/how-to-use-minikube-for-local-kubernetes-development-and-testing
**** DONE Déployer une application complexe avec k8s
CLOSED: [2024-01-15 Mon 08:45]
- Les tutos que je suis pour le moment se contentent de déployer des applications simples
  - I.e. Un pod faisant tourner un nginx
- Pour apprendre correctement k8s, serait intéressant de déployer une application composée de
  - Serveurs d'applications, répliqués
    - Avec un load balancer pour répartir la charge
  - Interagissant avec une BDD
    - Elle aussi répliquée ?
- Cela permettrait de creuser
  - La configuration et le déploiement de pods différents
  - Les interactions entre ces pods, potentiellement sur des noeuds différents
  - L'utilisation de volumes
  - L'utilisation de fichiers de description
- Exemple
  - *Deployment of multiple apps on Kubernetes cluster — Walkthrough* : https://wkrzywiec.medium.com/deployment-of-multiple-apps-on-kubernetes-cluster-walkthrough-e05d37ed63d1
*** Done
- Suivre cours de Guillaume sur les technologies cloud
  - CM5 - Services cloud réseau
    - S'intéresse aux différents services réseau mis à disposition par les cloud providers
    - Bien beau d'instancier des VMs/conteneurs
    - Mais doit leur attribuer une adresse IP privée
      - Et une adresse IP publique pour ceux qui doivent pouvoir être contactés de l'extérieur
      - Possède un pool d'adresses IPs qui vont être attribuées dynamiquement aux instances
    - Doit créer les routes de communication entre ces instances, et entre ces instances et le monde extérieur
      - Utilise des VLANs et probablement des techniques de SDNs
    - Doit aussi considérer l'aspect sécurité
      - Mettre en place des pare-feux, VPNs
      - Provider clouds proposent des services de pare-feux
        - FWaaS : FireWall as a Service
    - Finalement, pour la scalabilité, doit généralement mettre en place du load balancing
      - LBaaS : Load-Balancing as a Service
    - Questions
      - C'est quoi exactement la différence entre VLANs et SDNs ?
        - P-e lire un peu à ce sujet
        - *Cloud Network Virtualization: Benefits of SDN over VLAN*
          - Blogpost disponible ici : https://cloudsecurityalliance.org/blog/2021/06/25/cloud-network-virtualization-benefits-of-sdn-over-vlan/
          - De ce que je comprends, les VLANs ont initialement été conçus pour créer plusieurs réseaux virtuels au sein d'un même réseau local
            - Limité au sein du LAN
          - Pas les mêmes conditions que le cloud
            - Un single-tenant vs. multi-tenant
            - Pas la même échelle
          - Ne sont donc pas adaptés à ce nouveau cas d'usage
            - Particulièrement d'un point de vue sécu/isolation
          - L'approche SDN répond à ce nouveau besoin
            - Découple le /control plane/ du /data plane/, i.e. découple le routing de l'envoi effectif des messages
              - Un peu de mal à piger les implications de cela
              - Cela me paraît évident que ça doit être découplé
              - Ne dois pas comprendre les contraintes matérielles
            - Permet de configurer plus finement et simplement les firewalls
              - Adopte la politique du /default deny/, contrairement à l'existant
            - Protège d'attaques nativement
            - Conçu pour l'élasticité
        - *Network Virtualisation and the difference with VLANs, SDNs*
          - Blogpost disponible ici : https://craigread.cloud/network-virtualisation-and-the-difference-with-vlans-sdns/
          - Re-explique qu'un VLAN permet de diviser un LAN en de multiples réseaux
          - Explique que le VLAN n'est pas de la virtualisation de réseau
            - Pas moyen de prendre une snapshot du réseau, de le cloner ou déplacer
            - Pas sûr de comprendre de ce qu'on entend par cloner un réseau concrètement
              - Et de l'usage qu'est fait de cette fonctionnalité
          - Précise aussi que SDN n'est pas de la virtualisation non plus
            - Ne virtualise pas les composants, e.g. switchs et routeurs
            - Mais permet de les contrôler logiciellement
          - Mais que la virtualisation de réseau existe belle & bien
            - Permet de virtualiser le réseau complet, hardware compris
          - Quand utiliser SDN vs. Network Virtualisation ?
  - CM6 - Microservices
    - Porte sur l'évolution de l'architecture système des applications
    - Anciennement, architecture monolithique
      - Simple
      - Mais des limites
        - Pas de contrôle de droits d'accès sur les données par domaine/métier
        - Un bug d'un domaine/métier de l'application peut la faire crasher dans son entièreté
          - i.e. pas d'isolation
        - Difficile à scale
          - La base de données est un bottleneck
          - De part le fonctionnement des writes et des transactions
    - Architecture orientée micro-services
      - Décompose l'application en multitude de services
      - Chaque service doit avoir une fonctionnalité précise
        - Separation of Concern
      - Les services peuvent communiquer entre eux, si nécessaire, par le biais de leur API
      - Chaque service est responsable de ses données
        - Chaque service peut ainsi choisir ses outils, i.e. son SGBD, en fonction de ses use cases
      - Principes d'une architecture orientée micro-services
        - Se base sur : https://nirmata.com/2015/02/02/microservices-five-architectural-constraints/
        - Elastic : chaque service doit pouvoir scale up/down de manière indépendante des autres services
        - Resilient : un service doit crasher sans impacter les autres services
        - Composable : les services doivent proposer des APIs uniformes et conçues pour la composition
        - Minimal : un microservice doit être composé uniquement des entités fortement liées
        - Complete : un microservice doit être fonctionnellement complet
      - Pour la communication entre services, une approche éprouvée est d'utiliser un message broker
        - Permet de découpler les composants
        - Pas de blocage pour l'initiateur d'une requête pendant le calcul de la réponse
        - Permet de scale le service produisant la réponse en fonction de la workload de manière transparente
    - Aborde ensuite l'approche DevOps
      - Là aussi, devrais lire plus à ce sujet
      - *What is DevOps*
        - Disponible ici : https://about.gitlab.com/topics/devops/
        - Méthodologie consistant à coupler les tâches des équipes de développement et d'opérations (déploiement)
        - A pour but de
          - Mettre en place un cycle de développement incrémental
          - Livrer rapidement les nouvelles versions du logiciel
          - Améliorer la qualité du logiciel
        - Cela passe par
          - Collaboration approfondie entre les équipes dev et ops
            - Des équipes à objectifs intrinséquemment différents et parfois contraire
              - Dev : Faire évoluer rapidement l'application pour répondre aux retours
              - Ops : Garantir le bon fonctionnement de l'application
            - L'idée est ici de les faire faire cause commune
          - Incorporation et automatisation de bonnes pratiques
            - Tests, Livraison, Déploiement
        - Se base sur les 4 principes suivant
          - Automatisation des phases du cycle de vie du logiciel
            - Test, build, release
          - Collaboration et communication
            - Entre les anciennes différentes équipes
          - Amélioration continue et minimisation des pertes de temps
            - Automatisation des tâches répétitives
            - Identification perpétuelle de pistes d'amélioration
          - Focalisation sur les besoins des utilisateur-rices
            - L'automatisation des tâches permet de se focaliser sur les retours des utilisateur-rices
            - Et livrer rapidement une nouvelle version y répondant grâce à l'accélération du cycle de vie de l'application
  - CM7 - Conteneurs et Docker
    - Présente Docker
    - Rappelle qu'on a un intérêt à virtualiser
      - Permet d'isoler les différents composants d'une application
      - D'embarquer l'ensemble des dépendances
      - Et d'éviter les potentiels conflits, e.g. dépendances incompatibles
    - Mais que les VMs sont volumineuses, lentes à instancier et ajoutent un surcoût computationnel
    - Les conteneurs répondent aux mêmes problématiques
    - Mais de manière plus efficace
      - Reposent sur l'OS de la machine
        - Permet d'éviter l'utilisation coûteuse d'un hyperviseur
      - Reposent sur le système de layers
        - Permet de partager/factoriser des mêmes layers entre conteneurs
    - Précise cependant que Docker n'est un outil nativement conçu pour un usage dans le cloud
      - Conçu plutôt pour tourner sur une machine donné
    - Un orchestrateur est nécessaire pour cela
  - CM8 - Kubernetes et Orchestration de conteneurs
    - Les conteneurs, c'est bien
    - Mais dans un environnement cloud, ils ne sont pas suffisants par eux-mêmes
    - Entre autres, des besoins de
      - Scaling automatique
      - Détecter et redémarrer les conteneurs ayant une panne
      - Mettre en place des configurations réseaux avancées
    - Kubernetes permet de répondre à ces besoins
    - Notion de pod
      - Kubernetes permet de créer des pods
      - Un pod contient un ou plusieurs conteneurs et volumes
      - Et possède une adresse IP pour le tout
      - *NOTE* Si un élément du pod rencontre une panne, Kubernetes tue le pod entier
      - Pour créer pods, se basent sur des fichiers de description
        - À la *docker-compose*
    - Insiste sur le fait qu'il *ne faut pas utiliser un unique pod*
      - Pod peu gourmand, n'utilise qu'une fraction des ressources du noeud
      - Pod éphémère, peut être tué par Kubernetes de manière inopinée, sans sommation
    - À la place, *utiliser un groupe de pods identiques*
    - Notion de Controller
      - Kubernetes est un outil déclaratif
        - Users n'indiquent pas quelles commandes effectuer
        - Mais quel est l'état désiré
        - Kubernetes se charge de transitionner de l'état courant à cet état cible
          - [[file:img/kubernetes-reconciliation-loop.png]]
      - Propose plusieurs types de controllers
        - /Deployment/ a l'air d'être le controller "par défaut"
        - /StatefulSet/ pour les applications stateful
          - À la mort d'un pod, le recréé en réutilisant le même volume
        - /Job/ pour les tâches courtes
        - /DeamonSet/ pour que tous les noeuds matchant un critère démarre une instance d'un pod
          - Prend en compte les noeuds qui apparaissent au cours de la vie de l'application
        - Possibilité de créer de nouveaux controllers si besoin
      - Commandes existent pour manipuler directement les controllers
        - E.g. pour déployer une application
        - Étrangement, le niveau de granularité a l'air d'être sur l'image Docker et non pas le pod
      - Mais fonctionne aussi via des fichiers de description
      - Comment ça marche si application nécessitent de combiner plusieurs controllers ?
        - Un fichier unique ?
        - Ou un ensemble de fichiers de descriptions ?
    - Controllers incorporent des mécanismes supplémentaires
      - E.g. *Rolling Updates* : déploie progressivement de nouveaux pods se basant sur une nouvelle image puis interrompt les anciens pods
    - Kubernetes déploient aussi des Services
      - Sert de front-end pour les pods
      - Observe les pods pour déterminer à quel pod transmettre une requête
      - Se base pour cela sur un (des?) Selector(s)
        - Comment fonctionnent-ils ?
        - Possibilité/Besoin d'en faire des customs ?
    - D'un point de vue réseau
      - Communications entre containers se font via localhost
      - Communications entre pods (d'un même noeud) se font via les adresses IPs uniques des pods
      - Communications entre pod et service se font via l'adresse IP unique du service
      - Comment un container découvre l'adresse IP d'un pod/du service ?
    - Précise que Kubernetes ne repose sur le runtime Docker depuis sa v1.20
      - Utilise toujours les images Docker
      - Mais utilise un (des?) runtime(s) plus efficaces et standardisés
      - Quid des volumes et networks ?
        - Ne reposent pas du tout sur les solutions proposées par Docker ?
      - Est-ce que ça a un impact sur la façon de créer ses images Docker ?
- Réunion avec Guillaume le <2024-01-10 Wed>
  - Préparation
    - HS RH
      - A fait une demande de régularisation de congé pour le 02/01
      - A permis de détecter quelques problèmes
        - Personne qui valide mes demandes de congés
        - Jours reportés de l'an dernier
    - Technologies Cloud
      - Suivi le cours jusqu'au CM sur l'orchestration
        - M'a permis de revoir les bases
          - I/P/SaaS
            - Un peu de mal à délimiter PaaS
          - Infrastructures et Services
            - Ne connaissais pas OpenStack
            - Et que certaines organisations mettaient en place leur cloud privé
            - Par contre, est-ce qu'on retrouve les mêmes outils dans le fog ?
              - Ou est-ce trop gourmand ?
          - Services de stockage
            - Les SGBDs relationnels sont si peu adaptés au cloud ?
            - Pas trop creusé le sujet, mais j'entendais parler de NewSQL
      - Commence à expérimenter avec k8s
        - Installé minikube sur ma machine
        - En train de parcourir les tutos sur créer cluster, déployer simple application web
        - Et d'apprendre les concepts (Pods, Nodes, Services, Deployment...)
        - Curieux du fonctionnement du Control Plane pour qu'il ne soit pas un SPOF
        - Surpris que k8s soit pas un environnement unique, mais une multitude de distribution
          - Ai vu qu'il y a des distribs faites pour l'IoT : k3s, k0s
      - As-tu des ressources que tu conseilles, notamment sur Docker & Kubernetes ?
        - Understanding Docker/Kubernetes in a visual way par Aurélie Vache
    - Observatoires
      - Consulté le site d'Ammar sur les résultats de son questionnaire
        - Et débriefé avec lui
      - M'a permis de constater la grande hétérogénéité des observatoires
        - Source d'énergie, réseau disponible, etc.
      - Quels sont nos objectifs ?
        - À qui on s'adresse ?
        - Quelles sont nos contraintes ?
      - Ammar m'a parlé d'OZCAR et m'a linké un article
        - Prévois de le lire pour mieux comprendre les enjeux des observatoires
  - Notes
    - Deployment
      - Outil de base de k8s
    - Peut associer un Service LoadBalancer à un Deployment
    - k8s se focalise sur l'état desiré et l'état observé
      - Enregistre dans BDD l'état désiré
      - Puis observe son état
        - Outil de monitoring souvent ajouté : Prometheus
    - Voir du côté de Vagrant
      - Infrastructure as Code
        - Décrit l'infrastructure que l'on souhaite déployer via des services Cloud
      - Vagrant est l'équivalent local
        - Utilisé dans LivingFog
      - Permet de déployer Kubernetes et consorts
    - Observatoires
      - Nous nous intéressons aux observatoires
        - Isolés
        - Variétés de capteurs
        - Variétés d'utilisateurs
        - Contraintes sur énergie et bande-passante
      - Mais aurons quand même grande hétérogénéité
        - Type de tâches
        - Volume de données
      - Sujet à considérer est la problématique du changement
        - Comment accompagner les scientifiques dans l'adoption de la solution que l'on va proposer ?
        - P-e voir avec les ingés du service d'hydrologie pour déployer nos essais
          - Ont mis en place un petit observatoire au niveau du ruisseau
            - Avec capteurs
            - Et autres ?
- Régulariser situation du 02/01
  - A envoyé une demande de régularisation
  - Sur les conseils de Myriam, en a profité pour notifier des problèmes de
    - Personne qui valide mes demandes de congés
    - Jours reportés de l'an dernier
  - Demande a été traitée
- Prendre en main Kubernetes
  - Plutôt que de faire tourner l'environnement kubernetes en complet sur sa machine
  - Semble plus commun d'utiliser un outil pour virtualiser le cluster et les différents composants de k8s
  - Plusieurs outils existent
    - minikube : https://github.com/kubernetes/minikube
      - Outil dev par l'équipe de k8s
    - kind : https://github.com/kubernetes-sigs/kind
      - Outil dev par l'équipe de k8s
      - Conçu initialement pour tester k8s
      - Indiqué comme pouvant être aussi utilisé pour le dev d'applis locales
  - Plusieurs blogposts font des comparaisons entre ces outils
    - https://www.blueshoe.io/blog/minikube-vs-k3d-vs-kind-vs-getdeck-beiboot/
    - https://shipit.dev/posts/minikube-vs-kind-vs-k3s.html
    - https://alperenbayramoglu2.medium.com/simple-comparison-of-lightweight-k8s-implementations-7c07c4e6e95f
    - Pour prendre en main k8s, les différentes options semblent se valoir
      - [[file:img/kubernetes-distrib-comparaison.png]]
  - Je croyais que k8s était un logiciel/environnement unique
  - Mais il semble y avoir une multitude de distributions différentes
    - Notamment des distribs conçues pour/orientées IoT & Edge
    - K3s : https://github.com/k3s-io/k3s
    - MicroK8s : https://github.com/canonical/microk8s
  - Pour démarrer, suis le tuto : https://www.digitalocean.com/community/tutorials/how-to-use-minikube-for-local-kubernetes-development-and-testing
    - Quelques difficultés à la première étape
      - minikube plantait silencieusement
      - Ajouter l'option /--driver=docker/ a permis de dépasser l'erreur rencontrée
        - Ai ajouté l'option à ma config par défaut
          - minikube config set driver docker
    - Ai pu suivre le reste du tuto sans erreurs
    - Pas trop compris les points suivants
      - kubectl create deployment web --image=gcr.io/google-samples/hello-app:1.0
        - Permet de créer un deployment nommé web en utilisant l'image passée en option
        - Mais c'est quoi un deployment ?
        - Options notables de la commande create deployment
          - --replicas=X : permet d'indiquer un nombre de replicas initial
          - --port=Y : permet d'exposer le port donné
        - C'est créé sur un ou plusieurs noeuds ?
      - kubetcl expose deployment web --type=NodePort --port=8080
        - Permet de créer un service qui expose la ressource demandée
        - À quoi correspondent les options --type et --port ?
        - --port
          - Le port sur lequel écoute l'application du ou des pods
          - Des pods ou des noeuds ?
        - --type
          - Le type de service qui va être créé
          - Ici, je suppose que c'est un service simple qui se contente de faire du port forwarding
          - Plus d'infos ici : https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport
          - Cette page précise qu'on peut aussi passer comme valeur LoadBalancer
          - Permet de provisionner un load balancer fournit par le cloud provider
          - Quid dans minikube ?
            - Le tuto de k8s le fait faire
            - Pas d'erreur reportée, service fonctionnel
  - Passe maintenant à : https://kubernetes.io/docs/tutorials/kubernetes-basics/
    - Cluster
      - Ensemble composé de Nodes et du Control Plane
      - Node
        - Machine, potentiellement virtuelle, qui sert de worker pour l'application
        - Va faire tourner des Pods
        - Chaque noeud possède un Kubelet
          - Agent qui gère le noeud et sa communication avec le Control Plane
      - Control Plane
        - Orchestrateur qui gère la maintenance de l'état de l'application, son passage à l'échelle et ses rolling updates
        - Quelles garanties sont offertes par le Control Plane ?
          - Est-il distribué ? Comment fonctionne-t-il ? Quel impact sur son comportement en cas de panne d'une des répliques ?
    - Deployment
      - Permet de décrire l'état souhaité
      - Un Deployment Controller, géré par le (faisant partie du ?) Control Plane, va ensuite monitorer l'état de l'application et instancier/retirer des Pods au besoin pour obtenir l'état souhaité
    - Le tuto fait remarquer que, au moment de lancer une application, on a un seul Node de disponible
      - Le Node qui fait aussi tourner le Control Plane
    - On peut cependant lancer une application
      - Celle-ci tournera alors sur le même Node que le Control Plane
    - Me paraît mieux de modifier le setup de base pour avoir plusieurs noeuds
      - Au moins 2, le Control Plane et un Worker
      - Pour cela, suis tutos :
        - https://minikube.sigs.k8s.io/docs/tutorials/multi_node/
        - https://medium.com/cloudnloud/how-to-minikube-with-multi-node-setup-1159006fc80e
      - Commandes
        - Créer cluster : minikube start --nodes=2
        - Ajouter Node à cluster existant : minikube node add
          - À voir comment on précise à quel cluster on ajoute ce Node
      - Semble y avoir un problème avec le driver par défaut pour les Volumes dans un cluster multi-nodes
        - https://minikube.sigs.k8s.io/docs/tutorials/volume_snapshots_and_csi/
        - Voir ce que cela implique et corriger si besoin
      - Minikube m'a aussi affiché un warning lors de l'ajout du Node
        - Cluster was created without any CNI, adding a node to it might cause broken networking.
        - Voir ce que cela implique et corriger si besoin
- Trouver des ressources Docker & Kubernetes
  - Guillaume m'a passé le livre *Understanding Kubernetes in a visual way* par Aurélie Vache
  - Elle a aussi fait une série de vidéos sur le sujet :
    - https://www.youtube.com/watch?v=a1Uwoq1Yv6U&list=PLmw3X80dPdlzksg6X9s23LEkLMWFGGUn5
  - Aussi trouvé les vidéos suivantes qui ont l'air pertinentes
    - *Kubernetes Design Principles: Understand the Why* : https://www.youtube.com/watch?v=ZuIQurh_kDk
    - *Kubernetes Explained in 6 Minutes | k8s Architecture* : https://www.youtube.com/watch?v=TlHvYWVUZyc
  - Me parait un bon début
- Discussion avec Éric Poiseau et Olivier Sentieys
  - En réponse au mail de Guillaume informant les autres membres du projet SmartOps, Éric m'a proposé de passer le voir
  - Il m'a présenté le SED et s'est occupé de quelques démarches
    - Ajout à la mailing list ingedev
    - Ajout au mattermost devel
    - Ajout au groupe gitlab SmartSense
    - Présentation rapide de l'AGOS
  - A insisté sur le fait que je passe le voir si je rencontre des difficultés ou ai besoin d'un avis extérieur
  - M'a ensuite présenté à Olivier Sentieys
    - Pensais qu'il était basé à Lannion
    - Mais semble être revenu à Rennes
    - Seul Mickael Le Gentil est basé à Lannion donc
  - M'ont parlé du projet SmartSense
  - Présenté les capteurs SmartSense
    - Carte sur laquelle les capteurs sont branchés
    - Interfacée avec une Raspberry Pi (version 3 si j'ai bien suivi)
      - Permet d'avoir un peu de moyen de calculs localement
      - Et appliquer des traitements sur les données avant de les remonter
      - Notamment, plutôt que de transmettre le flux vidéo/audio
      - Peut traiter ces flux pour remonter des métriques telles que présence de personnes dans la salle, nombre de personnes, type de sons identifiés
      - Permet ainsi de préserver l'anonymat et de limiter l'usage de bande-passante
    - Branché sur secteur pour l'alim électrique
    - Connecté en ethernet pour remonter les données
    - Existe une version adaptée pour l'extérieur
      - Fonctionne sur batterie
      - Et stocke les données collectées sur carte SD, à récupérer manuellement
  - Montré https://co2.irisa.fr/
    - Permet de suivre l'évolution de métriques remontées par les capteurs SmartSense d'une salle donnée
      - e.g. taux de CO2, la température
    - Surprenamment, n'interroge pas la BDD
    - Mais récupère et présente les métriques seulement à partir de l'instant T
    - N'a plus trop l'air de fonctionner
      - Affiche les données à un instant donné au moment où j'accède à l'application
      - Mais n'a pas l'air de récupérer/d'afficher de nouvelles données si je reste sur la page
        - Temps réel ? Fréquence d'échantillonnage ?
      - Plus troublant, la date donnée par le capteur SmartSense est incorrecte
        - [[file:img/2024-01-11-screen-co2-irisa.png]]
      - Et n'a pas l'air de s'actualiser régulièrement
      - Une slide de l'ADT mentionne que les données collectées sont transmises à une time series DB, InfluxDB
    - Est-ce que ça ne pose pas de problème d'avoir des données estampillées incorrectement ?
    - J'ai rien dit
    - En me reconnectant sur le site, je suis tombé sur une salle dans laquelle il y avait une réunion au même moment
    - J'ai ainsi pu faire les capteurs en cours de fonctionnement
      - [[file:img/2024-01-11-screen-2-co2-irisa.png]]
    - L'interface affiche ainsi les nouvelles entrées
      - Une mesure toutes les 20s semblerait
    - Les capteurs sont donc inactifs entre les réunions ?
      - Comment cela fonctionne ?
  - Montré https://smartsense-gest.inria.fr/
    - A l'air d'être une interface de gestion des capteurs
    - M'ont créé un compte, mais ne dispose d'aucun droit
  - Premières pistes de travail concernant SmartSense
    - Rencontrer Guillermo Andrade-Barroso
      - Ingénieur du SED qui a été impliqué de manière plus importante dans le projet SmartSense
      - Aura probablement une meilleure compréhension des différents repos qui composent le projet
        - De leur fonction, état et pistes de travail
    - Une piste déjà identifiée consiste en l'ajout du support du WiFi aux capteurs SmartSense
      - Permettrait dans un contexte en extérieur de transmettre les données
      - Et de me faire découvrir le système
    - Puis voir pour faire interagir les capteurs SmartSense avec la plateforme LivingFog
- Regarder *Kubernetes Design Principles: Understand the Why*
  - Pourquoi k8s ?
    - Souhaite déployer des conteneurs sur noeuds
    - Méthode traditionnelle consiste à se log en SSH sur la machine et exécuter la commande
    - Mais doit ensuite vérifier que tout se déroule correctement
      - Conteneur n'a pas crash
      - Noeud n'a pas crash
      - Connexion SSH a bien fonctionné
    - Besoin d'un outil de monitoring pour cela
    - Et de mécanismes de catch up pour gérer tous ces edge cases
    - Rejoint ce que m'expliquait Guillaume
      - Se retrouve avec une base de code complexe & lourde pour gérer tous les scénarios étranges
  - Approche déclarative
    - Permet en tant qu'user de ne plus se complexifier la tâche avec le "comment"
    - Se concentre juste sur le "quoi", l'état désiré
    - Et l'outil est en charge de réaliser ce "quoi", de mettre en place cet état
  - Pourquoi approche déclarative ?
    - Auto-recovery
      - Si une panne survient, c'est k8s qui est en charge de détecter la panne et de re-converger vers l'état désiré
      - Sans que l'user soit concerné/impliqué dans le "comment"
  - Comment déployer les containers ?
    - Approche naïve est que le Control Plane, à partir de la description de l'état désiré
      - Choisisse un noeud adapté
      - Commande à ce noeud de démarrer le container
    - Reproduirait le pattern qu'on aurait avec l'approche impérative
      - Control Plane devrait alors monitorer et incorporer des mécanismes de catch up en cas de défaillance
  - Pour éviter cela, ré-utilise une approche déclarative en interne
    - Control plane définit l'état désiré de chaque noeud
    - Chaque composant (les noeuds, le scheduler...) va alors oeuvrer pour converger vers l'état indiqué
    - Approche nommée Level Triggered (vs. Event Triggered)
      - Event Triggered : approche event-based
        - Les composants réagissent aux events propagés pour déterminer leurs actions
        - Si un composant a eu une défaillance et a manqué un event, doit mettre en place un mécanisme pour lui re-propager cet event
      - Level Triggered : approche par niveaux
        - Events font progresser de niveau
        - Niveau mis à disposition des composants
        - C'est à partir de son niveau courant et du niveau désiré qu'un composant détermine ses actions
    - Permet de concevoir un système plus simple et robuste
    - Clame cependant qu'aucun composant n'est un SPOF dans ce système
      - Quid du Control Plane ?
      - C'est lui qui conserve l'état désiré du système
      - Et qui reçoit/gère les demandes de MàJ de l'état
        - e.g. scheduler a décidé du noeud qui allait être responsable d'un pod donné
      - Comment il ne peut pas être un SPOF ?
    - Justifie cela de la manière suivante
      - Si le Control Plane rencontre une panne
      - Les différents composants du système continueront à tourner à partir des dernières informations obtenues sur l'état désiré
      - Si un autre composant a une panne
      - Le reste du système continue de fonctionner de manière indépendante
    - Curieux de la charge de travail du Control Plane et du Scheduler
      - Et de l'impact d'une panne du Scheduler
    - Cette approche permet aussi de faciliter l'ajout d'add-ons/l'implémentation de composants customs
      - Doit juste interagir avec le Control Plane pour mettre à jour le niveau comme souhaité
  - Comment fournir les secrets et autres données de config à l'application ?
    - L'API k8s fournit plusieurs objets pour représenter ces données
    - L'API étant transparente, peut modifier son application pour fetch ces données
    - Mais quid des applications legacy qui récupèrent ces données via un fichier ou des variables d'env depuis des temps immémoriaux ?
    - k8s permet de fournir ces données aux pods sous la forme de fichiers ou de variable d'env
  - Comment sont gérés les volumes distants ?
    - i.e. volumes fournis par des services cloud
    - Renseigné directement dans la définition du pod
    - Une fois que le pod schedulé pour un node, le storage controller vérifie si le volume indiqué est attaché au node
      - Effectue les démarches nécessaires si besoin
    - Et MàJ l'état du node
    - Mais c'est une erreur de référencer le type de stockage directement dans la config du pod
      - Pod plus portable, vendor-locked
    - Ont mis en place des abstractions pour répondre à ce problème
      - PersistentVolume et PersistentVolumeClaim
      - Référence une claim dans la config d'un pod
      - Une Claim est un objet k8s aussi
        - Décrit les caractéristiques du volume demandé
        - e.g. accès read-only/rw, type de stockage
      - Et un Controller, le Persistent Volume Controller se charge d'allouer un volume correspond aux besoins par rapport aux services disponibles
  - Pourquoi rendre l'application portable ?
    - Permet de découpler le dev de l'application du cluster/service cloud sur lequel elle va tourner
    - Fait la comparaison suivante : k8s, c'est comme un OS pour les applications distribués
      - Permet de ne plus se soucier lors du dev d'une appli distribué de l'environnement dans lequel cette dernière va tourner
- Adapter la configuration réseau pour clusters multi-nodes
  - Pas particulièrement réussi à trouver des ressources sur le sujet
  - J'ai redémarré minikube cette fois-ci avec 2 nodes d'entrée de jeu
    - minikube start --nodes 2
  - Le log au démarrage ne m'a pas indiqué le moindre warning
  - On va considérer que c'est bon du coup
    - Jusqu'à preuve du contraire
- Utiliser un driver pour Volume adapté aux clusters multi-nodes
  - L'issue indiquée ne propose pas d'autres solutions/d'alternatives à celle présentée
    - Issue : https://github.com/kubernetes/minikube/issues/12360
  - Et semble assez récente
    - Correctif courant février 2023
    - Des users qui confirment la correction du problème courant août 2023
  - J'ai donc suivi les étapes indiquées
  - Le setup de la classe de storage semble s'être effectué correctement
- Réunion SmartSense
  - Réunion ayant pour objectifs principaux de
    - Me présenter la plateforme SmartSense
    - Me présenter les problématiques/pistes de travail que Mickaël & Olivier souhaiteraient qu'on explore au cours de l'ADT
  - Préparation
    - Olivier & Eric m'ont déjà présenté les capteurs SmartSense
      - Le fait qu'ils sont équipés d'une Raspberry Pi 3 pour avoir un peu d'intelligence/puissance de calcul en local
    - M'ont aussi parlé de Guillermo Andrade-Barroso
      - Attendais un peu explorer les repos de mon côté pour le contacter
      - Et d'avoir eu cette réunion
    - M'ont parlé de 2 applications principalement
      - https://co2.irisa.fr/
      - https://smartsense-gest.inria.fr/dashboard
    - CO2
      - Permet de suivre les relevés de données par les capteurs dans une salle à partir d'un instant T
      - Ne voyant pas d'évolution, et les données datant de l'an dernier, pensais qu'il était planté
      - Mais j'ai eu la chance de tomber sur une réunion lors d'un test
      - Et pu voir son fonctionnement
    - Gest
      - Dashboard du système
      - Avait l'air de rencontrer des problèmes de certificats quand Eric a souhaité me le présenter
      - J'ai un compte, mais sans droits d'accès
    - Curieux de mieux comprendre la galaxie de repos du groupe GitLab
      - Quels sont les principaux projets ?
      - Quel est leur rôle respectif ?
      - Est-ce que certains ne sont plus d'actualité ?
      - Y a-t-il un document récapitulant l'architecture globale du système ?
  - Notes
    - Actuellement, raspberry peu utilisée
      - Sert juste à passer les données au réseau
    - Idée serait d'utiliser cette carte pour ajouter des traitements
      - E.g. préparer les données pour permettre la désaggrégation des données
        - Histoire de suivre la consommation énergétique de chaque équipement
      - Détecter la présence de personne
        - Peut utiliser la vidéo
        - Mais aussi le CO2
          - Semblerait qu'il est possible d'estimer le nombre de personnes présentes dans une pièce en fonction de la croissance du taux de CO2
    - Objectif
      - Mettre des traitements à chaque tier de l'architecture
      - Tout au long de la vie de la donnée
        - De la collecte au cloud
    - Axe de travail SmartOps
      - Mettre en place la communication sans-fil
      - Pour permettre interaction avec Living Fog
    - Bug d'InfluxDB sur version en extérieur de SmartSense
      - Fait tourner sur la raspberry une instance InfluxDB
        - Puisque pas de connexion pour remonter les données
      - Mais rencontraient des problèmes de stabilité de l'instance
        - Tâches trop couteuses ?
        - Serait intéressant de creuser et d'identifier l'origine du problème
    - Dernière étape
      - Utiliser du hardware spécialisé, un Digital Software Processor, pour faire un pré-traitement sur les flux (audio/vidéo)
        - Flux trop important/trop coûteux à traiter par les microprocesseurs équipés
      - Actuellement, déjà un DSP d'équipé sur les capteurs SmartSense
      - Un étudiant travaille actuellement sur un projet de cette nature
        - But est de router les micros sur le DSP pour traiter leurs entrées
        - Dans le but de faire par ex de la spatialisation de sources sonores
    - CO2
      - Application réalisée dans le cadre d'un stage
        - Pas vraiment testée/validée
      - Mais bon point d'entrée pour comprendre comment on interagit avec le système pour récupérer les données et effectuer des traitements
    - Gest
      - Possibilité de récupérer les données via un export de la BDD
      - Sinon possibilité de se connecter directement au broker pour récupérer les données en temps réel
        - Mickaël a un script python qui fait ça
  - Prochaines étapes
    - Continuer à me former sur la partie Fog
    - Et découvrir SmartSense
      - Consulter les documents d'architectures dans 3Douest/Documents
      - Consulter le script python permettant en local de consulter les données remontées par SmartSense
      - Consulter le projet CO2 pour creuser plus loin
    - En parallèle, Mickaël voit comment setup l'environnement de dev pour SmartSense
      - Et m'apportera le matériel nécessaire
    - Une fois l'environnement mis en place, première étape sera probablement de mettre en place une communication WiFi
      - Puis d'ajouter des traitements en local sur le capteur
- Déployer une application complexe avec k8s
  - Plusieurs points à creuser au préalable
    - Gestion des volumes
      - On ne créé pas directement les volumes
      - Les abstractions Persistent Volume et Persistent Volume Claim sont là pour permettre de découpler les volumes des cloud providers
      - Indique via une Claim les caractéristiques du volume que l'on souhaite obtenir/mis à disposition de notre application
      - k8s se charge d'allouer un volume fittant ces critères
      - Et on indique dans la specification d'un pod le ou les volumes qui doivent être montés
      - Comment ça se passe si on re-déploie l'application ?
        - Comment garantir que le même volume soit alloué à la même claim ?
          - Est-ce que k8s gère ça de son côté ?
        - On associe un nom de volume à une claim dans la specification du deployment
    - Gestion des services
      - Lors de la création d'un service, plusieurs données sont récupérées
        - L'adresse IP du service
        - Le port sur lequel il accepte les connexions
      - Ses données sont accessibles aux pods par le biais de variables d'env
        - <NAME>_SERVICE_HOST/PORT
      - Mais ces variables d'env ne seront set que pour les pods créés après le service
      - Recommandé donc de créer les services avant les deployments correspondants
      - Comment on fait ce mapping service/deployment dans le fichier de config ?
        - Via les labels ?
        - Le nom plus probablement
      - Utiliser le nom du service ou les variables d'env définies du coup ?
    - Configuration et secrets
      - Possible de définir un fichier de configuration où centraliser les informations
      - e.g. mot de passe de la BDD
      - Quelle est la bonne pratique vis-à-vis de ces fichiers ?
        - Si une donnée est utilisée plusieurs fois dans le/les fichiers de description, la déplacer dans le fichier de configuration ?
    - Gestion des labels et selectors
      - Les fichiers de config que je rencontre renseignent régulièrement des métadonnées pour chaque objet k8s
        - labels
        - selectors
          - matchLabels
          - app
          - tier
      - Quelle est la liste de ces métadonnées ?
      - Quelle est leur rôle respectif ?
    - Organisation du fichier de description
      - Possible de faire un fichier de description par entité k8s
        - service, deployment, etc
      - Un peu lourd et peu pratique
      - Possible de regrouper plusieurs descriptions dans un même fichier
        - En séparant les descriptions respectives par des ---
    - Possible de lier les fichiers entre eux ?
      - Avoir un fichier index en quelque sorte
      - Ou ce n'est pas la bonne pratique ?
  - J'ai suivi le tuto suivant *Example: Deploying WordPress and MySQL with Persistent Volumes*
    - Dispo ici : https://kubernetes.io/docs/tutorials/stateful-application/mysql-wordpress-persistent-volume/
    - Définit un Secret pour indiquer le mot de passe de la BDD
    - Définit des fichiers de description distincts pour
      - L'instance de MySQL et les composants associés
        - PVC, Service, Deployment
      - L'instance de WordPress et les composants associés
        - PVC, Service, Deployment
    - Regroupe la description du système par le biais du fichier Kustomization
    - Déploie le système via la commande suivante
      - kubetcl apply -k ./
      - Warning : option -k et non pas -f vu qu'on passe par un objet Kustomization
    - Fonctionne nickel
      - A pu administrer et modifier le site par défaut proposé par WordPress
        - Création d'une page
        - Ajout d'une image uploadée
  - J'ai voulu répliquer ensuite l'instance de WordPress
    - kubetcl scale replicas=3 deployment wordpress
  - Obtient un pod correspondant sur chaque noeud
  - J'ai alors rencontré les problèmes évoqués par Guillaume
    - Déconnexions intempestives
      - Si on est dirigé vers une instance autre que celle qui a issue notre cookie d'authentification
      - Ce dernier est invalidé
      - Besoin de se reconnecter
      - Mais ne dure que si on continue d'interagir par chance avec la même instance
    - Contenu indisponible
      - Les pages sont bien partagées entre instances
      - Puisqu'elles doivent être décrites en BDD
        - Qui elle est commune à l'ensemble des instances
      - Par contre, l'image uploadée est elle indisponible régulièrement
      - Doit être conservée que par une des instances de WordPress
      - Le volume n'est donc pas partagé par l'ensemble des noeuds
  - Comment les corriger ?
** Semaine du <2024-01-03 Wed> au <2024-01-05 Fri>
*** Planned
**** DONE Installer logiciels
CLOSED: [2024-01-03 Wed 14:39]
- Emacs, VSCode, Git, Docker
**** DONE Configurer Org-mode
CLOSED: [2024-01-03 Wed 14:39]
**** DONE Résoudre problème ethernet
CLOSED: [2024-01-04 Thu 14:09]
- Semblerait que la connexion ethernet échoue à mon bureau
- Trouver et corriger du problème
**** DONE Consulter résultats questionnaire de Ammar
CLOSED: [2024-01-04 Thu 16:37]
- Ammar a produit et envoyé un questionnaire aux gestionnaires d'observatoires d'environnements naturels
  - Afin de comprendre l'existant, leurs usages et besoins
- Disponible ici : https://survey-results.kazem.fr/protected-routes/survey_stats
- Consulter cette ressource pour en apprendre plus sur l'existant et les problèmes rencontrés par les gestionnaires d'observatoires
  - Permettrait ensuite d'en discuter avec Ammar
**** DONE Apprendre raccourcis clavier de Fedora
CLOSED: [2024-01-05 Fri 07:57]
- Ouvrir terminal
- Gérer bureaux virtuels
  - Se déplacer entre bureaux
  - Déplacer applications entre bureaux
- Augmenter/Diminuer volume
- Mettre en veille
- Prendre en screenshot une zone de l'écran
**** IN-PROGRESS Suivre cours de Guillaume sur les technologies cloud
- Disponible ici : https://gitlab.inria.fr/pierre/sct-m1info
**** IN-PROGRESS Régulariser situation du 02/01
**** TODO Trouver des ressources sur Docker & Kubernetes
- Au-delà du cours de Guillaume, existe des ressources pour rentrer plus en détails sur ces outils (talks, livres)
- Voir pour en trouver et les consulter
*** Done
- Installer logiciels
  - Emacs & Git étaient déjà installé
  - A ajouté le repo officiel pour Docker
  - VSCode, c'était un fichier à installer
- Configurer Org-mode
  - Pour org-mode, je suis retourner lire la page de Martin sur la méthodo :
    - https://people.irisa.fr/Martin.Quinson/Research/Students/Methodo/
  - Il y parle de spacemacs, une configuration préfaite d'emacs
    - https://www.spacemacs.org/
  - Je l'ai installé et fait son tuto
  - Un peu pertubante initialement puisque cette config combine les commandes de vim & celles d'emacs
  - À voir ce que cela donne à l'usage
- Réunion avec Guillaume <2024-01-03 Wed> à 15h00
  - Questions
    - Par où commencer ?
      - Documents à lire ?
      - Code ?
    - Comment communiquer ?
      - Mattermost ?
  - Notes
    - Olivier s'intéresse aux capteurs Smartsense
    - Travaille avec Guillaume sur le projet Terra Forma
    - Projet coordonné par membre du département de géo-sciences de l'univ de Rennes
    - Majorité des membres du projet sont non-informaticiens, étudient les sciences de l'environnement
    - Intéressés par des observatoires de l'environnement naturels
    - Délimitent des territoires intéressants et les équipent de capteurs intelligents
    - Solution de base nécessite de récupérer les données sur le terrain après temps de collecte
      - Mais sujets de recherche peuvent nécessiter de traiter les données régulièrement
      - Mais territoires pas forcément accessibles
      - Mettent donc des stations de calculs au sein des environnements
    - Mais stations de calculs existantes répondent pas au besoin
      - Généralement propriétaires
      - Ne permettent que l'archivage des données et la transmission à un cloud
      - Souhaiteraient mettre en place leurs propres applications
        - Déclencher des actions (mettre en route capteurs, changer fréquence d'échantillonnage...) suite à un évenement en temps réel
        - Faire tourner des modèles de l'environnement et les comparer aux données réelles pour les valider/invalider
          - Et potentiellement évaluer l'état de l'environnement si on joue sur un de ces paramètres
      - Mais les solutions ne le permettent pas
    - Utilisation de plateformes de calcul en milieu naturel isolés posent des questions
      - Où trouver l'énergie pour les alimenter ?
        - Solaire probablement, mais s'agit d'une ressource intermittente (jour/nuit, été/hiver)
      - L'énergie étant limitée, comment adapter les traitements en fonction de la quantité à disposition (allumer/éteindre capteurs) ?
      - Comment relancer la plateforme si à court de jus momentanément ?
    - Ammar travaille sur ces problématiques
      - A rencontré et fait un questionnaire à l'attention des gestionnaires d'observatoires
        - Sur l'existant, leurs besoins, leurs attentes
      - Aurait récupérer et mis en forme les résultats de ce questionnaire
      - Voir avec lui à ce sujet
    - En ce qui me concerne, but du projet est de prendre en main la plateforme LivingFog
      - Plateforme développée par plusieurs doctorant-es
        - Probablement pas parfait d'un point de vue technique
        - Mais de la doc existe (livrables pour projet européen, doc technique)
      - A été déployée à Valence dans le cadre d'un hackathon
        - Consistait à proposer des applis de smart city (application de suivi de l'ensablement du port, application de détection de la fréquentation des différentes activités proposées)
        - Résultats très satisfaisants semblerait
      - But est d'évaluer cette plateforme pour notre nouvel usage
        - De déterminer ce qui nous intéresse et non
        - De virer ce qui nous est inutile
        - De consolider ce qui existe et intéressant pour nous
        - Et de l'adapter à notre usage
    - LivingFog repose sur la techno LoRaWAN pour la communication
      - Pratique pour échanger à longue distance en utilisant peu d'énergie
      - Mais faible bande-passante
      - Et qui pose des contraintes supplémentaires
        - Capteurs envoient les données à des gateways qui relaient les messages
        - Mais pas d'association entre capteurs et gateways
          - Les messages sont donc dupliqués
        - La déduplication des messages est effectuée de manière centralisée
      - Des gens de Terra Forma se penchent dessus, nous, on ne va pas se concentrer dessus
    - On va plutôt se pencher sur la partie cluster
      - Utilise des clusters de raspberry
      - Fait tourner kubernetes dessus pour gérer un ensemble d'applications sur un cluster
        - Existe des versions allégées de kubernetes k3s pour cluster de raspberry
    - Première étape est donc de monter en compétence sur les technos correspondantes
    - Guillaume a un cours sur les technos Cloud
      - Va m'y donner accès pour que je le suive et que je monte en compétence là-dessus
    - Creuser plus particulièrement Docker & Kubernetes
- Résoudre problème ethernet
  - Guillaume m'a explique que les prises Ethernet ne sont pas toutes rattachées au même réseau
  - Peut être nécessaire de changer la prise sur laquelle je suis branché
  - Cela n'a rien changé
  - Après discussion avec les membres de la DSI, m'ont dit d'ouvrir un ticket pour qu'ils affectent en dur l'adresse mac du dock à ma machine
  - Ça a résolu mon problème de connexion
- Suivre cours de Guillaume sur les technologies cloud
  - CM1 - Introduction au Cloud
    - Pour offrir un service plutôt qu'un produit, nécessité d'une infrastructure
    - Cloud offre plusieurs bénéfices aux users
      - Comparé à un système traditionnel, permet de déléguer la gestion de l'environnement au provider
      - Permet d'utiliser uniquement les ressources dont l'on a besoin à un instant T
        - Et non pas perpetuellement les ressources dont l'on a besoin pour tenir la charge lors des pics d'activité
      - Permet donc de scale de manière flexible en fonction des besoin
    - Différences entre IaaS, PaaS et SaaS
      - [[file:img/iaas-paas-saas.png]]
      - IaaS
        - Provider ne fournit que les machines virtuelles
        - C'est aux users de setup leurs machines à partir de l'install de l'OS
      - PaaS
        - Ici la machine est déjà installée
        - Il ne reste plus qu'à installer son ou ses applications
      - SaaS
        - Ici, aucune installation nécessaire
        - On souscrit directement une instance de l'application désirée
    - Mentionne que certaines entreprises créent leur propre cloud privé
      - Détaillé par : https://www.datamation.com/cloud/private-vs-public-cloud/
    - Cloud public
      - Cloud tel que je l'imagine et connais
      - Géré par un provider
      - Les entreprises ont recours à ses services et se "contentent" de l'utiliser
    - Cloud privé sur site
      - L'entreprise recrée un cloud chez elle
        - Data-center, machines, gestion
      - Pour cela, peut reposer sur des outils mis à disposition par les cloud providers ou des projets OS (OpenStack)
      - Offre la confidentialité et souveraineté des données
      - Mais en échange, introduit
        - Une charge de travail (setup et manage le cloud)
        - Des coûts à priori (data center, machines)
        - Une limitation de la scalability (doit acheter des machines supplémentaires lorsque atteint la charge limite)
    - Cloud privé hébergé
      - Possible aussi de demander à un provider de s'occuper de notre cloud privé
      - Caractéristiques similaires à un cloud public
        - Même si nécessite plus de préparations et de coûts en amonts qu'une offre publique
      - Mais permet de reposer sur des machines dédiées à notre usage, offrant ainsi sécurité et confidentialité
    - Majorité des entreprises ont un usage hybride entre cloud public et privé
      - [[file:img/usage-cloud.png]]
    - Et rien n'empêche d'utiliser plusieurs clouds d'un même type
      - Pour silo-er les apps, avoir de la redondance en cas de panne d'un provider
    - Questions
      - Un peu de mal à formaliser le PaaS et ce qu'il comprend
        - Je vois ça comme une machine avec déjà son OS de setup
        - Il ne reste plus qu'à installer son application
        - Mais le cours mentionne la couche middleware
        - Qu'est-ce qu'elle couvre et peut offrir comme services ?
          - Mention de DBs et frameworks HPC
  - CM2 - Virtualisation
    - Définition
      - Un logiciel qui imite un appareil physique
      - Fournit au moins les mêmes fonctionnalités
      - Utilise une interface identique
    - Avantages
      - Peut être créé et supprimé à la volée
      - Peut être facilement modifié/configuré
      - Peut proposer des fonctionnalités supplémentaires à la version physique
    - Exemples
      - Clavier virtuel
      - Disque virtuel
      - Système de stockage virtuel (NAS, SAN)
        - Un peu de mal à piger la différence entre ces technos
      - Réseau virtuel (VLAN, SDN)
      - Machine virtuelle
      - Conteneur
    - Remarques
      - Slide 8, opération /take snapshot/ : c'est pas /head = new_snapshot/ plutôt ?
        - Ou /head = empty/ plutôt ?
  - CM3 - Infrastructures cloud VM-based
    - Porte principalement sur la description de l'architecture système d'un cloud
    - Prend pour cela comme exemple OpenStack
      - Se base sur la présentation qui en est faite lors de la *Cloud Architect Alliance #15*
      - Disponible ici : https://www.slideshare.net/alessandrovozza/cloud-architect-alliance-15-openstack
    - Globalement, une multitude de différents services
      - [[file:img/2015-open-stack-architecture.png]]
    - Chacun ayant son rôle et ses responsabilités
      - E.g. Keystone
        - Service d'authentification et d'autorisation
        - Fournit aussi la liste des autres services
    - Composants autonomes, pouvant être indépendamment répliqués pour répondre aux besoins (charge, disponibilité...)
  - CM4 - Services cloud de stockage
    - Présente les différents types de service de stockage offerts par les cloud providers
    - Object storage
      - Niveau de granularité est le fichier
      - Permet de créer,lire et supprimer des fichiers
      - Mais pas de les modifier
        - Les fichiers sont donc immuables
      - E.g. Amazon S3 (Simple Storage Service)
    - Block storage
      - Niveau de granularité est le volume, i.e. des partitions disques virtuelles
      - Permet de créer, modifier les caractéristiques (taille, type de stockage), et d'attacher des volumes aux VMs
      - E.g. Amazon EBS (Elastic Block Store)
      - Propose généralement services supplémentaires
        - Snapshotting, et sauvegarde/réplication des snapshots effectuées
    - Relationnal storage
      - Indique qu'on peut démarrer et gérer son propre SGBD relationnel sur une VM
      - Mais que les cloud providers proposent directement des services de BDDs relationnelles
      - Insiste cependant sur les limites de ce type de système
        - Ne tolèrent pas les partitions réseaux généralement
        - Deviennent soit indisponible, soit incohérente de manière non-maitrisée
    - NoSQL storage
      - Présente les bases de données NoSQL
      - Précise qu'elles ont été conçues pour les besoins des applications cloud, notamment
        - Scalable, i.e. supporter un dataset de très grande taille et une charge importante
        - Elastic, i.e. faciliter l'ajout & la suppression d'instances à la volée
        - Partition tolerant
      - Détaille ensuite différents SGBDs NoSQL
        - DynamoDB (KV-Store)
        - MongoDB (Document-based)
        - Apache Cassandra (Column-based)
    - Remarques
      - Je sais pas si Guillaume mentionne la vague NewSQL dans la partie sur les services de SGBDs relationnels
        - Mais le constat est peu élogieux sous la forme actuelle
        - Est-ce que les SGBDs relationnels sont si inadaptées aux applications distribuées ?
          - Notamment, les systèmes appartenant à la vague NewSQL ne sont pas partition tolerant ?
        - Peut aussi s'intéresser à ce qui se fait du côté de ElectricSQL
- Régulariser situation du 02/01
  - J'ai essayé de déposer mon jour de congé pour le 02/01 le <2024-01-04 Thu>
  - Mais Casa m'empêche de le faire car la date est antérieure à la date du jour
  - À voir au retour de l'assistante d'équipe
- Consulter résultats questionnaire de Ammar
  - Résultats obtenus via 59 réponses (17 complètes, 42 incomplètes), couvrant 25 observatoires
  - Systèmes existants
    - Sources d'énergie
      - Principalement du solaire et de la batterie
      - Comment les observatoires gèrent-ils les limites de ces sources (nuit, batterie vide...) ?
      - Mentionne une source "Autres", des exemples ?
    - Techniques de communication
      - Principalement via mémoire interne (?) et 4G
        - Qu'est-ce qu'on entend par mémoire interne ?
        - C'est pas trop coûteux la 4G ?
    - Équipement info sur site
      - 47% déclarent que les observatoires incluent de l'équipement info en plus des capteurs
      - On a une idée du type d'équipement ?
    - Nombre de capteurs par site
      - La majorité des sites est regroupée (gausienne) dans les tranches 10-20, 20-50 et 50-100
    - Utilisation des données par des /operational players/
      - C'est quoi ?
    - Détection d'évènements automatique
      - Peu de détection automatique (17,65%), et encore moins de réponse automatique (29,41%)
      - À quoi sert la détection sans réponse ?
      - Exemples de réponse ?
    - Pré-processing sur site
      - Peu répandu (29,41%)
      - À quoi sert ce pré-processing ?
      - Les données invalides détectées lors de ce pré-processing sont généralement supprimées (81,82%)
      - Choix ou contrainte ?
    - Détection automatique de capteurs défectueux
      - Seulement 5,88% de sites avec cette fonctionnalité
      - Que font-ils dans ce cas ? Coupure du capteur incriminé ?
  - Systèmes futurs
    - Ammar a abordé dans une seconde du questionnaire la question des systèmes futurs et des fonctionnalités désirées
    - Intégration de données extérieures
      - En plus des données collectées, une partie considérable des réponses montre un intérêt pour intégrer dans les données d'un site des données extérieures
      - Plusieurs provenances suggérées
        - Autres sites/observatoires (52,94%)
        - Services tiers, e.g. Météo France (76,74%)
        - Données manuelles (47,06%)
    - Monitoring de la santé du système
      - Les réponses au questionnaire montre un intérêt/besoin à ce sujet
      - Pistes indiquées
        - Intégrer des données d'autres sources pour aider la détection
          - Quelles données ?
          - Comment cela fonctionne ?
        - Notification
  - Questions globales
    - Les figures présentent-elles les résultats des observatoires des 17 réponses complètes uniquement ?
    - Y a-t-il différents niveaux de réponses aux questions "intéressé-e/non-intéressé-e" ?
      - Y a une différence entre vouloir "pourquoi pas" une fonctionnalité et avoir besoin d'une fonctionnalité
      - Cela peut avoir un impact sur les contraintes du système quand la fonctionnalité considérée est "intégrer des données de services tiers" ou "données en temps réel"
    - Quel est le but de ces observatoires ?
      - Est-ce qu'ils sont là pour simplement observer ?
      - Ou certains ont vocation à agir sur l'environnement observé en cas d'évènement (sécheresse, inondation...) ?
    - Y avait-il des questions libres à ce questionnaire ?
      - Ammar pose des questions sur des aspects précis des observatoires et définit des pistes d'améliorations de par son formulaire
      - Mais est-ce que d'autres aspects sont importants pour les gestionnaires d'observatoires et n'étaient pas abordés dans le questionnaire ?
  - Remarques
    - Choix des couleurs
      - L'utilisation du vert pour indiqué "non" me paraît non-intuitif
        - Une couleur proche du vert pour indiquer un résultat positif et une autre proche du rouge pour indiquer un résultat négatif me semble plus commun
    - Graphique sur l'âge des données collectées
      - L'unité me paraît pas super adaptée
  - Discussion
    - Source d'énergie
      - Batterie interne = piles
      - Mais nécessite tournée régulière pour la maintenance
        - Nécessaire de toute façon pour récupérer les données
    - Équipement IT
      - Ammar n'est pas convaincu qu'il y ait tant d'observatoires sans data logger
        - À creuser avec les gestionnaires d'observatoires
    - Operational Players
      - Organisations tierces, généralement services publiques, qui pourraient utiliser les données collectées par les observatoires pour leur tâche, e.g. alerter la population sur un risque d'inondation, de sécheresse
      - Mais l'utilisation des données des observatoires par les acteurs opérationnels n'est pas le but de tous les observatoires
    - Réponse automatique à un event
      - C'est 30% global, pas juste en réponse à la détection automatique
      - Y a des events manuels, e.g. le passage en hiver
    - Hétérogénéité des observatoires
      - L'ensemble des observatoires montre une grande hétérogénéité de leurs buts, contraintes et besoins
        - Certains ont accès à la 4G, au réseau électrique
      - Tous ne nous intéressent pas dans le cadre de ce projet
      - But du questionnaire est d'identifier les observatoires auxquels nous pouvons apporter quelque chose
* Autres
** Commandes utiles
- Mettre à jour paquets
  - dnf check-update
  - sudo dnf upgrade
- Kubernetes
  - Pod
    - Créer un pod : kubectl create -f pod.yaml
    - Lister les pods existants : kubectl get pods
    - Inspecter un pod : kubectl describe pod mysmallpod
- Noeud SmartSense
  - Lister l'espace disque disponible : df -h
  - Récupérer la liste des services en route : systemctl --type=service --state=running
  - Se connecter à la DB : influx -username <username> -password <password> -database <database>
  - Suivre les logs de l'application : tail -f /var/log/syslog
    - Ou : journalctl -f -u mainApp/influxdb
  - Récupérer la conf d'un fichier, sans les commentaires : grep '^[[:blank:]]*[^[:blank:]#;]' <file>
  - Arrêter le noeud : sudo shutdown -h now / sudo halt
- Influx
  - Lister les bases de données : SHOW DATABASES
  - Utiliser une base de donneés : USE <database>
  - Lister les measurements : SHOW MEASUREMENTS
  - Récupérer les entrées d'un measurement : SELECT * FROM <measurement> LIMIT <nb>
  - Quitter le shell InfluxDB : exit
** Raccourcis utiles
*** Fedora
- Se déplacer entre bureaux virtuels
  - Ctrl + Alt + Left/Right
- Déplacer application courante entre bureaux virtuels
  - Ctrl + Alt + Shift + Left/Right
- Redimensionner l'application courante
  - Super + Left/Right/Up/Down
- Déplacer application courante entre écrans
  - Super + Shift + Left/Right/Up/Down
- Prendre en screenshot une zone de l'écran
  - Print Screen
- Verrouiller l'écran
  - Super + l
*** Emacs
- Naviguer dans le fichier
  - Haut/bas : k/j
  - Gauche/droite : h/l
  - Début/fin : g-g/G
- Copier/Coller
  - Sélection : C-SPC
  - Copier (yank) : y (ou M-y pour capturer la ligne entière et le retour à la ligne précédent)
  - Coller : p (après) ou P (avant)
- Afficher image
  - Insérer lien vers image : C-c C-l
  - Toggle inline image : C-c C-x C-v
- Recherche
  - /mot RET pour déclencher la recherche
  - n pour avancer jusqu'à l'occurrence suivante
  - N pour l'occurrence précédente
  - ?mot RET pour déclencher la recherche en sens inverse
- Buffer
  - Revenir au buffer précédent : SPC TAB
*** Terminal
- Ouvrir un nouvel onglet
  - Ctrl + Shift + T
- Changer d'onglet
  - Alt + 1/2/3
- Fermer onglet
  - Ctrl + Shift + W
